{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3531d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spotipy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from dateutil import parser\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from tqdm import tqdm\n",
    "\n",
    "#os.environ['SPOTIPY_CLIENT_ID'] = 'your client id'\n",
    "#os.environ['SPOTIPY_CLIENT_SECRET' = 'your client secret'\n",
    "\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45175323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Whatever People Say I Am, That's What I'm Not\": 'spotify:album:50Zz8CkIhATKUlQMbHO3k1',\n",
       " 'Favourite Worst Nightmare': 'spotify:album:1XkGORuUX2QGOEIL4EbJKm',\n",
       " 'Favourite Worst Nightmare (Standard Version)': 'spotify:album:6rsQnwaoJHxXJRCDBPkBRw',\n",
       " 'Humbug': 'spotify:album:5IEoiwkThhRmSMBANhpxl2',\n",
       " 'Suck It and See': 'spotify:album:2ym2jcqckXqWeTDoxz3Kst',\n",
       " 'AM': 'spotify:album:78bpIziExqiI9qztvNFlQu',\n",
       " 'Tranquility Base Hotel & Casino': 'spotify:album:7v6FNgLDS8KmaWA1amUtqe',\n",
       " 'Live at the Royal Albert Hall': 'spotify:album:7Heaa0B4KOxdWhSICTR2wE',\n",
       " 'The Car': 'spotify:album:1kqHAucTGT1dJAtNXY8QDW'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Arctic Monkeys'\n",
    "results = spotify.search(q='artist:' + name, type='artist')\n",
    "uri = results['artists']['items'][0]['uri']\n",
    "results = spotify.artist_albums(uri, album_type='album')\n",
    "albums = results['items']\n",
    "\n",
    "albums_dict = {}\n",
    "for i, album in enumerate(albums.__reversed__()):\n",
    "    if album['name'] not in albums_dict.keys():\n",
    "        albums_dict[album['name']] = album['uri']\n",
    "      \n",
    "albums_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da8c80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5eyTC5GZzpzlN7YRO9AoPf': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '3DQVgcqaP3iSMbaKsd57l5': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '7BuzJmV2h6eBbSDdRaDY7C': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '0hAMkY2kwdXPPDfQ1e3BmJ': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '111SaDBbcHW0zedi4RBHDp': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '64a5XZCVDWwvC7gwPPCsH6': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '4wMR4fRKMTyUJG6VAsmccv': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '56GFlp1dkt7dw56pQdTwqW': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '2fyIS6GXMgUcSv4oejx63f': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '6Slvi85s1hIaeykjvDe1xk': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '2zzLRQ78kKfPTx8FJQCdC2': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '2vQQfWTanvD99OeHLAoyhW': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '0eDQj41kzBhMKQIkTt6OJR': \"Whatever People Say I Am, That's What I'm Not\",\n",
       " '7f9I5WdyXm5q1XqnSYgQZb': 'Favourite Worst Nightmare',\n",
       " '5kxVyCgEUND7E2QKG7JmoF': 'Favourite Worst Nightmare',\n",
       " '5RrHzXKmwVd5BCq4UzyJPd': 'Favourite Worst Nightmare',\n",
       " '0ftMOhVfFm5Wbs5sZdEtsC': 'Favourite Worst Nightmare',\n",
       " '2x8evxqUlF0eRabbW2JBJd': 'Favourite Worst Nightmare',\n",
       " '71ytDkCnYc11VRiRCrhDHX': 'Favourite Worst Nightmare',\n",
       " '2BqfIlpahcebJPeu1IUTEo': 'Favourite Worst Nightmare',\n",
       " '0DKvcH4SCRdhVYTxStKx9h': 'Favourite Worst Nightmare',\n",
       " '0idZZsnM7nuSYanlpKTuwV': 'Favourite Worst Nightmare',\n",
       " '4N2yjWLIxZjOXDrCu2VlJe': 'Favourite Worst Nightmare',\n",
       " '5KGbRvZyVyKP2AEJMHErB4': 'Favourite Worst Nightmare',\n",
       " '0BxE4FqsDD1Ot4YuBXwAPp': 'Favourite Worst Nightmare',\n",
       " '5rTIpPWeO0IL4HWlGWrz5G': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '4OkPamOn5GofkOQu64Z4eR': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '45QyGXbqTWaFUrIKe2ugs3': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '11DdPGqDsM3ux1gVAqUIln': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '7e8utCy2JlSB8dRHKi49xM': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '7ABWRukVQcXrIrDKDx5Gek': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '13NCxLOlvQ4Tnexgfp03Gs': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '7gPd55hW5pVjTm3H9S1Wbv': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '0ZUXj43fteJjwvGoLMntte': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '48ucaKjccruxDbi3Au5ZaH': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '3BcQFPRZuuUClWStz29WjN': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '58ge6dfP91o9oXMzq3XkIS': 'Favourite Worst Nightmare (Standard Version)',\n",
       " '2hmHlBM0kPBm17Y7nVIW9f': 'Humbug',\n",
       " '6wVWJl64yoTzU27EI8ep20': 'Humbug',\n",
       " '0pdp3VrR4WQaswf0GyT0Y0': 'Humbug',\n",
       " '4dtP86vkhzwNXCFpCtizce': 'Humbug',\n",
       " '3RHHXwyRtskFx87sX80xEy': 'Humbug',\n",
       " '6EMhO2CuQZ3u7ZKDRuf560': 'Humbug',\n",
       " '5bsnLiT00hG37qd8p2jdVl': 'Humbug',\n",
       " '3u16Clmxz7dJpnQWXXynok': 'Humbug',\n",
       " '45n7uujqwmMyBMjBu9SwRu': 'Humbug',\n",
       " '4PDPn7HosIycoXeoeibFc5': 'Humbug',\n",
       " '5xw2cHVLw1rlDPp3cL9Zuv': 'Suck It and See',\n",
       " '7EUcOIbJSePmXGvAe7G79C': 'Suck It and See',\n",
       " '49HYB8tppaxOsbBfeozPxu': 'Suck It and See',\n",
       " '52M1FvGd0AkoUwcHL2L8jv': 'Suck It and See',\n",
       " '3czdA0j4iaLDJJCoT5D8iP': 'Suck It and See',\n",
       " '0qfGWpvJGlp17wdTm19ioK': 'Suck It and See',\n",
       " '7cRR82VFtvy3FeqIrjEeFy': 'Suck It and See',\n",
       " '1bXLpqe49cqEpj88uPR4pu': 'Suck It and See',\n",
       " '4Ai0ANRDYwx6mCD4Uty1WS': 'Suck It and See',\n",
       " '0S6CXA5LpRDX6b4akgrOot': 'Suck It and See',\n",
       " '0LxeKwg9t7HOnyfv4bTALT': 'Suck It and See',\n",
       " '2fgQ8COnxtEvaTcNbEtsUf': 'Suck It and See',\n",
       " '5FVd6KXrgO9B3JPmC8OPst': 'AM',\n",
       " '2AT8iROs4FQueDv2c8q2KE': 'AM',\n",
       " '6wNUBZNWFxdUGof6vkaykE': 'AM',\n",
       " '7nzsY8vlnKdvGOEE0rjAXZ': 'AM',\n",
       " '1j9rezdE3YeC7yktZXC1em': 'AM',\n",
       " '5TTGoX70AFrTvuEtqHK37S': 'AM',\n",
       " '75n7mraeMycQOl2sDGYaTe': 'AM',\n",
       " '4atMrAadB7dS8xn9vfk9PQ': 'AM',\n",
       " '086myS9r57YsLbJpU0TgK9': 'AM',\n",
       " '0NdTUS4UiNYCNn5FgVqKQY': 'AM',\n",
       " '2LGdO5MtFdyphi2EihANZG': 'AM',\n",
       " '5XeFesFbtLpXzIVDNQP22n': 'AM',\n",
       " '0b93tWwuoAC0nXe1CfR30I': 'Tranquility Base Hotel & Casino',\n",
       " '1t67WYNfUxfOiwaz7SJ66b': 'Tranquility Base Hotel & Casino',\n",
       " '2HbYLDA1SigY1ilC94ieVu': 'Tranquility Base Hotel & Casino',\n",
       " '2URDbWGmPz3vhagl25p8OC': 'Tranquility Base Hotel & Casino',\n",
       " '0U6Vg6RUmzADUO0Y9fVKft': 'Tranquility Base Hotel & Casino',\n",
       " '5Z5nbOXhsSbySVC7WUc6y9': 'Tranquility Base Hotel & Casino',\n",
       " '5rqQTEIVK2PTuXU9GI2wT0': 'Tranquility Base Hotel & Casino',\n",
       " '6hkfgHhYXyDVYahUOZhGRd': 'Tranquility Base Hotel & Casino',\n",
       " '60T4FDF1tTcFlXkI08FFhL': 'Tranquility Base Hotel & Casino',\n",
       " '7aiKdAM9WYW3GzWSA9OXIl': 'Tranquility Base Hotel & Casino',\n",
       " '3PhbzvTllkq1rkULafc6ns': 'Tranquility Base Hotel & Casino',\n",
       " '5dthj0uH1DJAbxC6B9n4Co': 'Live at the Royal Albert Hall',\n",
       " '1RJxGCTCROHUFVWMFOWPYM': 'Live at the Royal Albert Hall',\n",
       " '38mecB29TH0gTqIxhM4OK1': 'Live at the Royal Albert Hall',\n",
       " '5zDoSmh06F7kjXGIHFhQzh': 'Live at the Royal Albert Hall',\n",
       " '1VUcb7Ik5bYw0SzXBH9rLr': 'Live at the Royal Albert Hall',\n",
       " '4Q2vbGXSU28xWveWKp4wra': 'Live at the Royal Albert Hall',\n",
       " '4hZlP9bciuyeBMxPqYHR1C': 'Live at the Royal Albert Hall',\n",
       " '3d7DrmuuKPkJxvCX7G7pOZ': 'Live at the Royal Albert Hall',\n",
       " '5F3cEp3T5zbvWtBsp2FVzp': 'Live at the Royal Albert Hall',\n",
       " '5yJKvGzNSgxbyAGmOrIF3t': 'Live at the Royal Albert Hall',\n",
       " '29kEMCLEdzXhZgOngvUrPY': 'Live at the Royal Albert Hall',\n",
       " '1ll6X7gXZtDL4G0eOqfCjQ': 'Live at the Royal Albert Hall',\n",
       " '09NwfVvbphzx8H2VHskQAD': 'Live at the Royal Albert Hall',\n",
       " '3JcVulhVMfRmEpWmbEVqkk': 'Live at the Royal Albert Hall',\n",
       " '1SaOPXYjSahmVwFSGlCXNI': 'Live at the Royal Albert Hall',\n",
       " '1peQof7MvOPkX8ZRWEWKjp': 'Live at the Royal Albert Hall',\n",
       " '4YS0QKXLqqSM3MxlWej009': 'Live at the Royal Albert Hall',\n",
       " '24RoLuJnqJiqzlSIbqVCoG': 'Live at the Royal Albert Hall',\n",
       " '6yZMhEmlZDbsH5ayXo0zaO': 'Live at the Royal Albert Hall',\n",
       " '30a6L5cAZgVbqA3QfO0RS5': 'Live at the Royal Albert Hall',\n",
       " '4cVsyYAbxGcTIdLoooHTRC': 'The Car',\n",
       " '2oga4f4xl2JGsLWiLSF6Nc': 'The Car',\n",
       " '77mMSHbgFDTnVJ4xPIYUwo': 'The Car',\n",
       " '6WoYIBgGZTI5vkfUaoVdhS': 'The Car',\n",
       " '4Y9M5mNB71lX6RSpIu5Dk6': 'The Car',\n",
       " '7yzr3fhBxJRHt6M24m1gKg': 'The Car',\n",
       " '32LmcNM8fk7p7OznN6y6ZH': 'The Car',\n",
       " '3iNeb273j5psVhQy8rZReg': 'The Car',\n",
       " '7yviviXNt3Ia5MKADOIVE1': 'The Car',\n",
       " '2gYlET3zymQlXc3NSNgPGG': 'The Car'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_dict = {}\n",
    "for key in albums_dict:\n",
    "    for track in spotify.album_tracks(albums_dict[key])['items']:\n",
    "        tracks_dict[track['id']] = key\n",
    "        \n",
    "tracks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9daf5e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type the name of any track: love on the rocks\n",
      "\n",
      "First result is \"Love On The Rocks - From \"The Jazz Singer\" Soundtrack\" by \"Neil Diamond\". The ID is: 6XNGIaXv2xljDcxQ99p65f\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now we need the ID of some track just to retrieve the available parameters list.\n",
    "'''\n",
    "\n",
    "track_name = input('Type the name of any track: ')\n",
    "\n",
    "try:\n",
    "    results = spotify.search(q='track:' + track_name, type='track')\n",
    "    items = results['tracks']['items']\n",
    "    track_id = items[0]['id']\n",
    "except:\n",
    "    raise Exception('Could not find any track with this name. Try again!')\n",
    "\n",
    "print(f'''\\nFirst result is \"{items[0]['name']}\" by \"{items[0]['artists'][0]['name']}\". The ID is: {track_id}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b66a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danceability',\n",
       " 'energy',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'acousticness',\n",
       " 'instrumentalness',\n",
       " 'liveness',\n",
       " 'valence',\n",
       " 'tempo',\n",
       " 'type',\n",
       " 'id',\n",
       " 'uri',\n",
       " 'track_href',\n",
       " 'analysis_url',\n",
       " 'duration_ms',\n",
       " 'time_signature']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = list(spotify.audio_features(tracks=track_id)[0].keys())\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cff99ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danceability',\n",
       " 'energy',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'acousticness',\n",
       " 'instrumentalness',\n",
       " 'liveness',\n",
       " 'valence',\n",
       " 'tempo',\n",
       " 'duration_ms',\n",
       " 'time_signature']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwanted = ['type','id','uri','track_href','analysis_url']\n",
    "parameters = [parameter for parameter in parameters if parameter not in unwanted]\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7905c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 112/112 [00:25<00:00,  4.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.387,\n",
       "  'energy': 0.922,\n",
       "  'key': 9,\n",
       "  'loudness': -5.192,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0674,\n",
       "  'acousticness': 0.00487,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.187,\n",
       "  'valence': 0.417,\n",
       "  'tempo': 146.478,\n",
       "  'duration_ms': 222947,\n",
       "  'time_signature': 4},\n",
       " 1: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.535,\n",
       "  'energy': 0.948,\n",
       "  'key': 6,\n",
       "  'loudness': -4.19,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0356,\n",
       "  'acousticness': 0.00225,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.376,\n",
       "  'valence': 0.778,\n",
       "  'tempo': 103.183,\n",
       "  'duration_ms': 173680,\n",
       "  'time_signature': 4},\n",
       " 2: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.454,\n",
       "  'energy': 0.778,\n",
       "  'key': 9,\n",
       "  'loudness': -4.225,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0449,\n",
       "  'acousticness': 0.00998,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.0427,\n",
       "  'valence': 0.704,\n",
       "  'tempo': 127.158,\n",
       "  'duration_ms': 177947,\n",
       "  'time_signature': 4},\n",
       " 3: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.522,\n",
       "  'energy': 0.889,\n",
       "  'key': 1,\n",
       "  'loudness': -4.137,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0461,\n",
       "  'acousticness': 0.00328,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.345,\n",
       "  'valence': 0.852,\n",
       "  'tempo': 144.499,\n",
       "  'duration_ms': 141133,\n",
       "  'time_signature': 4},\n",
       " 4: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.58,\n",
       "  'energy': 0.972,\n",
       "  'key': 11,\n",
       "  'loudness': -4.274,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0589,\n",
       "  'acousticness': 0.00384,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.296,\n",
       "  'valence': 0.926,\n",
       "  'tempo': 105.492,\n",
       "  'duration_ms': 130813,\n",
       "  'time_signature': 4},\n",
       " 5: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.599,\n",
       "  'energy': 0.946,\n",
       "  'key': 8,\n",
       "  'loudness': -4.192,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0378,\n",
       "  'acousticness': 0.000669,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.0973,\n",
       "  'valence': 0.653,\n",
       "  'tempo': 108.934,\n",
       "  'duration_ms': 173667,\n",
       "  'time_signature': 4},\n",
       " 6: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.593,\n",
       "  'energy': 0.333,\n",
       "  'key': 9,\n",
       "  'loudness': -14.342,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.046,\n",
       "  'acousticness': 0.358,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.245,\n",
       "  'valence': 0.258,\n",
       "  'tempo': 103.537,\n",
       "  'duration_ms': 134933,\n",
       "  'time_signature': 4},\n",
       " 7: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.622,\n",
       "  'energy': 0.846,\n",
       "  'key': 11,\n",
       "  'loudness': -4.831,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0311,\n",
       "  'acousticness': 0.00316,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.0989,\n",
       "  'valence': 0.914,\n",
       "  'tempo': 110.683,\n",
       "  'duration_ms': 143627,\n",
       "  'time_signature': 4},\n",
       " 8: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.634,\n",
       "  'energy': 0.599,\n",
       "  'key': 2,\n",
       "  'loudness': -5.447,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0365,\n",
       "  'acousticness': 0.0288,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.197,\n",
       "  'valence': 0.312,\n",
       "  'tempo': 112.215,\n",
       "  'duration_ms': 175440,\n",
       "  'time_signature': 4},\n",
       " 9: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.371,\n",
       "  'energy': 0.914,\n",
       "  'key': 11,\n",
       "  'loudness': -4.917,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.081,\n",
       "  'acousticness': 0.000293,\n",
       "  'instrumentalness': 8.75e-05,\n",
       "  'liveness': 0.0852,\n",
       "  'valence': 0.394,\n",
       "  'tempo': 134.982,\n",
       "  'duration_ms': 268627,\n",
       "  'time_signature': 4},\n",
       " 10: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.348,\n",
       "  'energy': 0.875,\n",
       "  'key': 11,\n",
       "  'loudness': -4.758,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.199,\n",
       "  'acousticness': 0.0341,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.117,\n",
       "  'valence': 0.407,\n",
       "  'tempo': 169.152,\n",
       "  'duration_ms': 202133,\n",
       "  'time_signature': 4},\n",
       " 11: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.216,\n",
       "  'energy': 0.882,\n",
       "  'key': 11,\n",
       "  'loudness': -5.176,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0439,\n",
       "  'acousticness': 0.00147,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.308,\n",
       "  'valence': 0.656,\n",
       "  'tempo': 189.286,\n",
       "  'duration_ms': 193427,\n",
       "  'time_signature': 4},\n",
       " 12: {'album': \"Whatever People Say I Am, That's What I'm Not\",\n",
       "  'danceability': 0.455,\n",
       "  'energy': 0.881,\n",
       "  'key': 11,\n",
       "  'loudness': -5.587,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0401,\n",
       "  'acousticness': 0.000566,\n",
       "  'instrumentalness': 6.06e-05,\n",
       "  'liveness': 0.11,\n",
       "  'valence': 0.201,\n",
       "  'tempo': 137.949,\n",
       "  'duration_ms': 331200,\n",
       "  'time_signature': 4},\n",
       " 13: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.42,\n",
       "  'energy': 0.974,\n",
       "  'key': 1,\n",
       "  'loudness': -4.706,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.191,\n",
       "  'acousticness': 8.15e-05,\n",
       "  'instrumentalness': 0.00155,\n",
       "  'liveness': 0.0871,\n",
       "  'valence': 0.463,\n",
       "  'tempo': 165.182,\n",
       "  'duration_ms': 172867,\n",
       "  'time_signature': 4},\n",
       " 14: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.637,\n",
       "  'energy': 0.963,\n",
       "  'key': 9,\n",
       "  'loudness': -5.116,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0882,\n",
       "  'acousticness': 0.000286,\n",
       "  'instrumentalness': 0.000889,\n",
       "  'liveness': 0.0449,\n",
       "  'valence': 0.823,\n",
       "  'tempo': 150.1,\n",
       "  'duration_ms': 165000,\n",
       "  'time_signature': 4},\n",
       " 15: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.555,\n",
       "  'energy': 0.925,\n",
       "  'key': 1,\n",
       "  'loudness': -4.689,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0362,\n",
       "  'acousticness': 1.09e-05,\n",
       "  'instrumentalness': 0.000161,\n",
       "  'liveness': 0.0659,\n",
       "  'valence': 0.77,\n",
       "  'tempo': 145.061,\n",
       "  'duration_ms': 138107,\n",
       "  'time_signature': 4},\n",
       " 16: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.414,\n",
       "  'energy': 0.811,\n",
       "  'key': 11,\n",
       "  'loudness': -4.4,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0919,\n",
       "  'acousticness': 0.00133,\n",
       "  'instrumentalness': 0.000129,\n",
       "  'liveness': 0.333,\n",
       "  'valence': 0.762,\n",
       "  'tempo': 137.617,\n",
       "  'duration_ms': 171227,\n",
       "  'time_signature': 4},\n",
       " 17: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.654,\n",
       "  'energy': 0.828,\n",
       "  'key': 1,\n",
       "  'loudness': -5.377,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0281,\n",
       "  'acousticness': 0.00146,\n",
       "  'instrumentalness': 0.000144,\n",
       "  'liveness': 0.122,\n",
       "  'valence': 0.79,\n",
       "  'tempo': 112.056,\n",
       "  'duration_ms': 183893,\n",
       "  'time_signature': 4},\n",
       " 18: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.29,\n",
       "  'energy': 0.399,\n",
       "  'key': 7,\n",
       "  'loudness': -10.696,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0338,\n",
       "  'acousticness': 0.902,\n",
       "  'instrumentalness': 0.0019,\n",
       "  'liveness': 0.105,\n",
       "  'valence': 0.0965,\n",
       "  'tempo': 128.37,\n",
       "  'duration_ms': 184760,\n",
       "  'time_signature': 5},\n",
       " 19: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.469,\n",
       "  'energy': 0.738,\n",
       "  'key': 11,\n",
       "  'loudness': -6.638,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0619,\n",
       "  'acousticness': 0.00013,\n",
       "  'instrumentalness': 0.0577,\n",
       "  'liveness': 0.078,\n",
       "  'valence': 0.624,\n",
       "  'tempo': 180.15,\n",
       "  'duration_ms': 209253,\n",
       "  'time_signature': 4},\n",
       " 20: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.476,\n",
       "  'energy': 0.844,\n",
       "  'key': 7,\n",
       "  'loudness': -5.253,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0431,\n",
       "  'acousticness': 1.81e-05,\n",
       "  'instrumentalness': 0.00196,\n",
       "  'liveness': 0.272,\n",
       "  'valence': 0.658,\n",
       "  'tempo': 155.322,\n",
       "  'duration_ms': 191680,\n",
       "  'time_signature': 4},\n",
       " 21: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.328,\n",
       "  'energy': 0.805,\n",
       "  'key': 4,\n",
       "  'loudness': -6.74,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0383,\n",
       "  'acousticness': 0.000938,\n",
       "  'instrumentalness': 0.048,\n",
       "  'liveness': 0.104,\n",
       "  'valence': 0.264,\n",
       "  'tempo': 135.546,\n",
       "  'duration_ms': 276200,\n",
       "  'time_signature': 4},\n",
       " 22: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.55,\n",
       "  'energy': 0.952,\n",
       "  'key': 2,\n",
       "  'loudness': -3.638,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.075,\n",
       "  'acousticness': 0.00103,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.257,\n",
       "  'valence': 0.538,\n",
       "  'tempo': 111.066,\n",
       "  'duration_ms': 145213,\n",
       "  'time_signature': 4},\n",
       " 23: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.66,\n",
       "  'energy': 0.837,\n",
       "  'key': 0,\n",
       "  'loudness': -4.315,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0682,\n",
       "  'acousticness': 0.000147,\n",
       "  'instrumentalness': 6.62e-06,\n",
       "  'liveness': 0.0788,\n",
       "  'valence': 0.757,\n",
       "  'tempo': 135.158,\n",
       "  'duration_ms': 193227,\n",
       "  'time_signature': 4},\n",
       " 24: {'album': 'Favourite Worst Nightmare',\n",
       "  'danceability': 0.526,\n",
       "  'energy': 0.866,\n",
       "  'key': 0,\n",
       "  'loudness': -5.822,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0568,\n",
       "  'acousticness': 0.00287,\n",
       "  'instrumentalness': 7.78e-05,\n",
       "  'liveness': 0.0945,\n",
       "  'valence': 0.248,\n",
       "  'tempo': 140.266,\n",
       "  'duration_ms': 253587,\n",
       "  'time_signature': 4},\n",
       " 25: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.421,\n",
       "  'energy': 0.98,\n",
       "  'key': 1,\n",
       "  'loudness': -4.229,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.212,\n",
       "  'acousticness': 8.39e-05,\n",
       "  'instrumentalness': 0.00125,\n",
       "  'liveness': 0.237,\n",
       "  'valence': 0.435,\n",
       "  'tempo': 165.193,\n",
       "  'duration_ms': 170253,\n",
       "  'time_signature': 4},\n",
       " 26: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.637,\n",
       "  'energy': 0.973,\n",
       "  'key': 9,\n",
       "  'loudness': -3.386,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.112,\n",
       "  'acousticness': 0.000413,\n",
       "  'instrumentalness': 2.23e-05,\n",
       "  'liveness': 0.104,\n",
       "  'valence': 0.8,\n",
       "  'tempo': 150.223,\n",
       "  'duration_ms': 160640,\n",
       "  'time_signature': 4},\n",
       " 27: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.551,\n",
       "  'energy': 0.928,\n",
       "  'key': 1,\n",
       "  'loudness': -4.776,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0365,\n",
       "  'acousticness': 1.05e-05,\n",
       "  'instrumentalness': 0.000108,\n",
       "  'liveness': 0.145,\n",
       "  'valence': 0.736,\n",
       "  'tempo': 145.057,\n",
       "  'duration_ms': 134733,\n",
       "  'time_signature': 4},\n",
       " 28: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.417,\n",
       "  'energy': 0.824,\n",
       "  'key': 11,\n",
       "  'loudness': -4.524,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.105,\n",
       "  'acousticness': 0.00168,\n",
       "  'instrumentalness': 8.09e-05,\n",
       "  'liveness': 0.343,\n",
       "  'valence': 0.642,\n",
       "  'tempo': 137.836,\n",
       "  'duration_ms': 167440,\n",
       "  'time_signature': 4},\n",
       " 29: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.646,\n",
       "  'energy': 0.813,\n",
       "  'key': 6,\n",
       "  'loudness': -5.29,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0288,\n",
       "  'acousticness': 0.00178,\n",
       "  'instrumentalness': 2.26e-05,\n",
       "  'liveness': 0.144,\n",
       "  'valence': 0.821,\n",
       "  'tempo': 112.115,\n",
       "  'duration_ms': 173493,\n",
       "  'time_signature': 4},\n",
       " 30: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.257,\n",
       "  'energy': 0.409,\n",
       "  'key': 7,\n",
       "  'loudness': -10.828,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0363,\n",
       "  'acousticness': 0.899,\n",
       "  'instrumentalness': 0.00293,\n",
       "  'liveness': 0.109,\n",
       "  'valence': 0.0794,\n",
       "  'tempo': 145.759,\n",
       "  'duration_ms': 181480,\n",
       "  'time_signature': 5},\n",
       " 31: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.471,\n",
       "  'energy': 0.735,\n",
       "  'key': 11,\n",
       "  'loudness': -6.685,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0582,\n",
       "  'acousticness': 7.84e-05,\n",
       "  'instrumentalness': 0.122,\n",
       "  'liveness': 0.101,\n",
       "  'valence': 0.636,\n",
       "  'tempo': 180.127,\n",
       "  'duration_ms': 205240,\n",
       "  'time_signature': 4},\n",
       " 32: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.472,\n",
       "  'energy': 0.909,\n",
       "  'key': 7,\n",
       "  'loudness': -5.349,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0584,\n",
       "  'acousticness': 1.95e-05,\n",
       "  'instrumentalness': 0.00277,\n",
       "  'liveness': 0.644,\n",
       "  'valence': 0.388,\n",
       "  'tempo': 155.311,\n",
       "  'duration_ms': 189680,\n",
       "  'time_signature': 4},\n",
       " 33: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.232,\n",
       "  'energy': 0.8,\n",
       "  'key': 4,\n",
       "  'loudness': -6.853,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0536,\n",
       "  'acousticness': 0.00082,\n",
       "  'instrumentalness': 0.0244,\n",
       "  'liveness': 0.128,\n",
       "  'valence': 0.224,\n",
       "  'tempo': 201.1,\n",
       "  'duration_ms': 274200,\n",
       "  'time_signature': 3},\n",
       " 34: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.545,\n",
       "  'energy': 0.953,\n",
       "  'key': 2,\n",
       "  'loudness': -3.737,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0703,\n",
       "  'acousticness': 0.00118,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.26,\n",
       "  'valence': 0.591,\n",
       "  'tempo': 111.121,\n",
       "  'duration_ms': 143213,\n",
       "  'time_signature': 4},\n",
       " 35: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.663,\n",
       "  'energy': 0.839,\n",
       "  'key': 0,\n",
       "  'loudness': -4.453,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0695,\n",
       "  'acousticness': 0.000185,\n",
       "  'instrumentalness': 4.65e-06,\n",
       "  'liveness': 0.0808,\n",
       "  'valence': 0.75,\n",
       "  'tempo': 135.155,\n",
       "  'duration_ms': 187133,\n",
       "  'time_signature': 4},\n",
       " 36: {'album': 'Favourite Worst Nightmare (Standard Version)',\n",
       "  'danceability': 0.52,\n",
       "  'energy': 0.852,\n",
       "  'key': 0,\n",
       "  'loudness': -5.866,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0543,\n",
       "  'acousticness': 0.00237,\n",
       "  'instrumentalness': 5.79e-05,\n",
       "  'liveness': 0.0733,\n",
       "  'valence': 0.234,\n",
       "  'tempo': 140.267,\n",
       "  'duration_ms': 253587,\n",
       "  'time_signature': 4},\n",
       " 37: {'album': 'Humbug',\n",
       "  'danceability': 0.415,\n",
       "  'energy': 0.657,\n",
       "  'key': 9,\n",
       "  'loudness': -6.758,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0295,\n",
       "  'acousticness': 0.052,\n",
       "  'instrumentalness': 0.0552,\n",
       "  'liveness': 0.233,\n",
       "  'valence': 0.69,\n",
       "  'tempo': 115.752,\n",
       "  'duration_ms': 205747,\n",
       "  'time_signature': 4},\n",
       " 38: {'album': 'Humbug',\n",
       "  'danceability': 0.498,\n",
       "  'energy': 0.885,\n",
       "  'key': 4,\n",
       "  'loudness': -4.423,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0461,\n",
       "  'acousticness': 0.0148,\n",
       "  'instrumentalness': 0.00041,\n",
       "  'liveness': 0.239,\n",
       "  'valence': 0.67,\n",
       "  'tempo': 106.719,\n",
       "  'duration_ms': 224827,\n",
       "  'time_signature': 4},\n",
       " 39: {'album': 'Humbug',\n",
       "  'danceability': 0.34,\n",
       "  'energy': 0.922,\n",
       "  'key': 3,\n",
       "  'loudness': -5.189,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.18,\n",
       "  'acousticness': 0.0129,\n",
       "  'instrumentalness': 2.39e-06,\n",
       "  'liveness': 0.226,\n",
       "  'valence': 0.532,\n",
       "  'tempo': 125.363,\n",
       "  'duration_ms': 210667,\n",
       "  'time_signature': 4},\n",
       " 40: {'album': 'Humbug',\n",
       "  'danceability': 0.323,\n",
       "  'energy': 0.806,\n",
       "  'key': 7,\n",
       "  'loudness': -6.554,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0769,\n",
       "  'acousticness': 0.0314,\n",
       "  'instrumentalness': 1.11e-05,\n",
       "  'liveness': 0.181,\n",
       "  'valence': 0.548,\n",
       "  'tempo': 124.615,\n",
       "  'duration_ms': 223067,\n",
       "  'time_signature': 4},\n",
       " 41: {'album': 'Humbug',\n",
       "  'danceability': 0.421,\n",
       "  'energy': 0.758,\n",
       "  'key': 4,\n",
       "  'loudness': -8.945,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0429,\n",
       "  'acousticness': 0.0062,\n",
       "  'instrumentalness': 0.0673,\n",
       "  'liveness': 0.0905,\n",
       "  'valence': 0.767,\n",
       "  'tempo': 103.659,\n",
       "  'duration_ms': 212133,\n",
       "  'time_signature': 4},\n",
       " 42: {'album': 'Humbug',\n",
       "  'danceability': 0.566,\n",
       "  'energy': 0.61,\n",
       "  'key': 2,\n",
       "  'loudness': -11.228,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0388,\n",
       "  'acousticness': 0.165,\n",
       "  'instrumentalness': 0.006,\n",
       "  'liveness': 0.215,\n",
       "  'valence': 0.406,\n",
       "  'tempo': 114.904,\n",
       "  'duration_ms': 237533,\n",
       "  'time_signature': 4},\n",
       " 43: {'album': 'Humbug',\n",
       "  'danceability': 0.287,\n",
       "  'energy': 0.721,\n",
       "  'key': 9,\n",
       "  'loudness': -5.81,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0387,\n",
       "  'acousticness': 0.00764,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.328,\n",
       "  'valence': 0.763,\n",
       "  'tempo': 169.252,\n",
       "  'duration_ms': 197973,\n",
       "  'time_signature': 4},\n",
       " 44: {'album': 'Humbug',\n",
       "  'danceability': 0.538,\n",
       "  'energy': 0.607,\n",
       "  'key': 1,\n",
       "  'loudness': -9.133,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0352,\n",
       "  'acousticness': 0.0586,\n",
       "  'instrumentalness': 0.769,\n",
       "  'liveness': 0.0975,\n",
       "  'valence': 0.543,\n",
       "  'tempo': 100.158,\n",
       "  'duration_ms': 283493,\n",
       "  'time_signature': 4},\n",
       " 45: {'album': 'Humbug',\n",
       "  'danceability': 0.244,\n",
       "  'energy': 0.896,\n",
       "  'key': 6,\n",
       "  'loudness': -5.576,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.464,\n",
       "  'acousticness': 0.0614,\n",
       "  'instrumentalness': 2.83e-05,\n",
       "  'liveness': 0.127,\n",
       "  'valence': 0.142,\n",
       "  'tempo': 83.354,\n",
       "  'duration_ms': 220507,\n",
       "  'time_signature': 4},\n",
       " 46: {'album': 'Humbug',\n",
       "  'danceability': 0.51,\n",
       "  'energy': 0.8,\n",
       "  'key': 0,\n",
       "  'loudness': -8.116,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0488,\n",
       "  'acousticness': 0.137,\n",
       "  'instrumentalness': 0.0834,\n",
       "  'liveness': 0.118,\n",
       "  'valence': 0.391,\n",
       "  'tempo': 96.935,\n",
       "  'duration_ms': 344053,\n",
       "  'time_signature': 4},\n",
       " 47: {'album': 'Suck It and See',\n",
       "  'danceability': 0.505,\n",
       "  'energy': 0.898,\n",
       "  'key': 7,\n",
       "  'loudness': -4.906,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0329,\n",
       "  'acousticness': 0.000518,\n",
       "  'instrumentalness': 0.00236,\n",
       "  'liveness': 0.173,\n",
       "  'valence': 0.731,\n",
       "  'tempo': 118.929,\n",
       "  'duration_ms': 234920,\n",
       "  'time_signature': 4},\n",
       " 48: {'album': 'Suck It and See',\n",
       "  'danceability': 0.343,\n",
       "  'energy': 0.89,\n",
       "  'key': 7,\n",
       "  'loudness': -5.759,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0655,\n",
       "  'acousticness': 0.000821,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.0912,\n",
       "  'valence': 0.525,\n",
       "  'tempo': 100.061,\n",
       "  'duration_ms': 217440,\n",
       "  'time_signature': 4},\n",
       " 49: {'album': 'Suck It and See',\n",
       "  'danceability': 0.285,\n",
       "  'energy': 0.807,\n",
       "  'key': 2,\n",
       "  'loudness': -4.741,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0528,\n",
       "  'acousticness': 0.00123,\n",
       "  'instrumentalness': 0.00368,\n",
       "  'liveness': 0.317,\n",
       "  'valence': 0.542,\n",
       "  'tempo': 132.206,\n",
       "  'duration_ms': 179907,\n",
       "  'time_signature': 4},\n",
       " 50: {'album': 'Suck It and See',\n",
       "  'danceability': 0.449,\n",
       "  'energy': 0.872,\n",
       "  'key': 11,\n",
       "  'loudness': -4.992,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0507,\n",
       "  'acousticness': 0.000793,\n",
       "  'instrumentalness': 0.00062,\n",
       "  'liveness': 0.0642,\n",
       "  'valence': 0.788,\n",
       "  'tempo': 130.22,\n",
       "  'duration_ms': 180373,\n",
       "  'time_signature': 4},\n",
       " 51: {'album': 'Suck It and See',\n",
       "  'danceability': 0.434,\n",
       "  'energy': 0.912,\n",
       "  'key': 9,\n",
       "  'loudness': -5.148,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0451,\n",
       "  'acousticness': 0.0191,\n",
       "  'instrumentalness': 0.278,\n",
       "  'liveness': 0.326,\n",
       "  'valence': 0.315,\n",
       "  'tempo': 119.729,\n",
       "  'duration_ms': 183507,\n",
       "  'time_signature': 4},\n",
       " 52: {'album': 'Suck It and See',\n",
       "  'danceability': 0.304,\n",
       "  'energy': 0.939,\n",
       "  'key': 1,\n",
       "  'loudness': -5.836,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0549,\n",
       "  'acousticness': 0.000142,\n",
       "  'instrumentalness': 0.00601,\n",
       "  'liveness': 0.136,\n",
       "  'valence': 0.402,\n",
       "  'tempo': 96.954,\n",
       "  'duration_ms': 142173,\n",
       "  'time_signature': 4},\n",
       " 53: {'album': 'Suck It and See',\n",
       "  'danceability': 0.511,\n",
       "  'energy': 0.943,\n",
       "  'key': 2,\n",
       "  'loudness': -4.934,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0537,\n",
       "  'acousticness': 0.00135,\n",
       "  'instrumentalness': 0.0181,\n",
       "  'liveness': 0.187,\n",
       "  'valence': 0.531,\n",
       "  'tempo': 127.283,\n",
       "  'duration_ms': 232280,\n",
       "  'time_signature': 4},\n",
       " 54: {'album': 'Suck It and See',\n",
       "  'danceability': 0.585,\n",
       "  'energy': 0.694,\n",
       "  'key': 2,\n",
       "  'loudness': -6.632,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0392,\n",
       "  'acousticness': 0.00037,\n",
       "  'instrumentalness': 0.0144,\n",
       "  'liveness': 0.0724,\n",
       "  'valence': 0.785,\n",
       "  'tempo': 127.966,\n",
       "  'duration_ms': 162747,\n",
       "  'time_signature': 4},\n",
       " 55: {'album': 'Suck It and See',\n",
       "  'danceability': 0.443,\n",
       "  'energy': 0.865,\n",
       "  'key': 4,\n",
       "  'loudness': -4.547,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0391,\n",
       "  'acousticness': 0.00724,\n",
       "  'instrumentalness': 0.000116,\n",
       "  'liveness': 0.468,\n",
       "  'valence': 0.474,\n",
       "  'tempo': 110.008,\n",
       "  'duration_ms': 203880,\n",
       "  'time_signature': 4},\n",
       " 56: {'album': 'Suck It and See',\n",
       "  'danceability': 0.349,\n",
       "  'energy': 0.662,\n",
       "  'key': 11,\n",
       "  'loudness': -6.873,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0402,\n",
       "  'acousticness': 0.00197,\n",
       "  'instrumentalness': 0.908,\n",
       "  'liveness': 0.136,\n",
       "  'valence': 0.554,\n",
       "  'tempo': 169.926,\n",
       "  'duration_ms': 191427,\n",
       "  'time_signature': 4},\n",
       " 57: {'album': 'Suck It and See',\n",
       "  'danceability': 0.339,\n",
       "  'energy': 0.932,\n",
       "  'key': 4,\n",
       "  'loudness': -5.017,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.057,\n",
       "  'acousticness': 0.00105,\n",
       "  'instrumentalness': 0.114,\n",
       "  'liveness': 0.255,\n",
       "  'valence': 0.586,\n",
       "  'tempo': 128.291,\n",
       "  'duration_ms': 225987,\n",
       "  'time_signature': 4},\n",
       " 58: {'album': 'Suck It and See',\n",
       "  'danceability': 0.481,\n",
       "  'energy': 0.883,\n",
       "  'key': 4,\n",
       "  'loudness': -5.554,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0638,\n",
       "  'acousticness': 0.000679,\n",
       "  'instrumentalness': 0.558,\n",
       "  'liveness': 0.145,\n",
       "  'valence': 0.46,\n",
       "  'tempo': 135.937,\n",
       "  'duration_ms': 256800,\n",
       "  'time_signature': 4},\n",
       " 59: {'album': 'AM',\n",
       "  'danceability': 0.548,\n",
       "  'energy': 0.532,\n",
       "  'key': 5,\n",
       "  'loudness': -7.596,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0323,\n",
       "  'acousticness': 0.186,\n",
       "  'instrumentalness': 0.000263,\n",
       "  'liveness': 0.217,\n",
       "  'valence': 0.405,\n",
       "  'tempo': 85.03,\n",
       "  'duration_ms': 272394,\n",
       "  'time_signature': 4},\n",
       " 60: {'album': 'AM',\n",
       "  'danceability': 0.288,\n",
       "  'energy': 0.758,\n",
       "  'key': 6,\n",
       "  'loudness': -5.692,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0371,\n",
       "  'acousticness': 0.00616,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.303,\n",
       "  'valence': 0.619,\n",
       "  'tempo': 97.094,\n",
       "  'duration_ms': 201726,\n",
       "  'time_signature': 4},\n",
       " 61: {'album': 'AM',\n",
       "  'danceability': 0.415,\n",
       "  'energy': 0.668,\n",
       "  'key': 0,\n",
       "  'loudness': -6.849,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.036,\n",
       "  'acousticness': 0.212,\n",
       "  'instrumentalness': 0.0615,\n",
       "  'liveness': 0.27,\n",
       "  'valence': 0.842,\n",
       "  'tempo': 180.048,\n",
       "  'duration_ms': 206052,\n",
       "  'time_signature': 4},\n",
       " 62: {'album': 'AM',\n",
       "  'danceability': 0.579,\n",
       "  'energy': 0.558,\n",
       "  'key': 2,\n",
       "  'loudness': -6.986,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0895,\n",
       "  'acousticness': 0.0202,\n",
       "  'instrumentalness': 1.26e-06,\n",
       "  'liveness': 0.212,\n",
       "  'valence': 0.506,\n",
       "  'tempo': 179.949,\n",
       "  'duration_ms': 207357,\n",
       "  'time_signature': 4},\n",
       " 63: {'album': 'AM',\n",
       "  'danceability': 0.499,\n",
       "  'energy': 0.81,\n",
       "  'key': 5,\n",
       "  'loudness': -5.579,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0347,\n",
       "  'acousticness': 0.000637,\n",
       "  'instrumentalness': 0.0748,\n",
       "  'liveness': 0.0625,\n",
       "  'valence': 0.288,\n",
       "  'tempo': 131.052,\n",
       "  'duration_ms': 185406,\n",
       "  'time_signature': 4},\n",
       " 64: {'album': 'AM',\n",
       "  'danceability': 0.505,\n",
       "  'energy': 0.698,\n",
       "  'key': 0,\n",
       "  'loudness': -5.563,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0297,\n",
       "  'acousticness': 0.33,\n",
       "  'instrumentalness': 0.0887,\n",
       "  'liveness': 0.0966,\n",
       "  'valence': 0.599,\n",
       "  'tempo': 115.013,\n",
       "  'duration_ms': 243132,\n",
       "  'time_signature': 4},\n",
       " 65: {'album': 'AM',\n",
       "  'danceability': 0.532,\n",
       "  'energy': 0.462,\n",
       "  'key': 10,\n",
       "  'loudness': -10.71,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.03,\n",
       "  'acousticness': 0.279,\n",
       "  'instrumentalness': 0.196,\n",
       "  'liveness': 0.101,\n",
       "  'valence': 0.485,\n",
       "  'tempo': 80.001,\n",
       "  'duration_ms': 215012,\n",
       "  'time_signature': 4},\n",
       " 66: {'album': 'AM',\n",
       "  'danceability': 0.538,\n",
       "  'energy': 0.953,\n",
       "  'key': 9,\n",
       "  'loudness': -5.611,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.056,\n",
       "  'acousticness': 0.0234,\n",
       "  'instrumentalness': 0.00126,\n",
       "  'liveness': 0.113,\n",
       "  'valence': 0.74,\n",
       "  'tempo': 100.033,\n",
       "  'duration_ms': 181049,\n",
       "  'time_signature': 4},\n",
       " 67: {'album': 'AM',\n",
       "  'danceability': 0.691,\n",
       "  'energy': 0.631,\n",
       "  'key': 2,\n",
       "  'loudness': -6.478,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0368,\n",
       "  'acousticness': 0.0483,\n",
       "  'instrumentalness': 1.13e-05,\n",
       "  'liveness': 0.104,\n",
       "  'valence': 0.8,\n",
       "  'tempo': 92.004,\n",
       "  'duration_ms': 161124,\n",
       "  'time_signature': 4},\n",
       " 68: {'album': 'AM',\n",
       "  'danceability': 0.728,\n",
       "  'energy': 0.638,\n",
       "  'key': 5,\n",
       "  'loudness': -6.455,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0336,\n",
       "  'acousticness': 0.249,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.116,\n",
       "  'valence': 0.872,\n",
       "  'tempo': 130.014,\n",
       "  'duration_ms': 193030,\n",
       "  'time_signature': 4},\n",
       " 69: {'album': 'AM',\n",
       "  'danceability': 0.665,\n",
       "  'energy': 0.542,\n",
       "  'key': 11,\n",
       "  'loudness': -8.323,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.033,\n",
       "  'acousticness': 0.123,\n",
       "  'instrumentalness': 0.00291,\n",
       "  'liveness': 0.342,\n",
       "  'valence': 0.587,\n",
       "  'tempo': 97.975,\n",
       "  'duration_ms': 257563,\n",
       "  'time_signature': 4},\n",
       " 70: {'album': 'AM',\n",
       "  'danceability': 0.464,\n",
       "  'energy': 0.417,\n",
       "  'key': 0,\n",
       "  'loudness': -9.345,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0256,\n",
       "  'acousticness': 0.136,\n",
       "  'instrumentalness': 0.022,\n",
       "  'liveness': 0.0974,\n",
       "  'valence': 0.479,\n",
       "  'tempo': 67.528,\n",
       "  'duration_ms': 183956,\n",
       "  'time_signature': 4},\n",
       " 71: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.581,\n",
       "  'energy': 0.767,\n",
       "  'key': 7,\n",
       "  'loudness': -5.026,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0527,\n",
       "  'acousticness': 0.243,\n",
       "  'instrumentalness': 0.00131,\n",
       "  'liveness': 0.141,\n",
       "  'valence': 0.673,\n",
       "  'tempo': 120.07,\n",
       "  'duration_ms': 354640,\n",
       "  'time_signature': 4},\n",
       " 72: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.714,\n",
       "  'energy': 0.585,\n",
       "  'key': 8,\n",
       "  'loudness': -4.57,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0419,\n",
       "  'acousticness': 0.057,\n",
       "  'instrumentalness': 0.00444,\n",
       "  'liveness': 0.144,\n",
       "  'valence': 0.842,\n",
       "  'tempo': 77.104,\n",
       "  'duration_ms': 208640,\n",
       "  'time_signature': 4},\n",
       " 73: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.372,\n",
       "  'energy': 0.865,\n",
       "  'key': 7,\n",
       "  'loudness': -4.288,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0513,\n",
       "  'acousticness': 0.00169,\n",
       "  'instrumentalness': 0.00293,\n",
       "  'liveness': 0.127,\n",
       "  'valence': 0.594,\n",
       "  'tempo': 176.689,\n",
       "  'duration_ms': 158040,\n",
       "  'time_signature': 3},\n",
       " 74: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.584,\n",
       "  'energy': 0.835,\n",
       "  'key': 9,\n",
       "  'loudness': -4.326,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0297,\n",
       "  'acousticness': 0.0411,\n",
       "  'instrumentalness': 0.0147,\n",
       "  'liveness': 0.199,\n",
       "  'valence': 0.781,\n",
       "  'tempo': 142.2,\n",
       "  'duration_ms': 212093,\n",
       "  'time_signature': 4},\n",
       " 75: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.492,\n",
       "  'energy': 0.564,\n",
       "  'key': 2,\n",
       "  'loudness': -5.811,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0278,\n",
       "  'acousticness': 0.129,\n",
       "  'instrumentalness': 1.73e-05,\n",
       "  'liveness': 0.131,\n",
       "  'valence': 0.0896,\n",
       "  'tempo': 92.544,\n",
       "  'duration_ms': 173627,\n",
       "  'time_signature': 4},\n",
       " 76: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.601,\n",
       "  'energy': 0.863,\n",
       "  'key': 0,\n",
       "  'loudness': -4.31,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0685,\n",
       "  'acousticness': 0.0626,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.0717,\n",
       "  'valence': 0.676,\n",
       "  'tempo': 130.189,\n",
       "  'duration_ms': 312347,\n",
       "  'time_signature': 4},\n",
       " 77: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.602,\n",
       "  'energy': 0.601,\n",
       "  'key': 10,\n",
       "  'loudness': -5.742,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0303,\n",
       "  'acousticness': 0.346,\n",
       "  'instrumentalness': 0.349,\n",
       "  'liveness': 0.0735,\n",
       "  'valence': 0.553,\n",
       "  'tempo': 145.075,\n",
       "  'duration_ms': 180013,\n",
       "  'time_signature': 4},\n",
       " 78: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.542,\n",
       "  'energy': 0.766,\n",
       "  'key': 7,\n",
       "  'loudness': -5.411,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0282,\n",
       "  'acousticness': 0.0295,\n",
       "  'instrumentalness': 0.0802,\n",
       "  'liveness': 0.396,\n",
       "  'valence': 0.643,\n",
       "  'tempo': 88.062,\n",
       "  'duration_ms': 185907,\n",
       "  'time_signature': 4},\n",
       " 79: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.514,\n",
       "  'energy': 0.773,\n",
       "  'key': 0,\n",
       "  'loudness': -3.754,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0388,\n",
       "  'acousticness': 0.00944,\n",
       "  'instrumentalness': 0.00326,\n",
       "  'liveness': 0.387,\n",
       "  'valence': 0.445,\n",
       "  'tempo': 103.943,\n",
       "  'duration_ms': 182560,\n",
       "  'time_signature': 4},\n",
       " 80: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.675,\n",
       "  'energy': 0.681,\n",
       "  'key': 5,\n",
       "  'loudness': -5.728,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0356,\n",
       "  'acousticness': 0.312,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.304,\n",
       "  'valence': 0.675,\n",
       "  'tempo': 106.521,\n",
       "  'duration_ms': 271613,\n",
       "  'time_signature': 4},\n",
       " 81: {'album': 'Tranquility Base Hotel & Casino',\n",
       "  'danceability': 0.476,\n",
       "  'energy': 0.555,\n",
       "  'key': 9,\n",
       "  'loudness': -6.551,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0404,\n",
       "  'acousticness': 0.624,\n",
       "  'instrumentalness': 3.98e-05,\n",
       "  'liveness': 0.126,\n",
       "  'valence': 0.426,\n",
       "  'tempo': 131.497,\n",
       "  'duration_ms': 217720,\n",
       "  'time_signature': 3},\n",
       " 82: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.463,\n",
       "  'energy': 0.802,\n",
       "  'key': 9,\n",
       "  'loudness': -7.804,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0711,\n",
       "  'acousticness': 0.0887,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.949,\n",
       "  'valence': 0.451,\n",
       "  'tempo': 129.643,\n",
       "  'duration_ms': 331520,\n",
       "  'time_signature': 4},\n",
       " 83: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.291,\n",
       "  'energy': 0.934,\n",
       "  'key': 0,\n",
       "  'loudness': -8.238,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.17,\n",
       "  'acousticness': 0.0197,\n",
       "  'instrumentalness': 0.000707,\n",
       "  'liveness': 0.833,\n",
       "  'valence': 0.244,\n",
       "  'tempo': 80.602,\n",
       "  'duration_ms': 209907,\n",
       "  'time_signature': 4},\n",
       " 84: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.329,\n",
       "  'energy': 0.867,\n",
       "  'key': 9,\n",
       "  'loudness': -7.588,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.116,\n",
       "  'acousticness': 0.0167,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.442,\n",
       "  'valence': 0.324,\n",
       "  'tempo': 104.671,\n",
       "  'duration_ms': 240707,\n",
       "  'time_signature': 4},\n",
       " 85: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.252,\n",
       "  'energy': 0.77,\n",
       "  'key': 0,\n",
       "  'loudness': -7.925,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0489,\n",
       "  'acousticness': 0.0924,\n",
       "  'instrumentalness': 2.97e-05,\n",
       "  'liveness': 0.688,\n",
       "  'valence': 0.305,\n",
       "  'tempo': 84.366,\n",
       "  'duration_ms': 281093,\n",
       "  'time_signature': 4},\n",
       " 86: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.371,\n",
       "  'energy': 0.811,\n",
       "  'key': 4,\n",
       "  'loudness': -7.591,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0577,\n",
       "  'acousticness': 0.175,\n",
       "  'instrumentalness': 0.00012,\n",
       "  'liveness': 0.722,\n",
       "  'valence': 0.533,\n",
       "  'tempo': 91.691,\n",
       "  'duration_ms': 183680,\n",
       "  'time_signature': 4},\n",
       " 87: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.343,\n",
       "  'energy': 0.724,\n",
       "  'key': 0,\n",
       "  'loudness': -9.384,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0753,\n",
       "  'acousticness': 0.0133,\n",
       "  'instrumentalness': 3.89e-05,\n",
       "  'liveness': 0.325,\n",
       "  'valence': 0.186,\n",
       "  'tempo': 139.451,\n",
       "  'duration_ms': 275733,\n",
       "  'time_signature': 4},\n",
       " 88: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.554,\n",
       "  'energy': 0.643,\n",
       "  'key': 0,\n",
       "  'loudness': -9.395,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0323,\n",
       "  'acousticness': 0.182,\n",
       "  'instrumentalness': 0.0133,\n",
       "  'liveness': 0.236,\n",
       "  'valence': 0.818,\n",
       "  'tempo': 76.985,\n",
       "  'duration_ms': 202707,\n",
       "  'time_signature': 4},\n",
       " 89: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.207,\n",
       "  'energy': 0.837,\n",
       "  'key': 6,\n",
       "  'loudness': -9.093,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.211,\n",
       "  'acousticness': 0.0355,\n",
       "  'instrumentalness': 0.000173,\n",
       "  'liveness': 0.758,\n",
       "  'valence': 0.297,\n",
       "  'tempo': 173.112,\n",
       "  'duration_ms': 239533,\n",
       "  'time_signature': 4},\n",
       " 90: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.368,\n",
       "  'energy': 0.779,\n",
       "  'key': 6,\n",
       "  'loudness': -7.564,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0869,\n",
       "  'acousticness': 0.153,\n",
       "  'instrumentalness': 0.000266,\n",
       "  'liveness': 0.892,\n",
       "  'valence': 0.472,\n",
       "  'tempo': 76.495,\n",
       "  'duration_ms': 221973,\n",
       "  'time_signature': 4},\n",
       " 91: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.556,\n",
       "  'energy': 0.578,\n",
       "  'key': 4,\n",
       "  'loudness': -9.992,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0319,\n",
       "  'acousticness': 0.167,\n",
       "  'instrumentalness': 0.0228,\n",
       "  'liveness': 0.712,\n",
       "  'valence': 0.268,\n",
       "  'tempo': 97.791,\n",
       "  'duration_ms': 350467,\n",
       "  'time_signature': 4},\n",
       " 92: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.391,\n",
       "  'energy': 0.825,\n",
       "  'key': 11,\n",
       "  'loudness': -8.18,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.253,\n",
       "  'acousticness': 0.176,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.704,\n",
       "  'valence': 0.291,\n",
       "  'tempo': 91.389,\n",
       "  'duration_ms': 246973,\n",
       "  'time_signature': 4},\n",
       " 93: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.428,\n",
       "  'energy': 0.75,\n",
       "  'key': 9,\n",
       "  'loudness': -9.14,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0904,\n",
       "  'acousticness': 0.251,\n",
       "  'instrumentalness': 0.00104,\n",
       "  'liveness': 0.705,\n",
       "  'valence': 0.383,\n",
       "  'tempo': 142.657,\n",
       "  'duration_ms': 243240,\n",
       "  'time_signature': 4},\n",
       " 94: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.284,\n",
       "  'energy': 0.635,\n",
       "  'key': 0,\n",
       "  'loudness': -8.476,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0488,\n",
       "  'acousticness': 0.171,\n",
       "  'instrumentalness': 6e-06,\n",
       "  'liveness': 0.756,\n",
       "  'valence': 0.385,\n",
       "  'tempo': 106.295,\n",
       "  'duration_ms': 201773,\n",
       "  'time_signature': 3},\n",
       " 95: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.173,\n",
       "  'energy': 0.918,\n",
       "  'key': 11,\n",
       "  'loudness': -7.598,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.142,\n",
       "  'acousticness': 0.0909,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.957,\n",
       "  'valence': 0.421,\n",
       "  'tempo': 173.821,\n",
       "  'duration_ms': 221947,\n",
       "  'time_signature': 4},\n",
       " 96: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.262,\n",
       "  'energy': 0.905,\n",
       "  'key': 2,\n",
       "  'loudness': -6.681,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0968,\n",
       "  'acousticness': 0.034,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.76,\n",
       "  'valence': 0.274,\n",
       "  'tempo': 109.727,\n",
       "  'duration_ms': 241240,\n",
       "  'time_signature': 3},\n",
       " 97: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.267,\n",
       "  'energy': 0.809,\n",
       "  'key': 2,\n",
       "  'loudness': -8.326,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0678,\n",
       "  'acousticness': 0.0915,\n",
       "  'instrumentalness': 0.00915,\n",
       "  'liveness': 0.891,\n",
       "  'valence': 0.38,\n",
       "  'tempo': 113.656,\n",
       "  'duration_ms': 221253,\n",
       "  'time_signature': 4},\n",
       " 98: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.241,\n",
       "  'energy': 0.968,\n",
       "  'key': 11,\n",
       "  'loudness': -7.381,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.378,\n",
       "  'acousticness': 0.14,\n",
       "  'instrumentalness': 6.46e-06,\n",
       "  'liveness': 0.92,\n",
       "  'valence': 0.0991,\n",
       "  'tempo': 120.412,\n",
       "  'duration_ms': 293520,\n",
       "  'time_signature': 4},\n",
       " 99: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.507,\n",
       "  'energy': 0.703,\n",
       "  'key': 10,\n",
       "  'loudness': -8.529,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0655,\n",
       "  'acousticness': 0.18,\n",
       "  'instrumentalness': 5.84e-06,\n",
       "  'liveness': 0.784,\n",
       "  'valence': 0.51,\n",
       "  'tempo': 120.299,\n",
       "  'duration_ms': 335213,\n",
       "  'time_signature': 4},\n",
       " 100: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.252,\n",
       "  'energy': 0.933,\n",
       "  'key': 2,\n",
       "  'loudness': -7.33,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.244,\n",
       "  'acousticness': 0.0466,\n",
       "  'instrumentalness': 1.09e-06,\n",
       "  'liveness': 0.861,\n",
       "  'valence': 0.187,\n",
       "  'tempo': 145.98,\n",
       "  'duration_ms': 264227,\n",
       "  'time_signature': 4},\n",
       " 101: {'album': 'Live at the Royal Albert Hall',\n",
       "  'danceability': 0.196,\n",
       "  'energy': 0.959,\n",
       "  'key': 11,\n",
       "  'loudness': -6.71,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.15,\n",
       "  'acousticness': 0.132,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.969,\n",
       "  'valence': 0.269,\n",
       "  'tempo': 98.424,\n",
       "  'duration_ms': 371853,\n",
       "  'time_signature': 4},\n",
       " 102: {'album': 'The Car',\n",
       "  'danceability': 0.521,\n",
       "  'energy': 0.365,\n",
       "  'key': 3,\n",
       "  'loudness': -10.914,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0317,\n",
       "  'acousticness': 0.626,\n",
       "  'instrumentalness': 0.012,\n",
       "  'liveness': 0.185,\n",
       "  'valence': 0.324,\n",
       "  'tempo': 143.789,\n",
       "  'duration_ms': 265798,\n",
       "  'time_signature': 4},\n",
       " 103: {'album': 'The Car',\n",
       "  'danceability': 0.544,\n",
       "  'energy': 0.337,\n",
       "  'key': 10,\n",
       "  'loudness': -9.846,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0653,\n",
       "  'acousticness': 0.357,\n",
       "  'instrumentalness': 6.34e-05,\n",
       "  'liveness': 0.085,\n",
       "  'valence': 0.667,\n",
       "  'tempo': 192.685,\n",
       "  'duration_ms': 191174,\n",
       "  'time_signature': 4},\n",
       " 104: {'album': 'The Car',\n",
       "  'danceability': 0.591,\n",
       "  'energy': 0.309,\n",
       "  'key': 4,\n",
       "  'loudness': -11.087,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0287,\n",
       "  'acousticness': 0.704,\n",
       "  'instrumentalness': 0.0122,\n",
       "  'liveness': 0.102,\n",
       "  'valence': 0.257,\n",
       "  'tempo': 71.573,\n",
       "  'duration_ms': 239151,\n",
       "  'time_signature': 4},\n",
       " 105: {'album': 'The Car',\n",
       "  'danceability': 0.651,\n",
       "  'energy': 0.244,\n",
       "  'key': 7,\n",
       "  'loudness': -11.925,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0544,\n",
       "  'acousticness': 0.856,\n",
       "  'instrumentalness': 0.00165,\n",
       "  'liveness': 0.0895,\n",
       "  'valence': 0.395,\n",
       "  'tempo': 149.759,\n",
       "  'duration_ms': 197576,\n",
       "  'time_signature': 3},\n",
       " 106: {'album': 'The Car',\n",
       "  'danceability': 0.556,\n",
       "  'energy': 0.315,\n",
       "  'key': 7,\n",
       "  'loudness': -11.651,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0625,\n",
       "  'acousticness': 0.568,\n",
       "  'instrumentalness': 0,\n",
       "  'liveness': 0.0774,\n",
       "  'valence': 0.256,\n",
       "  'tempo': 143.327,\n",
       "  'duration_ms': 290584,\n",
       "  'time_signature': 4},\n",
       " 107: {'album': 'The Car',\n",
       "  'danceability': 0.428,\n",
       "  'energy': 0.365,\n",
       "  'key': 4,\n",
       "  'loudness': -11.889,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0276,\n",
       "  'acousticness': 0.78,\n",
       "  'instrumentalness': 0.0033,\n",
       "  'liveness': 0.113,\n",
       "  'valence': 0.236,\n",
       "  'tempo': 94.033,\n",
       "  'duration_ms': 198554,\n",
       "  'time_signature': 3},\n",
       " 108: {'album': 'The Car',\n",
       "  'danceability': 0.548,\n",
       "  'energy': 0.328,\n",
       "  'key': 9,\n",
       "  'loudness': -9.973,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0296,\n",
       "  'acousticness': 0.663,\n",
       "  'instrumentalness': 0.00365,\n",
       "  'liveness': 0.0972,\n",
       "  'valence': 0.343,\n",
       "  'tempo': 67.023,\n",
       "  'duration_ms': 237984,\n",
       "  'time_signature': 3},\n",
       " 109: {'album': 'The Car',\n",
       "  'danceability': 0.394,\n",
       "  'energy': 0.452,\n",
       "  'key': 4,\n",
       "  'loudness': -9.923,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0321,\n",
       "  'acousticness': 0.276,\n",
       "  'instrumentalness': 0.00998,\n",
       "  'liveness': 0.193,\n",
       "  'valence': 0.653,\n",
       "  'tempo': 169.298,\n",
       "  'duration_ms': 244932,\n",
       "  'time_signature': 4},\n",
       " 110: {'album': 'The Car',\n",
       "  'danceability': 0.569,\n",
       "  'energy': 0.335,\n",
       "  'key': 11,\n",
       "  'loudness': -13.637,\n",
       "  'mode': 0,\n",
       "  'speechiness': 0.0322,\n",
       "  'acousticness': 0.802,\n",
       "  'instrumentalness': 0.018,\n",
       "  'liveness': 0.0834,\n",
       "  'valence': 0.388,\n",
       "  'tempo': 127.587,\n",
       "  'duration_ms': 210012,\n",
       "  'time_signature': 4},\n",
       " 111: {'album': 'The Car',\n",
       "  'danceability': 0.52,\n",
       "  'energy': 0.478,\n",
       "  'key': 4,\n",
       "  'loudness': -10.862,\n",
       "  'mode': 1,\n",
       "  'speechiness': 0.0276,\n",
       "  'acousticness': 0.61,\n",
       "  'instrumentalness': 0.00122,\n",
       "  'liveness': 0.105,\n",
       "  'valence': 0.545,\n",
       "  'tempo': 82.932,\n",
       "  'duration_ms': 167380,\n",
       "  'time_signature': 4}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {}\n",
    "for j, key in enumerate(tqdm(tracks_dict)):\n",
    "    features_dict[j] = {}\n",
    "    features_dict[j]['album'] = tracks_dict[key]\n",
    "    track_features = spotify.audio_features(tracks=key)[0]\n",
    "    for parameter in parameters:\n",
    "        features_dict[j][parameter] = track_features[parameter]\n",
    "\n",
    "\n",
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f404acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.365</td>\n",
       "      <td>4</td>\n",
       "      <td>-11.889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.236</td>\n",
       "      <td>94.033</td>\n",
       "      <td>198554</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.328</td>\n",
       "      <td>9</td>\n",
       "      <td>-9.973</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.00365</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.343</td>\n",
       "      <td>67.023</td>\n",
       "      <td>237984</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.452</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.923</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.00998</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.653</td>\n",
       "      <td>169.298</td>\n",
       "      <td>244932</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.335</td>\n",
       "      <td>11</td>\n",
       "      <td>-13.637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.388</td>\n",
       "      <td>127.587</td>\n",
       "      <td>210012</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.478</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.545</td>\n",
       "      <td>82.932</td>\n",
       "      <td>167380</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       album danceability energy key loudness mode speechiness acousticness  \\\n",
       "107  The Car        0.428  0.365   4  -11.889    0      0.0276         0.78   \n",
       "108  The Car        0.548  0.328   9   -9.973    0      0.0296        0.663   \n",
       "109  The Car        0.394  0.452   4   -9.923    0      0.0321        0.276   \n",
       "110  The Car        0.569  0.335  11  -13.637    0      0.0322        0.802   \n",
       "111  The Car         0.52  0.478   4  -10.862    1      0.0276         0.61   \n",
       "\n",
       "    instrumentalness liveness valence    tempo duration_ms time_signature  \n",
       "107           0.0033    0.113   0.236   94.033      198554              3  \n",
       "108          0.00365   0.0972   0.343   67.023      237984              3  \n",
       "109          0.00998    0.193   0.653  169.298      244932              4  \n",
       "110            0.018   0.0834   0.388  127.587      210012              4  \n",
       "111          0.00122    0.105   0.545   82.932      167380              4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(features_dict).T\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dc8fed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>...</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "      <th>mode_0</th>\n",
       "      <th>mode_1</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whatever People Say I Am, That's What I'm Not</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.922</td>\n",
       "      <td>-5.192</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>0.00487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.417</td>\n",
       "      <td>146.478</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whatever People Say I Am, That's What I'm Not</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.948</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.778</td>\n",
       "      <td>103.183</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whatever People Say I Am, That's What I'm Not</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.778</td>\n",
       "      <td>-4.225</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.00998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.704</td>\n",
       "      <td>127.158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whatever People Say I Am, That's What I'm Not</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.889</td>\n",
       "      <td>-4.137</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.00328</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.852</td>\n",
       "      <td>144.499</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whatever People Say I Am, That's What I'm Not</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.972</td>\n",
       "      <td>-4.274</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.00384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.926</td>\n",
       "      <td>105.492</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-11.889</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.236</td>\n",
       "      <td>94.033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-9.973</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.00365</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.343</td>\n",
       "      <td>67.023</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-9.923</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.00998</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.653</td>\n",
       "      <td>169.298</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-13.637</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.388</td>\n",
       "      <td>127.587</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>The Car</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.478</td>\n",
       "      <td>-10.862</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.545</td>\n",
       "      <td>82.932</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             album danceability energy  \\\n",
       "0    Whatever People Say I Am, That's What I'm Not        0.387  0.922   \n",
       "1    Whatever People Say I Am, That's What I'm Not        0.535  0.948   \n",
       "2    Whatever People Say I Am, That's What I'm Not        0.454  0.778   \n",
       "3    Whatever People Say I Am, That's What I'm Not        0.522  0.889   \n",
       "4    Whatever People Say I Am, That's What I'm Not         0.58  0.972   \n",
       "..                                             ...          ...    ...   \n",
       "107                                        The Car        0.428  0.365   \n",
       "108                                        The Car        0.548  0.328   \n",
       "109                                        The Car        0.394  0.452   \n",
       "110                                        The Car        0.569  0.335   \n",
       "111                                        The Car         0.52  0.478   \n",
       "\n",
       "    loudness speechiness acousticness instrumentalness liveness valence  \\\n",
       "0     -5.192      0.0674      0.00487                0    0.187   0.417   \n",
       "1      -4.19      0.0356      0.00225                0    0.376   0.778   \n",
       "2     -4.225      0.0449      0.00998                0   0.0427   0.704   \n",
       "3     -4.137      0.0461      0.00328                0    0.345   0.852   \n",
       "4     -4.274      0.0589      0.00384                0    0.296   0.926   \n",
       "..       ...         ...          ...              ...      ...     ...   \n",
       "107  -11.889      0.0276         0.78           0.0033    0.113   0.236   \n",
       "108   -9.973      0.0296        0.663          0.00365   0.0972   0.343   \n",
       "109   -9.923      0.0321        0.276          0.00998    0.193   0.653   \n",
       "110  -13.637      0.0322        0.802            0.018   0.0834   0.388   \n",
       "111  -10.862      0.0276         0.61          0.00122    0.105   0.545   \n",
       "\n",
       "       tempo  ... key_7  key_8  key_9  key_10  key_11  mode_0  mode_1  \\\n",
       "0    146.478  ...     0      0      1       0       0       1       0   \n",
       "1    103.183  ...     0      0      0       0       0       1       0   \n",
       "2    127.158  ...     0      0      1       0       0       0       1   \n",
       "3    144.499  ...     0      0      0       0       0       0       1   \n",
       "4    105.492  ...     0      0      0       0       1       1       0   \n",
       "..       ...  ...   ...    ...    ...     ...     ...     ...     ...   \n",
       "107   94.033  ...     0      0      0       0       0       1       0   \n",
       "108   67.023  ...     0      0      1       0       0       1       0   \n",
       "109  169.298  ...     0      0      0       0       0       1       0   \n",
       "110  127.587  ...     0      0      0       0       1       1       0   \n",
       "111   82.932  ...     0      0      0       0       0       0       1   \n",
       "\n",
       "     time_signature_3  time_signature_4  time_signature_5  \n",
       "0                   0                 1                 0  \n",
       "1                   0                 1                 0  \n",
       "2                   0                 1                 0  \n",
       "3                   0                 1                 0  \n",
       "4                   0                 1                 0  \n",
       "..                ...               ...               ...  \n",
       "107                 1                 0                 0  \n",
       "108                 1                 0                 0  \n",
       "109                 0                 1                 0  \n",
       "110                 0                 1                 0  \n",
       "111                 0                 1                 0  \n",
       "\n",
       "[112 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "for feature in categorical_features:\n",
    "    dummies = pd.get_dummies(df[feature], prefix=feature)\n",
    "    df = pd.concat([df.drop([feature], axis=1), dummies], axis=1)   \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad57f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Whatever People Say I Am, That's What I'm Not\",\n",
       "       'Favourite Worst Nightmare',\n",
       "       'Favourite Worst Nightmare (Standard Version)', 'Humbug',\n",
       "       'Suck It and See', 'AM', 'Tranquility Base Hotel & Casino',\n",
       "       'Live at the Royal Albert Hall', 'The Car'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['album'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2450f7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Whatever People Say I Am, That's What I'm Not\",\n",
       "       'Favourite Worst Nightmare', 'Humbug', 'Suck It and See', 'AM',\n",
       "       'Tranquility Base Hotel & Casino', 'The Car'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwanted_albums = ['Favourite Worst Nightmare (Standard Version)', 'Live at the Royal Albert Hall']\n",
    "\n",
    "for unwanted_album in unwanted_albums:\n",
    "    df.drop(df[df['album'] == unwanted_album].index, inplace=True)\n",
    "    \n",
    "df['album'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "860f1d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['album', 'danceability', 'energy', 'loudness', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'duration_ms', 'key_0', 'key_1', 'key_2', 'key_3', 'key_4', 'key_5',\n",
       "       'key_6', 'key_7', 'key_8', 'key_9', 'key_10', 'key_11', 'mode_0',\n",
       "       'mode_1', 'time_signature_3', 'time_signature_4', 'time_signature_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98426513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67658256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "627cd047",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:]\n",
    "scaler_X = StandardScaler()\n",
    "scaler = scaler_X.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "X_scaled = pd.DataFrame(columns=X.columns,data=X_scaled)\n",
    "y = df.iloc[:,:1]\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y.values.ravel())\n",
    "\n",
    "y = y.astype(np.float64)\n",
    "\n",
    "x = X_scaled.iloc[:,:].to_numpy()\n",
    "y_ = y.reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y_)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6136b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b41478e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data: \n",
      "(150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Example labels: \n",
      "(150,)\n",
      "[0 0 0 0 0]\n",
      "(150, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "iris_data = load_iris() # load the iris dataset\n",
    "\n",
    "print('Example data: ')\n",
    "print(iris_data.data.shape)\n",
    "print(iris_data.data[:5])\n",
    "print('Example labels: ')\n",
    "print(iris_data.target.shape)\n",
    "print(iris_data.target[:5])\n",
    "\n",
    "x = iris_data.data\n",
    "y_ = iris_data.target.reshape(-1, 1) # Convert data to a single column\n",
    "print(y_.shape)\n",
    "# One Hot encode the class labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y_)\n",
    "#print(y)\n",
    "\n",
    "# Split the data for training and testing\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ea1fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 27) (64, 7)\n",
      "(16, 27) (16, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f5cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dcb83291",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_scaled.iloc[:,:4].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "76fda6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "421030d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "type(y[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "34b011bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model Summary: \n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fc1 (Dense)                 (None, 10)                280       \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 50)                550       \n",
      "                                                                 \n",
      " fc4 (Dense)                 (None, 10)                510       \n",
      "                                                                 \n",
      " output (Dense)              (None, 7)                 77        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,417\n",
      "Trainable params: 1,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/4000\n",
      "2/2 - 1s - loss: 2.0189 - accuracy: 0.1786 - val_loss: 2.0426 - val_accuracy: 0.1000 - 894ms/epoch - 447ms/step\n",
      "Epoch 2/4000\n",
      "2/2 - 0s - loss: 1.9973 - accuracy: 0.1786 - val_loss: 2.0296 - val_accuracy: 0.1000 - 71ms/epoch - 35ms/step\n",
      "Epoch 3/4000\n",
      "2/2 - 0s - loss: 1.9820 - accuracy: 0.1607 - val_loss: 2.0174 - val_accuracy: 0.1000 - 64ms/epoch - 32ms/step\n",
      "Epoch 4/4000\n",
      "2/2 - 0s - loss: 1.9664 - accuracy: 0.1607 - val_loss: 2.0073 - val_accuracy: 0.0750 - 65ms/epoch - 33ms/step\n",
      "Epoch 5/4000\n",
      "2/2 - 0s - loss: 1.9514 - accuracy: 0.1964 - val_loss: 1.9984 - val_accuracy: 0.0750 - 72ms/epoch - 36ms/step\n",
      "Epoch 6/4000\n",
      "2/2 - 0s - loss: 1.9412 - accuracy: 0.1607 - val_loss: 1.9904 - val_accuracy: 0.0750 - 64ms/epoch - 32ms/step\n",
      "Epoch 7/4000\n",
      "2/2 - 0s - loss: 1.9288 - accuracy: 0.1607 - val_loss: 1.9837 - val_accuracy: 0.1000 - 72ms/epoch - 36ms/step\n",
      "Epoch 8/4000\n",
      "2/2 - 0s - loss: 1.9179 - accuracy: 0.1786 - val_loss: 1.9770 - val_accuracy: 0.1250 - 65ms/epoch - 33ms/step\n",
      "Epoch 9/4000\n",
      "2/2 - 0s - loss: 1.9088 - accuracy: 0.1786 - val_loss: 1.9701 - val_accuracy: 0.1500 - 69ms/epoch - 34ms/step\n",
      "Epoch 10/4000\n",
      "2/2 - 0s - loss: 1.8992 - accuracy: 0.2143 - val_loss: 1.9632 - val_accuracy: 0.2250 - 75ms/epoch - 37ms/step\n",
      "Epoch 11/4000\n",
      "2/2 - 0s - loss: 1.8903 - accuracy: 0.2857 - val_loss: 1.9564 - val_accuracy: 0.2000 - 71ms/epoch - 35ms/step\n",
      "Epoch 12/4000\n",
      "2/2 - 0s - loss: 1.8806 - accuracy: 0.2679 - val_loss: 1.9500 - val_accuracy: 0.2000 - 63ms/epoch - 32ms/step\n",
      "Epoch 13/4000\n",
      "2/2 - 0s - loss: 1.8718 - accuracy: 0.2679 - val_loss: 1.9445 - val_accuracy: 0.2000 - 72ms/epoch - 36ms/step\n",
      "Epoch 14/4000\n",
      "2/2 - 0s - loss: 1.8649 - accuracy: 0.2857 - val_loss: 1.9389 - val_accuracy: 0.2000 - 56ms/epoch - 28ms/step\n",
      "Epoch 15/4000\n",
      "2/2 - 0s - loss: 1.8563 - accuracy: 0.3036 - val_loss: 1.9336 - val_accuracy: 0.2000 - 61ms/epoch - 30ms/step\n",
      "Epoch 16/4000\n",
      "2/2 - 0s - loss: 1.8482 - accuracy: 0.3214 - val_loss: 1.9286 - val_accuracy: 0.2000 - 50ms/epoch - 25ms/step\n",
      "Epoch 17/4000\n",
      "2/2 - 0s - loss: 1.8403 - accuracy: 0.3214 - val_loss: 1.9234 - val_accuracy: 0.2000 - 58ms/epoch - 29ms/step\n",
      "Epoch 18/4000\n",
      "2/2 - 0s - loss: 1.8326 - accuracy: 0.3214 - val_loss: 1.9185 - val_accuracy: 0.2000 - 56ms/epoch - 28ms/step\n",
      "Epoch 19/4000\n",
      "2/2 - 0s - loss: 1.8255 - accuracy: 0.3214 - val_loss: 1.9136 - val_accuracy: 0.2000 - 68ms/epoch - 34ms/step\n",
      "Epoch 20/4000\n",
      "2/2 - 0s - loss: 1.8172 - accuracy: 0.3214 - val_loss: 1.9091 - val_accuracy: 0.2000 - 66ms/epoch - 33ms/step\n",
      "Epoch 21/4000\n",
      "2/2 - 0s - loss: 1.8101 - accuracy: 0.3393 - val_loss: 1.9044 - val_accuracy: 0.2000 - 58ms/epoch - 29ms/step\n",
      "Epoch 22/4000\n",
      "2/2 - 0s - loss: 1.8023 - accuracy: 0.3571 - val_loss: 1.8996 - val_accuracy: 0.2000 - 60ms/epoch - 30ms/step\n",
      "Epoch 23/4000\n",
      "2/2 - 0s - loss: 1.7937 - accuracy: 0.3571 - val_loss: 1.8945 - val_accuracy: 0.2250 - 60ms/epoch - 30ms/step\n",
      "Epoch 24/4000\n",
      "2/2 - 0s - loss: 1.7854 - accuracy: 0.3750 - val_loss: 1.8895 - val_accuracy: 0.1750 - 73ms/epoch - 36ms/step\n",
      "Epoch 25/4000\n",
      "2/2 - 0s - loss: 1.7763 - accuracy: 0.3929 - val_loss: 1.8840 - val_accuracy: 0.1500 - 70ms/epoch - 35ms/step\n",
      "Epoch 26/4000\n",
      "2/2 - 0s - loss: 1.7665 - accuracy: 0.3750 - val_loss: 1.8785 - val_accuracy: 0.1750 - 80ms/epoch - 40ms/step\n",
      "Epoch 27/4000\n",
      "2/2 - 0s - loss: 1.7571 - accuracy: 0.3750 - val_loss: 1.8725 - val_accuracy: 0.2000 - 72ms/epoch - 36ms/step\n",
      "Epoch 28/4000\n",
      "2/2 - 0s - loss: 1.7468 - accuracy: 0.3929 - val_loss: 1.8663 - val_accuracy: 0.2250 - 80ms/epoch - 40ms/step\n",
      "Epoch 29/4000\n",
      "2/2 - 0s - loss: 1.7361 - accuracy: 0.4107 - val_loss: 1.8598 - val_accuracy: 0.2250 - 94ms/epoch - 47ms/step\n",
      "Epoch 30/4000\n",
      "2/2 - 0s - loss: 1.7251 - accuracy: 0.4107 - val_loss: 1.8533 - val_accuracy: 0.2500 - 80ms/epoch - 40ms/step\n",
      "Epoch 31/4000\n",
      "2/2 - 0s - loss: 1.7127 - accuracy: 0.4107 - val_loss: 1.8466 - val_accuracy: 0.2500 - 74ms/epoch - 37ms/step\n",
      "Epoch 32/4000\n",
      "2/2 - 0s - loss: 1.7015 - accuracy: 0.4107 - val_loss: 1.8392 - val_accuracy: 0.2750 - 89ms/epoch - 44ms/step\n",
      "Epoch 33/4000\n",
      "2/2 - 0s - loss: 1.6889 - accuracy: 0.4286 - val_loss: 1.8314 - val_accuracy: 0.3000 - 98ms/epoch - 49ms/step\n",
      "Epoch 34/4000\n",
      "2/2 - 0s - loss: 1.6753 - accuracy: 0.4464 - val_loss: 1.8237 - val_accuracy: 0.3000 - 102ms/epoch - 51ms/step\n",
      "Epoch 35/4000\n",
      "2/2 - 0s - loss: 1.6636 - accuracy: 0.4464 - val_loss: 1.8155 - val_accuracy: 0.3000 - 82ms/epoch - 41ms/step\n",
      "Epoch 36/4000\n",
      "2/2 - 0s - loss: 1.6495 - accuracy: 0.4643 - val_loss: 1.8088 - val_accuracy: 0.2750 - 92ms/epoch - 46ms/step\n",
      "Epoch 37/4000\n",
      "2/2 - 0s - loss: 1.6371 - accuracy: 0.4643 - val_loss: 1.8021 - val_accuracy: 0.3000 - 93ms/epoch - 47ms/step\n",
      "Epoch 38/4000\n",
      "2/2 - 0s - loss: 1.6236 - accuracy: 0.5179 - val_loss: 1.7957 - val_accuracy: 0.3250 - 90ms/epoch - 45ms/step\n",
      "Epoch 39/4000\n",
      "2/2 - 0s - loss: 1.6104 - accuracy: 0.5179 - val_loss: 1.7880 - val_accuracy: 0.3500 - 79ms/epoch - 40ms/step\n",
      "Epoch 40/4000\n",
      "2/2 - 0s - loss: 1.5959 - accuracy: 0.5357 - val_loss: 1.7803 - val_accuracy: 0.3500 - 72ms/epoch - 36ms/step\n",
      "Epoch 41/4000\n",
      "2/2 - 0s - loss: 1.5831 - accuracy: 0.5536 - val_loss: 1.7728 - val_accuracy: 0.3500 - 56ms/epoch - 28ms/step\n",
      "Epoch 42/4000\n",
      "2/2 - 0s - loss: 1.5687 - accuracy: 0.5536 - val_loss: 1.7651 - val_accuracy: 0.3500 - 82ms/epoch - 41ms/step\n",
      "Epoch 43/4000\n",
      "2/2 - 0s - loss: 1.5546 - accuracy: 0.5536 - val_loss: 1.7579 - val_accuracy: 0.3500 - 82ms/epoch - 41ms/step\n",
      "Epoch 44/4000\n",
      "2/2 - 0s - loss: 1.5412 - accuracy: 0.5536 - val_loss: 1.7506 - val_accuracy: 0.3500 - 113ms/epoch - 57ms/step\n",
      "Epoch 45/4000\n",
      "2/2 - 0s - loss: 1.5262 - accuracy: 0.5536 - val_loss: 1.7431 - val_accuracy: 0.3500 - 101ms/epoch - 51ms/step\n",
      "Epoch 46/4000\n",
      "2/2 - 0s - loss: 1.5115 - accuracy: 0.5536 - val_loss: 1.7364 - val_accuracy: 0.3500 - 83ms/epoch - 41ms/step\n",
      "Epoch 47/4000\n",
      "2/2 - 0s - loss: 1.4960 - accuracy: 0.5536 - val_loss: 1.7290 - val_accuracy: 0.3500 - 71ms/epoch - 35ms/step\n",
      "Epoch 48/4000\n",
      "2/2 - 0s - loss: 1.4793 - accuracy: 0.5357 - val_loss: 1.7218 - val_accuracy: 0.3500 - 98ms/epoch - 49ms/step\n",
      "Epoch 49/4000\n",
      "2/2 - 0s - loss: 1.4634 - accuracy: 0.5357 - val_loss: 1.7145 - val_accuracy: 0.3500 - 109ms/epoch - 55ms/step\n",
      "Epoch 50/4000\n",
      "2/2 - 0s - loss: 1.4478 - accuracy: 0.5357 - val_loss: 1.7077 - val_accuracy: 0.3500 - 101ms/epoch - 50ms/step\n",
      "Epoch 51/4000\n",
      "2/2 - 0s - loss: 1.4305 - accuracy: 0.5536 - val_loss: 1.7005 - val_accuracy: 0.3500 - 95ms/epoch - 47ms/step\n",
      "Epoch 52/4000\n",
      "2/2 - 0s - loss: 1.4141 - accuracy: 0.5357 - val_loss: 1.6939 - val_accuracy: 0.3500 - 89ms/epoch - 44ms/step\n",
      "Epoch 53/4000\n",
      "2/2 - 0s - loss: 1.3975 - accuracy: 0.5536 - val_loss: 1.6870 - val_accuracy: 0.3500 - 90ms/epoch - 45ms/step\n",
      "Epoch 54/4000\n",
      "2/2 - 0s - loss: 1.3809 - accuracy: 0.5536 - val_loss: 1.6804 - val_accuracy: 0.3500 - 88ms/epoch - 44ms/step\n",
      "Epoch 55/4000\n",
      "2/2 - 0s - loss: 1.3649 - accuracy: 0.5536 - val_loss: 1.6737 - val_accuracy: 0.3500 - 94ms/epoch - 47ms/step\n",
      "Epoch 56/4000\n",
      "2/2 - 0s - loss: 1.3480 - accuracy: 0.5536 - val_loss: 1.6673 - val_accuracy: 0.3500 - 92ms/epoch - 46ms/step\n",
      "Epoch 57/4000\n",
      "2/2 - 0s - loss: 1.3313 - accuracy: 0.5536 - val_loss: 1.6608 - val_accuracy: 0.3500 - 89ms/epoch - 45ms/step\n",
      "Epoch 58/4000\n",
      "2/2 - 0s - loss: 1.3147 - accuracy: 0.5536 - val_loss: 1.6538 - val_accuracy: 0.3500 - 77ms/epoch - 38ms/step\n",
      "Epoch 59/4000\n",
      "2/2 - 0s - loss: 1.2976 - accuracy: 0.5536 - val_loss: 1.6469 - val_accuracy: 0.3500 - 87ms/epoch - 44ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/4000\n",
      "2/2 - 0s - loss: 1.2818 - accuracy: 0.5536 - val_loss: 1.6399 - val_accuracy: 0.3500 - 88ms/epoch - 44ms/step\n",
      "Epoch 61/4000\n",
      "2/2 - 0s - loss: 1.2648 - accuracy: 0.5536 - val_loss: 1.6322 - val_accuracy: 0.3500 - 76ms/epoch - 38ms/step\n",
      "Epoch 62/4000\n",
      "2/2 - 0s - loss: 1.2491 - accuracy: 0.5357 - val_loss: 1.6260 - val_accuracy: 0.3250 - 87ms/epoch - 43ms/step\n",
      "Epoch 63/4000\n",
      "2/2 - 0s - loss: 1.2329 - accuracy: 0.5179 - val_loss: 1.6195 - val_accuracy: 0.3250 - 80ms/epoch - 40ms/step\n",
      "Epoch 64/4000\n",
      "2/2 - 0s - loss: 1.2176 - accuracy: 0.5179 - val_loss: 1.6126 - val_accuracy: 0.3250 - 78ms/epoch - 39ms/step\n",
      "Epoch 65/4000\n",
      "2/2 - 0s - loss: 1.2006 - accuracy: 0.5357 - val_loss: 1.6068 - val_accuracy: 0.3250 - 76ms/epoch - 38ms/step\n",
      "Epoch 66/4000\n",
      "2/2 - 0s - loss: 1.1865 - accuracy: 0.5536 - val_loss: 1.6008 - val_accuracy: 0.3250 - 67ms/epoch - 33ms/step\n",
      "Epoch 67/4000\n",
      "2/2 - 0s - loss: 1.1711 - accuracy: 0.5714 - val_loss: 1.5945 - val_accuracy: 0.3250 - 68ms/epoch - 34ms/step\n",
      "Epoch 68/4000\n",
      "2/2 - 0s - loss: 1.1562 - accuracy: 0.5893 - val_loss: 1.5877 - val_accuracy: 0.3250 - 72ms/epoch - 36ms/step\n",
      "Epoch 69/4000\n",
      "2/2 - 0s - loss: 1.1409 - accuracy: 0.5893 - val_loss: 1.5811 - val_accuracy: 0.3250 - 93ms/epoch - 46ms/step\n",
      "Epoch 70/4000\n",
      "2/2 - 0s - loss: 1.1257 - accuracy: 0.5893 - val_loss: 1.5749 - val_accuracy: 0.3250 - 98ms/epoch - 49ms/step\n",
      "Epoch 71/4000\n",
      "2/2 - 0s - loss: 1.1121 - accuracy: 0.5893 - val_loss: 1.5682 - val_accuracy: 0.3500 - 101ms/epoch - 51ms/step\n",
      "Epoch 72/4000\n",
      "2/2 - 0s - loss: 1.0972 - accuracy: 0.6250 - val_loss: 1.5609 - val_accuracy: 0.4250 - 95ms/epoch - 47ms/step\n",
      "Epoch 73/4000\n",
      "2/2 - 0s - loss: 1.0831 - accuracy: 0.6964 - val_loss: 1.5549 - val_accuracy: 0.4250 - 79ms/epoch - 40ms/step\n",
      "Epoch 74/4000\n",
      "2/2 - 0s - loss: 1.0690 - accuracy: 0.6964 - val_loss: 1.5486 - val_accuracy: 0.4250 - 111ms/epoch - 56ms/step\n",
      "Epoch 75/4000\n",
      "2/2 - 0s - loss: 1.0557 - accuracy: 0.6964 - val_loss: 1.5428 - val_accuracy: 0.4250 - 113ms/epoch - 57ms/step\n",
      "Epoch 76/4000\n",
      "2/2 - 0s - loss: 1.0418 - accuracy: 0.6964 - val_loss: 1.5370 - val_accuracy: 0.4250 - 98ms/epoch - 49ms/step\n",
      "Epoch 77/4000\n",
      "2/2 - 0s - loss: 1.0284 - accuracy: 0.6964 - val_loss: 1.5307 - val_accuracy: 0.4000 - 116ms/epoch - 58ms/step\n",
      "Epoch 78/4000\n",
      "2/2 - 0s - loss: 1.0154 - accuracy: 0.6964 - val_loss: 1.5240 - val_accuracy: 0.4000 - 93ms/epoch - 47ms/step\n",
      "Epoch 79/4000\n",
      "2/2 - 0s - loss: 1.0018 - accuracy: 0.6964 - val_loss: 1.5179 - val_accuracy: 0.4000 - 75ms/epoch - 37ms/step\n",
      "Epoch 80/4000\n",
      "2/2 - 0s - loss: 0.9892 - accuracy: 0.6964 - val_loss: 1.5116 - val_accuracy: 0.4000 - 95ms/epoch - 48ms/step\n",
      "Epoch 81/4000\n",
      "2/2 - 0s - loss: 0.9759 - accuracy: 0.6964 - val_loss: 1.5067 - val_accuracy: 0.4000 - 84ms/epoch - 42ms/step\n",
      "Epoch 82/4000\n",
      "2/2 - 0s - loss: 0.9635 - accuracy: 0.6964 - val_loss: 1.5012 - val_accuracy: 0.4000 - 74ms/epoch - 37ms/step\n",
      "Epoch 83/4000\n",
      "2/2 - 0s - loss: 0.9514 - accuracy: 0.6964 - val_loss: 1.4946 - val_accuracy: 0.4000 - 74ms/epoch - 37ms/step\n",
      "Epoch 84/4000\n",
      "2/2 - 0s - loss: 0.9390 - accuracy: 0.6964 - val_loss: 1.4886 - val_accuracy: 0.4000 - 87ms/epoch - 43ms/step\n",
      "Epoch 85/4000\n",
      "2/2 - 0s - loss: 0.9269 - accuracy: 0.6964 - val_loss: 1.4833 - val_accuracy: 0.4250 - 70ms/epoch - 35ms/step\n",
      "Epoch 86/4000\n",
      "2/2 - 0s - loss: 0.9147 - accuracy: 0.7143 - val_loss: 1.4776 - val_accuracy: 0.4250 - 63ms/epoch - 31ms/step\n",
      "Epoch 87/4000\n",
      "2/2 - 0s - loss: 0.9029 - accuracy: 0.7143 - val_loss: 1.4709 - val_accuracy: 0.4500 - 66ms/epoch - 33ms/step\n",
      "Epoch 88/4000\n",
      "2/2 - 0s - loss: 0.8909 - accuracy: 0.7321 - val_loss: 1.4643 - val_accuracy: 0.4500 - 56ms/epoch - 28ms/step\n",
      "Epoch 89/4000\n",
      "2/2 - 0s - loss: 0.8796 - accuracy: 0.7143 - val_loss: 1.4580 - val_accuracy: 0.4500 - 66ms/epoch - 33ms/step\n",
      "Epoch 90/4000\n",
      "2/2 - 0s - loss: 0.8677 - accuracy: 0.7321 - val_loss: 1.4516 - val_accuracy: 0.4750 - 64ms/epoch - 32ms/step\n",
      "Epoch 91/4000\n",
      "2/2 - 0s - loss: 0.8561 - accuracy: 0.7500 - val_loss: 1.4447 - val_accuracy: 0.5000 - 59ms/epoch - 29ms/step\n",
      "Epoch 92/4000\n",
      "2/2 - 0s - loss: 0.8449 - accuracy: 0.7679 - val_loss: 1.4377 - val_accuracy: 0.5250 - 53ms/epoch - 26ms/step\n",
      "Epoch 93/4000\n",
      "2/2 - 0s - loss: 0.8340 - accuracy: 0.7679 - val_loss: 1.4302 - val_accuracy: 0.5250 - 54ms/epoch - 27ms/step\n",
      "Epoch 94/4000\n",
      "2/2 - 0s - loss: 0.8232 - accuracy: 0.7857 - val_loss: 1.4231 - val_accuracy: 0.5250 - 57ms/epoch - 29ms/step\n",
      "Epoch 95/4000\n",
      "2/2 - 0s - loss: 0.8118 - accuracy: 0.7857 - val_loss: 1.4172 - val_accuracy: 0.5250 - 59ms/epoch - 29ms/step\n",
      "Epoch 96/4000\n",
      "2/2 - 0s - loss: 0.8008 - accuracy: 0.7857 - val_loss: 1.4106 - val_accuracy: 0.5250 - 53ms/epoch - 26ms/step\n",
      "Epoch 97/4000\n",
      "2/2 - 0s - loss: 0.7902 - accuracy: 0.7857 - val_loss: 1.4050 - val_accuracy: 0.5250 - 51ms/epoch - 26ms/step\n",
      "Epoch 98/4000\n",
      "2/2 - 0s - loss: 0.7795 - accuracy: 0.7857 - val_loss: 1.3999 - val_accuracy: 0.5250 - 58ms/epoch - 29ms/step\n",
      "Epoch 99/4000\n",
      "2/2 - 0s - loss: 0.7689 - accuracy: 0.7857 - val_loss: 1.3949 - val_accuracy: 0.5250 - 63ms/epoch - 31ms/step\n",
      "Epoch 100/4000\n",
      "2/2 - 0s - loss: 0.7588 - accuracy: 0.7857 - val_loss: 1.3904 - val_accuracy: 0.5500 - 60ms/epoch - 30ms/step\n",
      "Epoch 101/4000\n",
      "2/2 - 0s - loss: 0.7490 - accuracy: 0.8036 - val_loss: 1.3855 - val_accuracy: 0.5500 - 49ms/epoch - 25ms/step\n",
      "Epoch 102/4000\n",
      "2/2 - 0s - loss: 0.7392 - accuracy: 0.8036 - val_loss: 1.3802 - val_accuracy: 0.5500 - 56ms/epoch - 28ms/step\n",
      "Epoch 103/4000\n",
      "2/2 - 0s - loss: 0.7291 - accuracy: 0.8036 - val_loss: 1.3753 - val_accuracy: 0.5500 - 58ms/epoch - 29ms/step\n",
      "Epoch 104/4000\n",
      "2/2 - 0s - loss: 0.7202 - accuracy: 0.8036 - val_loss: 1.3696 - val_accuracy: 0.5500 - 55ms/epoch - 27ms/step\n",
      "Epoch 105/4000\n",
      "2/2 - 0s - loss: 0.7112 - accuracy: 0.8036 - val_loss: 1.3647 - val_accuracy: 0.5500 - 61ms/epoch - 31ms/step\n",
      "Epoch 106/4000\n",
      "2/2 - 0s - loss: 0.7010 - accuracy: 0.7857 - val_loss: 1.3591 - val_accuracy: 0.5500 - 65ms/epoch - 32ms/step\n",
      "Epoch 107/4000\n",
      "2/2 - 0s - loss: 0.6920 - accuracy: 0.7857 - val_loss: 1.3528 - val_accuracy: 0.5500 - 64ms/epoch - 32ms/step\n",
      "Epoch 108/4000\n",
      "2/2 - 0s - loss: 0.6831 - accuracy: 0.7857 - val_loss: 1.3471 - val_accuracy: 0.5750 - 65ms/epoch - 33ms/step\n",
      "Epoch 109/4000\n",
      "2/2 - 0s - loss: 0.6747 - accuracy: 0.8036 - val_loss: 1.3411 - val_accuracy: 0.5750 - 48ms/epoch - 24ms/step\n",
      "Epoch 110/4000\n",
      "2/2 - 0s - loss: 0.6653 - accuracy: 0.8036 - val_loss: 1.3356 - val_accuracy: 0.5750 - 54ms/epoch - 27ms/step\n",
      "Epoch 111/4000\n",
      "2/2 - 0s - loss: 0.6570 - accuracy: 0.8036 - val_loss: 1.3307 - val_accuracy: 0.5750 - 67ms/epoch - 33ms/step\n",
      "Epoch 112/4000\n",
      "2/2 - 0s - loss: 0.6488 - accuracy: 0.8036 - val_loss: 1.3258 - val_accuracy: 0.6000 - 61ms/epoch - 31ms/step\n",
      "Epoch 113/4000\n",
      "2/2 - 0s - loss: 0.6400 - accuracy: 0.8214 - val_loss: 1.3214 - val_accuracy: 0.6000 - 52ms/epoch - 26ms/step\n",
      "Epoch 114/4000\n",
      "2/2 - 0s - loss: 0.6314 - accuracy: 0.8214 - val_loss: 1.3182 - val_accuracy: 0.6000 - 64ms/epoch - 32ms/step\n",
      "Epoch 115/4000\n",
      "2/2 - 0s - loss: 0.6229 - accuracy: 0.8214 - val_loss: 1.3157 - val_accuracy: 0.6000 - 48ms/epoch - 24ms/step\n",
      "Epoch 116/4000\n",
      "2/2 - 0s - loss: 0.6149 - accuracy: 0.8393 - val_loss: 1.3125 - val_accuracy: 0.6250 - 60ms/epoch - 30ms/step\n",
      "Epoch 117/4000\n",
      "2/2 - 0s - loss: 0.6076 - accuracy: 0.8393 - val_loss: 1.3074 - val_accuracy: 0.6500 - 58ms/epoch - 29ms/step\n",
      "Epoch 118/4000\n",
      "2/2 - 0s - loss: 0.5983 - accuracy: 0.8571 - val_loss: 1.3023 - val_accuracy: 0.6500 - 67ms/epoch - 33ms/step\n",
      "Epoch 119/4000\n",
      "2/2 - 0s - loss: 0.5904 - accuracy: 0.8571 - val_loss: 1.2970 - val_accuracy: 0.6500 - 55ms/epoch - 27ms/step\n",
      "Epoch 120/4000\n",
      "2/2 - 0s - loss: 0.5824 - accuracy: 0.8571 - val_loss: 1.2926 - val_accuracy: 0.6500 - 60ms/epoch - 30ms/step\n",
      "Epoch 121/4000\n",
      "2/2 - 0s - loss: 0.5748 - accuracy: 0.8571 - val_loss: 1.2888 - val_accuracy: 0.6250 - 62ms/epoch - 31ms/step\n",
      "Epoch 122/4000\n",
      "2/2 - 0s - loss: 0.5666 - accuracy: 0.8571 - val_loss: 1.2845 - val_accuracy: 0.6500 - 54ms/epoch - 27ms/step\n",
      "Epoch 123/4000\n",
      "2/2 - 0s - loss: 0.5588 - accuracy: 0.8750 - val_loss: 1.2813 - val_accuracy: 0.6500 - 72ms/epoch - 36ms/step\n",
      "Epoch 124/4000\n",
      "2/2 - 0s - loss: 0.5517 - accuracy: 0.8750 - val_loss: 1.2771 - val_accuracy: 0.6750 - 56ms/epoch - 28ms/step\n",
      "Epoch 125/4000\n",
      "2/2 - 0s - loss: 0.5438 - accuracy: 0.8750 - val_loss: 1.2733 - val_accuracy: 0.6750 - 61ms/epoch - 30ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/4000\n",
      "2/2 - 0s - loss: 0.5376 - accuracy: 0.8750 - val_loss: 1.2689 - val_accuracy: 0.6500 - 65ms/epoch - 32ms/step\n",
      "Epoch 127/4000\n",
      "2/2 - 0s - loss: 0.5291 - accuracy: 0.8750 - val_loss: 1.2661 - val_accuracy: 0.6500 - 58ms/epoch - 29ms/step\n",
      "Epoch 128/4000\n",
      "2/2 - 0s - loss: 0.5220 - accuracy: 0.8929 - val_loss: 1.2646 - val_accuracy: 0.6750 - 70ms/epoch - 35ms/step\n",
      "Epoch 129/4000\n",
      "2/2 - 0s - loss: 0.5145 - accuracy: 0.8929 - val_loss: 1.2636 - val_accuracy: 0.7000 - 55ms/epoch - 28ms/step\n",
      "Epoch 130/4000\n",
      "2/2 - 0s - loss: 0.5077 - accuracy: 0.9107 - val_loss: 1.2628 - val_accuracy: 0.6750 - 53ms/epoch - 26ms/step\n",
      "Epoch 131/4000\n",
      "2/2 - 0s - loss: 0.5005 - accuracy: 0.9286 - val_loss: 1.2603 - val_accuracy: 0.6750 - 56ms/epoch - 28ms/step\n",
      "Epoch 132/4000\n",
      "2/2 - 0s - loss: 0.4939 - accuracy: 0.9107 - val_loss: 1.2561 - val_accuracy: 0.6750 - 53ms/epoch - 26ms/step\n",
      "Epoch 133/4000\n",
      "2/2 - 0s - loss: 0.4869 - accuracy: 0.9286 - val_loss: 1.2529 - val_accuracy: 0.6750 - 52ms/epoch - 26ms/step\n",
      "Epoch 134/4000\n",
      "2/2 - 0s - loss: 0.4795 - accuracy: 0.9286 - val_loss: 1.2498 - val_accuracy: 0.6750 - 64ms/epoch - 32ms/step\n",
      "Epoch 135/4000\n",
      "2/2 - 0s - loss: 0.4727 - accuracy: 0.9286 - val_loss: 1.2477 - val_accuracy: 0.6750 - 59ms/epoch - 29ms/step\n",
      "Epoch 136/4000\n",
      "2/2 - 0s - loss: 0.4657 - accuracy: 0.9286 - val_loss: 1.2453 - val_accuracy: 0.6750 - 69ms/epoch - 35ms/step\n",
      "Epoch 137/4000\n",
      "2/2 - 0s - loss: 0.4597 - accuracy: 0.9286 - val_loss: 1.2411 - val_accuracy: 0.6750 - 60ms/epoch - 30ms/step\n",
      "Epoch 138/4000\n",
      "2/2 - 0s - loss: 0.4522 - accuracy: 0.9286 - val_loss: 1.2386 - val_accuracy: 0.6750 - 52ms/epoch - 26ms/step\n",
      "Epoch 139/4000\n",
      "2/2 - 0s - loss: 0.4456 - accuracy: 0.9286 - val_loss: 1.2362 - val_accuracy: 0.6750 - 51ms/epoch - 25ms/step\n",
      "Epoch 140/4000\n",
      "2/2 - 0s - loss: 0.4388 - accuracy: 0.9286 - val_loss: 1.2337 - val_accuracy: 0.6750 - 55ms/epoch - 28ms/step\n",
      "Epoch 141/4000\n",
      "2/2 - 0s - loss: 0.4335 - accuracy: 0.9286 - val_loss: 1.2319 - val_accuracy: 0.6750 - 57ms/epoch - 29ms/step\n",
      "Epoch 142/4000\n",
      "2/2 - 0s - loss: 0.4262 - accuracy: 0.9286 - val_loss: 1.2297 - val_accuracy: 0.6750 - 63ms/epoch - 31ms/step\n",
      "Epoch 143/4000\n",
      "2/2 - 0s - loss: 0.4197 - accuracy: 0.9286 - val_loss: 1.2284 - val_accuracy: 0.6750 - 57ms/epoch - 28ms/step\n",
      "Epoch 144/4000\n",
      "2/2 - 0s - loss: 0.4135 - accuracy: 0.9286 - val_loss: 1.2260 - val_accuracy: 0.7000 - 67ms/epoch - 33ms/step\n",
      "Epoch 145/4000\n",
      "2/2 - 0s - loss: 0.4070 - accuracy: 0.9464 - val_loss: 1.2235 - val_accuracy: 0.7000 - 79ms/epoch - 40ms/step\n",
      "Epoch 146/4000\n",
      "2/2 - 0s - loss: 0.4008 - accuracy: 0.9464 - val_loss: 1.2223 - val_accuracy: 0.7000 - 67ms/epoch - 34ms/step\n",
      "Epoch 147/4000\n",
      "2/2 - 0s - loss: 0.3948 - accuracy: 0.9643 - val_loss: 1.2216 - val_accuracy: 0.7000 - 70ms/epoch - 35ms/step\n",
      "Epoch 148/4000\n",
      "2/2 - 0s - loss: 0.3879 - accuracy: 0.9643 - val_loss: 1.2201 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 149/4000\n",
      "2/2 - 0s - loss: 0.3820 - accuracy: 0.9821 - val_loss: 1.2182 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 150/4000\n",
      "2/2 - 0s - loss: 0.3760 - accuracy: 0.9821 - val_loss: 1.2166 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 151/4000\n",
      "2/2 - 0s - loss: 0.3705 - accuracy: 0.9821 - val_loss: 1.2148 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 152/4000\n",
      "2/2 - 0s - loss: 0.3650 - accuracy: 1.0000 - val_loss: 1.2149 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 153/4000\n",
      "2/2 - 0s - loss: 0.3586 - accuracy: 1.0000 - val_loss: 1.2148 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 154/4000\n",
      "2/2 - 0s - loss: 0.3525 - accuracy: 1.0000 - val_loss: 1.2149 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 155/4000\n",
      "2/2 - 0s - loss: 0.3469 - accuracy: 1.0000 - val_loss: 1.2133 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 156/4000\n",
      "2/2 - 0s - loss: 0.3414 - accuracy: 1.0000 - val_loss: 1.2120 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 157/4000\n",
      "2/2 - 0s - loss: 0.3363 - accuracy: 1.0000 - val_loss: 1.2125 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 158/4000\n",
      "2/2 - 0s - loss: 0.3300 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 159/4000\n",
      "2/2 - 0s - loss: 0.3243 - accuracy: 1.0000 - val_loss: 1.2148 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 160/4000\n",
      "2/2 - 0s - loss: 0.3191 - accuracy: 1.0000 - val_loss: 1.2168 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 161/4000\n",
      "2/2 - 0s - loss: 0.3137 - accuracy: 1.0000 - val_loss: 1.2169 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 162/4000\n",
      "2/2 - 0s - loss: 0.3087 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 163/4000\n",
      "2/2 - 0s - loss: 0.3037 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 164/4000\n",
      "2/2 - 0s - loss: 0.2991 - accuracy: 1.0000 - val_loss: 1.2183 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 165/4000\n",
      "2/2 - 0s - loss: 0.2928 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 166/4000\n",
      "2/2 - 0s - loss: 0.2881 - accuracy: 1.0000 - val_loss: 1.2216 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 167/4000\n",
      "2/2 - 0s - loss: 0.2831 - accuracy: 1.0000 - val_loss: 1.2233 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 168/4000\n",
      "2/2 - 0s - loss: 0.2786 - accuracy: 1.0000 - val_loss: 1.2253 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 169/4000\n",
      "2/2 - 0s - loss: 0.2737 - accuracy: 1.0000 - val_loss: 1.2261 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 170/4000\n",
      "2/2 - 0s - loss: 0.2686 - accuracy: 1.0000 - val_loss: 1.2266 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 171/4000\n",
      "2/2 - 0s - loss: 0.2641 - accuracy: 1.0000 - val_loss: 1.2262 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 172/4000\n",
      "2/2 - 0s - loss: 0.2593 - accuracy: 1.0000 - val_loss: 1.2269 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 173/4000\n",
      "2/2 - 0s - loss: 0.2549 - accuracy: 1.0000 - val_loss: 1.2280 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 174/4000\n",
      "2/2 - 0s - loss: 0.2508 - accuracy: 1.0000 - val_loss: 1.2293 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 175/4000\n",
      "2/2 - 0s - loss: 0.2465 - accuracy: 1.0000 - val_loss: 1.2307 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 176/4000\n",
      "2/2 - 0s - loss: 0.2424 - accuracy: 1.0000 - val_loss: 1.2309 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 177/4000\n",
      "2/2 - 0s - loss: 0.2383 - accuracy: 1.0000 - val_loss: 1.2302 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 178/4000\n",
      "2/2 - 0s - loss: 0.2342 - accuracy: 1.0000 - val_loss: 1.2312 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 179/4000\n",
      "2/2 - 0s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 1.2312 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 180/4000\n",
      "2/2 - 0s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.2325 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 181/4000\n",
      "2/2 - 0s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.2358 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 182/4000\n",
      "2/2 - 0s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 183/4000\n",
      "2/2 - 0s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.2409 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 184/4000\n",
      "2/2 - 0s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2435 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 185/4000\n",
      "2/2 - 0s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 1.2459 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 186/4000\n",
      "2/2 - 0s - loss: 0.2039 - accuracy: 1.0000 - val_loss: 1.2490 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 187/4000\n",
      "2/2 - 0s - loss: 0.1999 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 188/4000\n",
      "2/2 - 0s - loss: 0.1963 - accuracy: 1.0000 - val_loss: 1.2524 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 189/4000\n",
      "2/2 - 0s - loss: 0.1927 - accuracy: 1.0000 - val_loss: 1.2536 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 190/4000\n",
      "2/2 - 0s - loss: 0.1890 - accuracy: 1.0000 - val_loss: 1.2559 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 191/4000\n",
      "2/2 - 0s - loss: 0.1855 - accuracy: 1.0000 - val_loss: 1.2571 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/4000\n",
      "2/2 - 0s - loss: 0.1817 - accuracy: 1.0000 - val_loss: 1.2599 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 193/4000\n",
      "2/2 - 0s - loss: 0.1789 - accuracy: 1.0000 - val_loss: 1.2614 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 194/4000\n",
      "2/2 - 0s - loss: 0.1754 - accuracy: 1.0000 - val_loss: 1.2637 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 195/4000\n",
      "2/2 - 0s - loss: 0.1722 - accuracy: 1.0000 - val_loss: 1.2656 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 196/4000\n",
      "2/2 - 0s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 1.2685 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 197/4000\n",
      "2/2 - 0s - loss: 0.1658 - accuracy: 1.0000 - val_loss: 1.2716 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 198/4000\n",
      "2/2 - 0s - loss: 0.1627 - accuracy: 1.0000 - val_loss: 1.2750 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 199/4000\n",
      "2/2 - 0s - loss: 0.1599 - accuracy: 1.0000 - val_loss: 1.2786 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 200/4000\n",
      "2/2 - 0s - loss: 0.1572 - accuracy: 1.0000 - val_loss: 1.2829 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 201/4000\n",
      "2/2 - 0s - loss: 0.1542 - accuracy: 1.0000 - val_loss: 1.2858 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 202/4000\n",
      "2/2 - 0s - loss: 0.1514 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 203/4000\n",
      "2/2 - 0s - loss: 0.1490 - accuracy: 1.0000 - val_loss: 1.2902 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 204/4000\n",
      "2/2 - 0s - loss: 0.1463 - accuracy: 1.0000 - val_loss: 1.2937 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 205/4000\n",
      "2/2 - 0s - loss: 0.1435 - accuracy: 1.0000 - val_loss: 1.2975 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 206/4000\n",
      "2/2 - 0s - loss: 0.1409 - accuracy: 1.0000 - val_loss: 1.3021 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 207/4000\n",
      "2/2 - 0s - loss: 0.1389 - accuracy: 1.0000 - val_loss: 1.3068 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 208/4000\n",
      "2/2 - 0s - loss: 0.1363 - accuracy: 1.0000 - val_loss: 1.3100 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 209/4000\n",
      "2/2 - 0s - loss: 0.1340 - accuracy: 1.0000 - val_loss: 1.3138 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 210/4000\n",
      "2/2 - 0s - loss: 0.1318 - accuracy: 1.0000 - val_loss: 1.3178 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 211/4000\n",
      "2/2 - 0s - loss: 0.1293 - accuracy: 1.0000 - val_loss: 1.3219 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 212/4000\n",
      "2/2 - 0s - loss: 0.1271 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 213/4000\n",
      "2/2 - 0s - loss: 0.1250 - accuracy: 1.0000 - val_loss: 1.3273 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 214/4000\n",
      "2/2 - 0s - loss: 0.1229 - accuracy: 1.0000 - val_loss: 1.3314 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 215/4000\n",
      "2/2 - 0s - loss: 0.1208 - accuracy: 1.0000 - val_loss: 1.3359 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 216/4000\n",
      "2/2 - 0s - loss: 0.1186 - accuracy: 1.0000 - val_loss: 1.3402 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 217/4000\n",
      "2/2 - 0s - loss: 0.1166 - accuracy: 1.0000 - val_loss: 1.3448 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 218/4000\n",
      "2/2 - 0s - loss: 0.1147 - accuracy: 1.0000 - val_loss: 1.3495 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 219/4000\n",
      "2/2 - 0s - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.3544 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 220/4000\n",
      "2/2 - 0s - loss: 0.1109 - accuracy: 1.0000 - val_loss: 1.3591 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 221/4000\n",
      "2/2 - 0s - loss: 0.1089 - accuracy: 1.0000 - val_loss: 1.3640 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 222/4000\n",
      "2/2 - 0s - loss: 0.1071 - accuracy: 1.0000 - val_loss: 1.3697 - val_accuracy: 0.7000 - 66ms/epoch - 33ms/step\n",
      "Epoch 223/4000\n",
      "2/2 - 0s - loss: 0.1054 - accuracy: 1.0000 - val_loss: 1.3750 - val_accuracy: 0.7000 - 59ms/epoch - 30ms/step\n",
      "Epoch 224/4000\n",
      "2/2 - 0s - loss: 0.1036 - accuracy: 1.0000 - val_loss: 1.3790 - val_accuracy: 0.7000 - 52ms/epoch - 26ms/step\n",
      "Epoch 225/4000\n",
      "2/2 - 0s - loss: 0.1019 - accuracy: 1.0000 - val_loss: 1.3827 - val_accuracy: 0.7000 - 60ms/epoch - 30ms/step\n",
      "Epoch 226/4000\n",
      "2/2 - 0s - loss: 0.1002 - accuracy: 1.0000 - val_loss: 1.3871 - val_accuracy: 0.7000 - 53ms/epoch - 26ms/step\n",
      "Epoch 227/4000\n",
      "2/2 - 0s - loss: 0.0987 - accuracy: 1.0000 - val_loss: 1.3910 - val_accuracy: 0.7000 - 65ms/epoch - 32ms/step\n",
      "Epoch 228/4000\n",
      "2/2 - 0s - loss: 0.0970 - accuracy: 1.0000 - val_loss: 1.3954 - val_accuracy: 0.7000 - 53ms/epoch - 26ms/step\n",
      "Epoch 229/4000\n",
      "2/2 - 0s - loss: 0.0955 - accuracy: 1.0000 - val_loss: 1.4000 - val_accuracy: 0.7000 - 58ms/epoch - 29ms/step\n",
      "Epoch 230/4000\n",
      "2/2 - 0s - loss: 0.0941 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.7000 - 61ms/epoch - 30ms/step\n",
      "Epoch 231/4000\n",
      "2/2 - 0s - loss: 0.0925 - accuracy: 1.0000 - val_loss: 1.4083 - val_accuracy: 0.7000 - 61ms/epoch - 31ms/step\n",
      "Epoch 232/4000\n",
      "2/2 - 0s - loss: 0.0910 - accuracy: 1.0000 - val_loss: 1.4109 - val_accuracy: 0.7000 - 57ms/epoch - 28ms/step\n",
      "Epoch 233/4000\n",
      "2/2 - 0s - loss: 0.0896 - accuracy: 1.0000 - val_loss: 1.4148 - val_accuracy: 0.7000 - 53ms/epoch - 26ms/step\n",
      "Epoch 234/4000\n",
      "2/2 - 0s - loss: 0.0882 - accuracy: 1.0000 - val_loss: 1.4194 - val_accuracy: 0.7000 - 51ms/epoch - 26ms/step\n",
      "Epoch 235/4000\n",
      "2/2 - 0s - loss: 0.0867 - accuracy: 1.0000 - val_loss: 1.4235 - val_accuracy: 0.7000 - 64ms/epoch - 32ms/step\n",
      "Epoch 236/4000\n",
      "2/2 - 0s - loss: 0.0856 - accuracy: 1.0000 - val_loss: 1.4281 - val_accuracy: 0.7000 - 59ms/epoch - 30ms/step\n",
      "Epoch 237/4000\n",
      "2/2 - 0s - loss: 0.0842 - accuracy: 1.0000 - val_loss: 1.4314 - val_accuracy: 0.7000 - 51ms/epoch - 26ms/step\n",
      "Epoch 238/4000\n",
      "2/2 - 0s - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.4359 - val_accuracy: 0.7000 - 46ms/epoch - 23ms/step\n",
      "Epoch 239/4000\n",
      "2/2 - 0s - loss: 0.0818 - accuracy: 1.0000 - val_loss: 1.4385 - val_accuracy: 0.7000 - 53ms/epoch - 27ms/step\n",
      "Epoch 240/4000\n",
      "2/2 - 0s - loss: 0.0805 - accuracy: 1.0000 - val_loss: 1.4422 - val_accuracy: 0.7000 - 55ms/epoch - 27ms/step\n",
      "Epoch 241/4000\n",
      "2/2 - 0s - loss: 0.0793 - accuracy: 1.0000 - val_loss: 1.4459 - val_accuracy: 0.7000 - 54ms/epoch - 27ms/step\n",
      "Epoch 242/4000\n",
      "2/2 - 0s - loss: 0.0782 - accuracy: 1.0000 - val_loss: 1.4518 - val_accuracy: 0.7000 - 51ms/epoch - 25ms/step\n",
      "Epoch 243/4000\n",
      "2/2 - 0s - loss: 0.0769 - accuracy: 1.0000 - val_loss: 1.4562 - val_accuracy: 0.7000 - 56ms/epoch - 28ms/step\n",
      "Epoch 244/4000\n",
      "2/2 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 1.4602 - val_accuracy: 0.7000 - 57ms/epoch - 29ms/step\n",
      "Epoch 245/4000\n",
      "2/2 - 0s - loss: 0.0747 - accuracy: 1.0000 - val_loss: 1.4636 - val_accuracy: 0.7000 - 52ms/epoch - 26ms/step\n",
      "Epoch 246/4000\n",
      "2/2 - 0s - loss: 0.0736 - accuracy: 1.0000 - val_loss: 1.4665 - val_accuracy: 0.7000 - 66ms/epoch - 33ms/step\n",
      "Epoch 247/4000\n",
      "2/2 - 0s - loss: 0.0726 - accuracy: 1.0000 - val_loss: 1.4708 - val_accuracy: 0.7000 - 54ms/epoch - 27ms/step\n",
      "Epoch 248/4000\n",
      "2/2 - 0s - loss: 0.0714 - accuracy: 1.0000 - val_loss: 1.4759 - val_accuracy: 0.7000 - 63ms/epoch - 32ms/step\n",
      "Epoch 249/4000\n",
      "2/2 - 0s - loss: 0.0704 - accuracy: 1.0000 - val_loss: 1.4802 - val_accuracy: 0.7000 - 62ms/epoch - 31ms/step\n",
      "Epoch 250/4000\n",
      "2/2 - 0s - loss: 0.0694 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.7000 - 64ms/epoch - 32ms/step\n",
      "Epoch 251/4000\n",
      "2/2 - 0s - loss: 0.0683 - accuracy: 1.0000 - val_loss: 1.4869 - val_accuracy: 0.7000 - 61ms/epoch - 30ms/step\n",
      "Epoch 252/4000\n",
      "2/2 - 0s - loss: 0.0674 - accuracy: 1.0000 - val_loss: 1.4913 - val_accuracy: 0.7000 - 48ms/epoch - 24ms/step\n",
      "Epoch 253/4000\n",
      "2/2 - 0s - loss: 0.0665 - accuracy: 1.0000 - val_loss: 1.4956 - val_accuracy: 0.7000 - 55ms/epoch - 27ms/step\n",
      "Epoch 254/4000\n",
      "2/2 - 0s - loss: 0.0655 - accuracy: 1.0000 - val_loss: 1.4997 - val_accuracy: 0.7000 - 57ms/epoch - 28ms/step\n",
      "Epoch 255/4000\n",
      "2/2 - 0s - loss: 0.0647 - accuracy: 1.0000 - val_loss: 1.5033 - val_accuracy: 0.7000 - 62ms/epoch - 31ms/step\n",
      "Epoch 256/4000\n",
      "2/2 - 0s - loss: 0.0637 - accuracy: 1.0000 - val_loss: 1.5064 - val_accuracy: 0.7000 - 65ms/epoch - 32ms/step\n",
      "Epoch 257/4000\n",
      "2/2 - 0s - loss: 0.0628 - accuracy: 1.0000 - val_loss: 1.5102 - val_accuracy: 0.7000 - 52ms/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/4000\n",
      "2/2 - 0s - loss: 0.0619 - accuracy: 1.0000 - val_loss: 1.5153 - val_accuracy: 0.7000 - 63ms/epoch - 32ms/step\n",
      "Epoch 259/4000\n",
      "2/2 - 0s - loss: 0.0610 - accuracy: 1.0000 - val_loss: 1.5205 - val_accuracy: 0.7000 - 58ms/epoch - 29ms/step\n",
      "Epoch 260/4000\n",
      "2/2 - 0s - loss: 0.0602 - accuracy: 1.0000 - val_loss: 1.5246 - val_accuracy: 0.7000 - 57ms/epoch - 28ms/step\n",
      "Epoch 261/4000\n",
      "2/2 - 0s - loss: 0.0593 - accuracy: 1.0000 - val_loss: 1.5293 - val_accuracy: 0.7000 - 66ms/epoch - 33ms/step\n",
      "Epoch 262/4000\n",
      "2/2 - 0s - loss: 0.0584 - accuracy: 1.0000 - val_loss: 1.5346 - val_accuracy: 0.7000 - 61ms/epoch - 30ms/step\n",
      "Epoch 263/4000\n",
      "2/2 - 0s - loss: 0.0574 - accuracy: 1.0000 - val_loss: 1.5398 - val_accuracy: 0.7000 - 54ms/epoch - 27ms/step\n",
      "Epoch 264/4000\n",
      "2/2 - 0s - loss: 0.0565 - accuracy: 1.0000 - val_loss: 1.5449 - val_accuracy: 0.7000 - 62ms/epoch - 31ms/step\n",
      "Epoch 265/4000\n",
      "2/2 - 0s - loss: 0.0556 - accuracy: 1.0000 - val_loss: 1.5496 - val_accuracy: 0.7000 - 53ms/epoch - 27ms/step\n",
      "Epoch 266/4000\n",
      "2/2 - 0s - loss: 0.0548 - accuracy: 1.0000 - val_loss: 1.5530 - val_accuracy: 0.7000 - 61ms/epoch - 30ms/step\n",
      "Epoch 267/4000\n",
      "2/2 - 0s - loss: 0.0538 - accuracy: 1.0000 - val_loss: 1.5573 - val_accuracy: 0.7000 - 61ms/epoch - 31ms/step\n",
      "Epoch 268/4000\n",
      "2/2 - 0s - loss: 0.0530 - accuracy: 1.0000 - val_loss: 1.5627 - val_accuracy: 0.7000 - 56ms/epoch - 28ms/step\n",
      "Epoch 269/4000\n",
      "2/2 - 0s - loss: 0.0521 - accuracy: 1.0000 - val_loss: 1.5690 - val_accuracy: 0.7000 - 63ms/epoch - 32ms/step\n",
      "Epoch 270/4000\n",
      "2/2 - 0s - loss: 0.0512 - accuracy: 1.0000 - val_loss: 1.5747 - val_accuracy: 0.7000 - 55ms/epoch - 27ms/step\n",
      "Epoch 271/4000\n",
      "2/2 - 0s - loss: 0.0504 - accuracy: 1.0000 - val_loss: 1.5798 - val_accuracy: 0.7000 - 61ms/epoch - 30ms/step\n",
      "Epoch 272/4000\n",
      "2/2 - 0s - loss: 0.0496 - accuracy: 1.0000 - val_loss: 1.5837 - val_accuracy: 0.7000 - 56ms/epoch - 28ms/step\n",
      "Epoch 273/4000\n",
      "2/2 - 0s - loss: 0.0487 - accuracy: 1.0000 - val_loss: 1.5883 - val_accuracy: 0.7000 - 66ms/epoch - 33ms/step\n",
      "Epoch 274/4000\n",
      "2/2 - 0s - loss: 0.0481 - accuracy: 1.0000 - val_loss: 1.5926 - val_accuracy: 0.7000 - 63ms/epoch - 31ms/step\n",
      "Epoch 275/4000\n",
      "2/2 - 0s - loss: 0.0473 - accuracy: 1.0000 - val_loss: 1.5979 - val_accuracy: 0.7000 - 54ms/epoch - 27ms/step\n",
      "Epoch 276/4000\n",
      "2/2 - 0s - loss: 0.0466 - accuracy: 1.0000 - val_loss: 1.6031 - val_accuracy: 0.7000 - 63ms/epoch - 32ms/step\n",
      "Epoch 277/4000\n",
      "2/2 - 0s - loss: 0.0457 - accuracy: 1.0000 - val_loss: 1.6070 - val_accuracy: 0.7000 - 54ms/epoch - 27ms/step\n",
      "Epoch 278/4000\n",
      "2/2 - 0s - loss: 0.0450 - accuracy: 1.0000 - val_loss: 1.6116 - val_accuracy: 0.7000 - 71ms/epoch - 35ms/step\n",
      "Epoch 279/4000\n",
      "2/2 - 0s - loss: 0.0444 - accuracy: 1.0000 - val_loss: 1.6169 - val_accuracy: 0.7000 - 63ms/epoch - 32ms/step\n",
      "Epoch 280/4000\n",
      "2/2 - 0s - loss: 0.0437 - accuracy: 1.0000 - val_loss: 1.6215 - val_accuracy: 0.7000 - 59ms/epoch - 29ms/step\n",
      "Epoch 281/4000\n",
      "2/2 - 0s - loss: 0.0430 - accuracy: 1.0000 - val_loss: 1.6250 - val_accuracy: 0.7000 - 54ms/epoch - 27ms/step\n",
      "Epoch 282/4000\n",
      "2/2 - 0s - loss: 0.0423 - accuracy: 1.0000 - val_loss: 1.6278 - val_accuracy: 0.7000 - 51ms/epoch - 25ms/step\n",
      "Epoch 283/4000\n",
      "2/2 - 0s - loss: 0.0418 - accuracy: 1.0000 - val_loss: 1.6308 - val_accuracy: 0.7000 - 58ms/epoch - 29ms/step\n",
      "Epoch 284/4000\n",
      "2/2 - 0s - loss: 0.0411 - accuracy: 1.0000 - val_loss: 1.6349 - val_accuracy: 0.7000 - 67ms/epoch - 33ms/step\n",
      "Epoch 285/4000\n",
      "2/2 - 0s - loss: 0.0406 - accuracy: 1.0000 - val_loss: 1.6385 - val_accuracy: 0.7000 - 59ms/epoch - 30ms/step\n",
      "Epoch 286/4000\n",
      "2/2 - 0s - loss: 0.0400 - accuracy: 1.0000 - val_loss: 1.6420 - val_accuracy: 0.7000 - 50ms/epoch - 25ms/step\n",
      "Epoch 287/4000\n",
      "2/2 - 0s - loss: 0.0394 - accuracy: 1.0000 - val_loss: 1.6457 - val_accuracy: 0.7000 - 60ms/epoch - 30ms/step\n",
      "Epoch 288/4000\n",
      "2/2 - 0s - loss: 0.0388 - accuracy: 1.0000 - val_loss: 1.6497 - val_accuracy: 0.7000 - 66ms/epoch - 33ms/step\n",
      "Epoch 289/4000\n",
      "2/2 - 0s - loss: 0.0383 - accuracy: 1.0000 - val_loss: 1.6532 - val_accuracy: 0.7000 - 61ms/epoch - 30ms/step\n",
      "Epoch 290/4000\n",
      "2/2 - 0s - loss: 0.0377 - accuracy: 1.0000 - val_loss: 1.6560 - val_accuracy: 0.7000 - 56ms/epoch - 28ms/step\n",
      "Epoch 291/4000\n",
      "2/2 - 0s - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.6593 - val_accuracy: 0.7000 - 46ms/epoch - 23ms/step\n",
      "Epoch 292/4000\n",
      "2/2 - 0s - loss: 0.0367 - accuracy: 1.0000 - val_loss: 1.6621 - val_accuracy: 0.7000 - 59ms/epoch - 29ms/step\n",
      "Epoch 293/4000\n",
      "2/2 - 0s - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.6660 - val_accuracy: 0.7000 - 54ms/epoch - 27ms/step\n",
      "Epoch 294/4000\n",
      "2/2 - 0s - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.6707 - val_accuracy: 0.7000 - 53ms/epoch - 27ms/step\n",
      "Epoch 295/4000\n",
      "2/2 - 0s - loss: 0.0352 - accuracy: 1.0000 - val_loss: 1.6757 - val_accuracy: 0.7000 - 67ms/epoch - 34ms/step\n",
      "Epoch 296/4000\n",
      "2/2 - 0s - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.6805 - val_accuracy: 0.7000 - 65ms/epoch - 32ms/step\n",
      "Epoch 297/4000\n",
      "2/2 - 0s - loss: 0.0343 - accuracy: 1.0000 - val_loss: 1.6853 - val_accuracy: 0.7000 - 58ms/epoch - 29ms/step\n",
      "Epoch 298/4000\n",
      "2/2 - 0s - loss: 0.0338 - accuracy: 1.0000 - val_loss: 1.6885 - val_accuracy: 0.7000 - 57ms/epoch - 28ms/step\n",
      "Epoch 299/4000\n",
      "2/2 - 0s - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.6912 - val_accuracy: 0.7000 - 51ms/epoch - 26ms/step\n",
      "Epoch 300/4000\n",
      "2/2 - 0s - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.6954 - val_accuracy: 0.7000 - 55ms/epoch - 27ms/step\n",
      "Epoch 301/4000\n",
      "2/2 - 0s - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.6995 - val_accuracy: 0.7000 - 59ms/epoch - 30ms/step\n",
      "Epoch 302/4000\n",
      "2/2 - 0s - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.7000 - 67ms/epoch - 33ms/step\n",
      "Epoch 303/4000\n",
      "2/2 - 0s - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.7070 - val_accuracy: 0.7000 - 60ms/epoch - 30ms/step\n",
      "Epoch 304/4000\n",
      "2/2 - 0s - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.7105 - val_accuracy: 0.7000 - 62ms/epoch - 31ms/step\n",
      "Epoch 305/4000\n",
      "2/2 - 0s - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.7135 - val_accuracy: 0.7000 - 57ms/epoch - 29ms/step\n",
      "Epoch 306/4000\n",
      "2/2 - 0s - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.7158 - val_accuracy: 0.7000 - 60ms/epoch - 30ms/step\n",
      "Epoch 307/4000\n",
      "2/2 - 0s - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.7187 - val_accuracy: 0.7000 - 65ms/epoch - 33ms/step\n",
      "Epoch 308/4000\n",
      "2/2 - 0s - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.7000 - 62ms/epoch - 31ms/step\n",
      "Epoch 309/4000\n",
      "2/2 - 0s - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.7260 - val_accuracy: 0.7000 - 65ms/epoch - 32ms/step\n",
      "Epoch 310/4000\n",
      "2/2 - 0s - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.7293 - val_accuracy: 0.7000 - 57ms/epoch - 28ms/step\n",
      "Epoch 311/4000\n",
      "2/2 - 0s - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.7323 - val_accuracy: 0.7000 - 67ms/epoch - 34ms/step\n",
      "Epoch 312/4000\n",
      "2/2 - 0s - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.7353 - val_accuracy: 0.7000 - 70ms/epoch - 35ms/step\n",
      "Epoch 313/4000\n",
      "2/2 - 0s - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.7390 - val_accuracy: 0.7000 - 55ms/epoch - 27ms/step\n",
      "Epoch 314/4000\n",
      "2/2 - 0s - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.7000 - 62ms/epoch - 31ms/step\n",
      "Epoch 315/4000\n",
      "2/2 - 0s - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.7457 - val_accuracy: 0.7000 - 51ms/epoch - 25ms/step\n",
      "Epoch 316/4000\n",
      "2/2 - 0s - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.7490 - val_accuracy: 0.7000 - 63ms/epoch - 31ms/step\n",
      "Epoch 317/4000\n",
      "2/2 - 0s - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.7513 - val_accuracy: 0.7000 - 61ms/epoch - 31ms/step\n",
      "Epoch 318/4000\n",
      "2/2 - 0s - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.7551 - val_accuracy: 0.7000 - 59ms/epoch - 30ms/step\n",
      "Epoch 319/4000\n",
      "2/2 - 0s - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.7585 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 320/4000\n",
      "2/2 - 0s - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.7617 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 321/4000\n",
      "2/2 - 0s - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.7649 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 322/4000\n",
      "2/2 - 0s - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.7690 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 323/4000\n",
      "2/2 - 0s - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.7715 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/4000\n",
      "2/2 - 0s - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.7748 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 325/4000\n",
      "2/2 - 0s - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.7780 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 326/4000\n",
      "2/2 - 0s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.7814 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 327/4000\n",
      "2/2 - 0s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.7844 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 328/4000\n",
      "2/2 - 0s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.7871 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 329/4000\n",
      "2/2 - 0s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.7894 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 330/4000\n",
      "2/2 - 0s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.7923 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 331/4000\n",
      "2/2 - 0s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.7949 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 332/4000\n",
      "2/2 - 0s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.7979 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 333/4000\n",
      "2/2 - 0s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.8003 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 334/4000\n",
      "2/2 - 0s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.8027 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 335/4000\n",
      "2/2 - 0s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.8052 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 336/4000\n",
      "2/2 - 0s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.8080 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 337/4000\n",
      "2/2 - 0s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.8107 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 338/4000\n",
      "2/2 - 0s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.8129 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 339/4000\n",
      "2/2 - 0s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.8154 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 340/4000\n",
      "2/2 - 0s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.8189 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 341/4000\n",
      "2/2 - 0s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.8222 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 342/4000\n",
      "2/2 - 0s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.8258 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 343/4000\n",
      "2/2 - 0s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.8287 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 344/4000\n",
      "2/2 - 0s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.8315 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 345/4000\n",
      "2/2 - 0s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.8342 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 346/4000\n",
      "2/2 - 0s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.8368 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 347/4000\n",
      "2/2 - 0s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 348/4000\n",
      "2/2 - 0s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.8408 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 349/4000\n",
      "2/2 - 0s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.8439 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 350/4000\n",
      "2/2 - 0s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.8477 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 351/4000\n",
      "2/2 - 0s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.8512 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 352/4000\n",
      "2/2 - 0s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.8535 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 353/4000\n",
      "2/2 - 0s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.8564 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 354/4000\n",
      "2/2 - 0s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.8597 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 355/4000\n",
      "2/2 - 0s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.8624 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 356/4000\n",
      "2/2 - 0s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.8655 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 357/4000\n",
      "2/2 - 0s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.8680 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 358/4000\n",
      "2/2 - 0s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.8710 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 359/4000\n",
      "2/2 - 0s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.8739 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 360/4000\n",
      "2/2 - 0s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.8762 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 361/4000\n",
      "2/2 - 0s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.8790 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 362/4000\n",
      "2/2 - 0s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.8810 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 363/4000\n",
      "2/2 - 0s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.8834 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 364/4000\n",
      "2/2 - 0s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.8856 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 365/4000\n",
      "2/2 - 0s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.8879 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 366/4000\n",
      "2/2 - 0s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.8908 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 367/4000\n",
      "2/2 - 0s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.8942 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 368/4000\n",
      "2/2 - 0s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.8973 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 369/4000\n",
      "2/2 - 0s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.9005 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 370/4000\n",
      "2/2 - 0s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.9033 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 371/4000\n",
      "2/2 - 0s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.9066 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 372/4000\n",
      "2/2 - 0s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.9092 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 373/4000\n",
      "2/2 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.9119 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 374/4000\n",
      "2/2 - 0s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.9150 - val_accuracy: 0.7250 - 86ms/epoch - 43ms/step\n",
      "Epoch 375/4000\n",
      "2/2 - 0s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.9178 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 376/4000\n",
      "2/2 - 0s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.9205 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 377/4000\n",
      "2/2 - 0s - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 378/4000\n",
      "2/2 - 0s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.9256 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 379/4000\n",
      "2/2 - 0s - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.9277 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 380/4000\n",
      "2/2 - 0s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.9302 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 381/4000\n",
      "2/2 - 0s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.9322 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 382/4000\n",
      "2/2 - 0s - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.9348 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 383/4000\n",
      "2/2 - 0s - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.9374 - val_accuracy: 0.7250 - 91ms/epoch - 46ms/step\n",
      "Epoch 384/4000\n",
      "2/2 - 0s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.9403 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 385/4000\n",
      "2/2 - 0s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.9433 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 386/4000\n",
      "2/2 - 0s - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 387/4000\n",
      "2/2 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.9494 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 388/4000\n",
      "2/2 - 0s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.9519 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 389/4000\n",
      "2/2 - 0s - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.9539 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/4000\n",
      "2/2 - 0s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.9566 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 391/4000\n",
      "2/2 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.9591 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 392/4000\n",
      "2/2 - 0s - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.9622 - val_accuracy: 0.7250 - 44ms/epoch - 22ms/step\n",
      "Epoch 393/4000\n",
      "2/2 - 0s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.9649 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 394/4000\n",
      "2/2 - 0s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.9676 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 395/4000\n",
      "2/2 - 0s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.9704 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 396/4000\n",
      "2/2 - 0s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.9734 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 397/4000\n",
      "2/2 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.9759 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 398/4000\n",
      "2/2 - 0s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.9786 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 399/4000\n",
      "2/2 - 0s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.9808 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 400/4000\n",
      "2/2 - 0s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.9832 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 401/4000\n",
      "2/2 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.9859 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 402/4000\n",
      "2/2 - 0s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.9882 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 403/4000\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.9904 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 404/4000\n",
      "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.9929 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 405/4000\n",
      "2/2 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.9951 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 406/4000\n",
      "2/2 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.9977 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 407/4000\n",
      "2/2 - 0s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.9997 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 408/4000\n",
      "2/2 - 0s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.0023 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 409/4000\n",
      "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.0049 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 410/4000\n",
      "2/2 - 0s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.0078 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 411/4000\n",
      "2/2 - 0s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.0098 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 412/4000\n",
      "2/2 - 0s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.0118 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 413/4000\n",
      "2/2 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.0144 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 414/4000\n",
      "2/2 - 0s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.0169 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 415/4000\n",
      "2/2 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.0193 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 416/4000\n",
      "2/2 - 0s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.0215 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 417/4000\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.0241 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 418/4000\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.0260 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 419/4000\n",
      "2/2 - 0s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.0284 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 420/4000\n",
      "2/2 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.0312 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 421/4000\n",
      "2/2 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.0333 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 422/4000\n",
      "2/2 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.0354 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 423/4000\n",
      "2/2 - 0s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.0375 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 424/4000\n",
      "2/2 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.0392 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 425/4000\n",
      "2/2 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.0412 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 426/4000\n",
      "2/2 - 0s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.0427 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 427/4000\n",
      "2/2 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.0448 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 428/4000\n",
      "2/2 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.0472 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 429/4000\n",
      "2/2 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.0493 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 430/4000\n",
      "2/2 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.0515 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 431/4000\n",
      "2/2 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.0538 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 432/4000\n",
      "2/2 - 0s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.0559 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 433/4000\n",
      "2/2 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.0579 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 434/4000\n",
      "2/2 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.0596 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 435/4000\n",
      "2/2 - 0s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.0620 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 436/4000\n",
      "2/2 - 0s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.0646 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 437/4000\n",
      "2/2 - 0s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.0666 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 438/4000\n",
      "2/2 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.0689 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 439/4000\n",
      "2/2 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.0708 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 440/4000\n",
      "2/2 - 0s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.0730 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 441/4000\n",
      "2/2 - 0s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.0748 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 442/4000\n",
      "2/2 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.0766 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 443/4000\n",
      "2/2 - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.0786 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 444/4000\n",
      "2/2 - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.0810 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 445/4000\n",
      "2/2 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.0836 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 446/4000\n",
      "2/2 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.0856 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 447/4000\n",
      "2/2 - 0s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.0873 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 448/4000\n",
      "2/2 - 0s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.0890 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 449/4000\n",
      "2/2 - 0s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.0909 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 450/4000\n",
      "2/2 - 0s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.0931 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 451/4000\n",
      "2/2 - 0s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0951 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 452/4000\n",
      "2/2 - 0s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0972 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 453/4000\n",
      "2/2 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.0991 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 454/4000\n",
      "2/2 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1008 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 455/4000\n",
      "2/2 - 0s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.1028 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/4000\n",
      "2/2 - 0s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.1048 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 457/4000\n",
      "2/2 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.1067 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 458/4000\n",
      "2/2 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.1083 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 459/4000\n",
      "2/2 - 0s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.1101 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 460/4000\n",
      "2/2 - 0s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.1118 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 461/4000\n",
      "2/2 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.1133 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 462/4000\n",
      "2/2 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.1152 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 463/4000\n",
      "2/2 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.1171 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 464/4000\n",
      "2/2 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.1191 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 465/4000\n",
      "2/2 - 0s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.1214 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 466/4000\n",
      "2/2 - 0s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.1232 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 467/4000\n",
      "2/2 - 0s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.1253 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 468/4000\n",
      "2/2 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1270 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 469/4000\n",
      "2/2 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1289 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 470/4000\n",
      "2/2 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1306 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 471/4000\n",
      "2/2 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1326 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 472/4000\n",
      "2/2 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.1343 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 473/4000\n",
      "2/2 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.1364 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 474/4000\n",
      "2/2 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.1383 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 475/4000\n",
      "2/2 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.1403 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 476/4000\n",
      "2/2 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.1425 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 477/4000\n",
      "2/2 - 0s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1438 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 478/4000\n",
      "2/2 - 0s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1456 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 479/4000\n",
      "2/2 - 0s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 480/4000\n",
      "2/2 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1496 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 481/4000\n",
      "2/2 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1512 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 482/4000\n",
      "2/2 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1530 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 483/4000\n",
      "2/2 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1548 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 484/4000\n",
      "2/2 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1565 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 485/4000\n",
      "2/2 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1585 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 486/4000\n",
      "2/2 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1605 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 487/4000\n",
      "2/2 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1622 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 488/4000\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1639 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 489/4000\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1656 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 490/4000\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1673 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 491/4000\n",
      "2/2 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1693 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 492/4000\n",
      "2/2 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1710 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 493/4000\n",
      "2/2 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1730 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 494/4000\n",
      "2/2 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1747 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 495/4000\n",
      "2/2 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1765 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 496/4000\n",
      "2/2 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1781 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 497/4000\n",
      "2/2 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1801 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 498/4000\n",
      "2/2 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1818 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 499/4000\n",
      "2/2 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1834 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 500/4000\n",
      "2/2 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1852 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 501/4000\n",
      "2/2 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1868 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 502/4000\n",
      "2/2 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1887 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 503/4000\n",
      "2/2 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1907 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 504/4000\n",
      "2/2 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1925 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 505/4000\n",
      "2/2 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1939 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 506/4000\n",
      "2/2 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1955 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 507/4000\n",
      "2/2 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1974 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 508/4000\n",
      "2/2 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1989 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 509/4000\n",
      "2/2 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.2006 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 510/4000\n",
      "2/2 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.2027 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 511/4000\n",
      "2/2 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.2049 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 512/4000\n",
      "2/2 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.2066 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 513/4000\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.2081 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 514/4000\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.2096 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 515/4000\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.2107 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 516/4000\n",
      "2/2 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.2120 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 517/4000\n",
      "2/2 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.2135 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 518/4000\n",
      "2/2 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.2151 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 519/4000\n",
      "2/2 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.2164 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 520/4000\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.2178 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 521/4000\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.2196 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/4000\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.2211 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 523/4000\n",
      "2/2 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.2223 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 524/4000\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2240 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 525/4000\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2256 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 526/4000\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2272 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 527/4000\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2286 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 528/4000\n",
      "2/2 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2303 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 529/4000\n",
      "2/2 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2315 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 530/4000\n",
      "2/2 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2332 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 531/4000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2349 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 532/4000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2365 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 533/4000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2380 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 534/4000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2396 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 535/4000\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2412 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 536/4000\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.2426 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 537/4000\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.2441 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 538/4000\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.2453 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 539/4000\n",
      "2/2 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.2470 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 540/4000\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.2489 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 541/4000\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.2503 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 542/4000\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.2519 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 543/4000\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.2537 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 544/4000\n",
      "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2553 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 545/4000\n",
      "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2571 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 546/4000\n",
      "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2589 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 547/4000\n",
      "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2604 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 548/4000\n",
      "2/2 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2619 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 549/4000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2637 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 550/4000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2656 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 551/4000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2671 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 552/4000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2686 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 553/4000\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2702 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 554/4000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2716 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 555/4000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2734 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 556/4000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2753 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 557/4000\n",
      "2/2 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2771 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 558/4000\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2784 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 559/4000\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2799 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 560/4000\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2811 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 561/4000\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2826 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 562/4000\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2842 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 563/4000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2859 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 564/4000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2875 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 565/4000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2889 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 566/4000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2902 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 567/4000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2915 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 568/4000\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2926 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 569/4000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2938 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 570/4000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2952 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 571/4000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2968 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 572/4000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2982 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 573/4000\n",
      "2/2 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2997 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 574/4000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3010 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 575/4000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3020 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 576/4000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3033 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 577/4000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3045 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 578/4000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3058 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 579/4000\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3072 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 580/4000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3085 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 581/4000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3098 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 582/4000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3113 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 583/4000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3130 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 584/4000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3144 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 585/4000\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3161 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 586/4000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3177 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 587/4000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3193 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 588/4000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3210 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 589/4000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3223 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 590/4000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3236 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 591/4000\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3248 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 592/4000\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3260 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 593/4000\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3274 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 594/4000\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3291 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 595/4000\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3304 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 596/4000\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3319 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 597/4000\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3331 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 598/4000\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3345 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 599/4000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3359 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 600/4000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3370 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 601/4000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3385 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 602/4000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3402 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 603/4000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3417 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 604/4000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3428 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 605/4000\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3441 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 606/4000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3453 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 607/4000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3469 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 608/4000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3484 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 609/4000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3495 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 610/4000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3505 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 611/4000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3518 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 612/4000\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3530 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 613/4000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3541 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 614/4000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3553 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 615/4000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3563 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 616/4000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3575 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 617/4000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3586 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 618/4000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3598 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 619/4000\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3610 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 620/4000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3622 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 621/4000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3632 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 622/4000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3646 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 623/4000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3658 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 624/4000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3670 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 625/4000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3684 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 626/4000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3696 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 627/4000\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3707 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 628/4000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3717 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 629/4000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3729 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 630/4000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3740 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 631/4000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3753 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 632/4000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3765 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 633/4000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3777 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 634/4000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3792 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 635/4000\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3807 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 636/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3820 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 637/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3832 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 638/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3844 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 639/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3856 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 640/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3871 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 641/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3885 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 642/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3902 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 643/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3915 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 644/4000\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3929 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 645/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.3942 - val_accuracy: 0.7250 - 45ms/epoch - 22ms/step\n",
      "Epoch 646/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.3954 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 647/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.3965 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 648/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.3976 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 649/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.3987 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 650/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.3999 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 651/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4012 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 652/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4025 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 653/4000\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4036 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 654/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4044 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 655/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4055 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 656/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4067 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 657/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4079 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 658/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4092 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 659/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4103 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 660/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4115 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 661/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4124 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 662/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4136 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 663/4000\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4149 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 664/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4161 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 665/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4175 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 666/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4190 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 667/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4204 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 668/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4216 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 669/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4228 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 670/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4240 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 671/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4253 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 672/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4266 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 673/4000\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4279 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 674/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4291 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 675/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4303 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 676/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4315 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 677/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4327 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 678/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4341 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 679/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4350 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 680/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4361 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 681/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4372 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 682/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4383 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 683/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4395 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 684/4000\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4407 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 685/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4419 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 686/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4430 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 687/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4443 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 688/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4452 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 689/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4459 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 690/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4470 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 691/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4483 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 692/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4497 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 693/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4509 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 694/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4520 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 695/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4530 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 696/4000\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4541 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 697/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4550 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 698/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4560 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 699/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4574 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 700/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4586 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 701/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4598 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 702/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4611 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 703/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4620 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 704/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4630 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 705/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4643 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 706/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4657 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 707/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4672 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 708/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4685 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 709/4000\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4697 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 710/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4709 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 711/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4719 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 712/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4729 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 713/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4741 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 714/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4753 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 715/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4767 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 716/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4780 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 717/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4793 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 718/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4802 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 719/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4812 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4824 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 721/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4836 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 722/4000\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4847 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 723/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4858 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 724/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4870 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 725/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4881 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 726/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4891 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 727/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4903 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 728/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4913 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 729/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4923 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 730/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4932 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 731/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4944 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 732/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4955 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 733/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4965 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 734/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4978 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 735/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4991 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 736/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5003 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 737/4000\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5011 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 738/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5022 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 739/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5032 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 740/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5041 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 741/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5051 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 742/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5062 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 743/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5074 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 744/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5086 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 745/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5095 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 746/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5106 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 747/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5119 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 748/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5130 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 749/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5141 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 750/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5155 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 751/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5167 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 752/4000\n",
      "2/2 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5179 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 753/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5188 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 754/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5198 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 755/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5207 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 756/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5218 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 757/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5228 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 758/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5240 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 759/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5249 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 760/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5259 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 761/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5267 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 762/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5276 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 763/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5283 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 764/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5292 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 765/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5302 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 766/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5313 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 767/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5325 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 768/4000\n",
      "2/2 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5334 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 769/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5344 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 770/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5354 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 771/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5363 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 772/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5375 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 773/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5385 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 774/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5392 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 775/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5402 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 776/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5413 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 777/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5423 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 778/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5431 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 779/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5442 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 780/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5450 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 781/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5459 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 782/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5469 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 783/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5482 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 784/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5492 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 785/4000\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5501 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 786/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5511 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 787/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5520 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 788/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5531 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 789/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5543 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 790/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5552 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 791/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5562 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 792/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5570 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 793/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5579 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 794/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5587 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 795/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5597 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 796/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5609 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 797/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5620 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 798/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5632 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 799/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5642 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 800/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5652 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 801/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5663 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 802/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5673 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 803/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5685 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 804/4000\n",
      "2/2 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5695 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 805/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5706 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 806/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5718 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 807/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5726 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 808/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5736 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 809/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5747 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 810/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5758 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 811/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5768 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 812/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5777 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 813/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5787 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 814/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5797 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 815/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5808 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 816/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5815 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 817/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5824 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 818/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5832 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 819/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5842 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 820/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5851 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 821/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5860 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 822/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5871 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 823/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5880 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 824/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5891 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 825/4000\n",
      "2/2 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5901 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 826/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5910 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 827/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5921 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 828/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5931 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 829/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5943 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 830/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5953 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 831/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5961 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 832/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5971 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 833/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5983 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 834/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5993 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 835/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6003 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 836/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6014 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 837/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6025 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 838/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6036 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 839/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6045 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 840/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6054 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 841/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6064 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 842/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6075 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 843/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6087 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 844/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6099 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 845/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6107 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 846/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6116 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 847/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6128 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 848/4000\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6136 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 849/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6147 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 850/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6157 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 851/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6166 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 852/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6175 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 853/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6186 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 854/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 855/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6207 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 856/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6218 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 857/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6226 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 858/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6237 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 859/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6246 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 860/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6255 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 861/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6265 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 862/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6276 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 863/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6285 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 864/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6295 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 865/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 866/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6314 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 867/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6323 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 868/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6332 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 869/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6342 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 870/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6354 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 871/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6365 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 872/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6374 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 873/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6383 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 874/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6393 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 875/4000\n",
      "2/2 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6403 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 876/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6412 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 877/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6422 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 878/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6432 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 879/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6443 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 880/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6452 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 881/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6462 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 882/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6472 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 883/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6481 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 884/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6492 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 885/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6500 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 886/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6509 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 887/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6518 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 888/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6527 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 889/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6538 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 890/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6550 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 891/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6558 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 892/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6567 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 893/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6576 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 894/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6586 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 895/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6597 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 896/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6606 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 897/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6614 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 898/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6621 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 899/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6629 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 900/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6639 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 901/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6650 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 902/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6661 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 903/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6671 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 904/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6680 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 905/4000\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6689 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 906/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6696 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 907/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6704 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 908/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6711 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 909/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6721 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 910/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6728 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 911/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6738 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 912/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6749 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 913/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6757 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 914/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6765 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 915/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6772 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 916/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6783 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 917/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6794 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 918/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6803 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 919/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6813 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 920/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6823 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 921/4000\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6833 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 922/4000\n",
      "2/2 - 0s - loss: 9.9978e-04 - accuracy: 1.0000 - val_loss: 2.6842 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 923/4000\n",
      "2/2 - 0s - loss: 9.9669e-04 - accuracy: 1.0000 - val_loss: 2.6851 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 924/4000\n",
      "2/2 - 0s - loss: 9.9399e-04 - accuracy: 1.0000 - val_loss: 2.6860 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 925/4000\n",
      "2/2 - 0s - loss: 9.9109e-04 - accuracy: 1.0000 - val_loss: 2.6867 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 926/4000\n",
      "2/2 - 0s - loss: 9.8838e-04 - accuracy: 1.0000 - val_loss: 2.6876 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 927/4000\n",
      "2/2 - 0s - loss: 9.8559e-04 - accuracy: 1.0000 - val_loss: 2.6884 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 928/4000\n",
      "2/2 - 0s - loss: 9.8252e-04 - accuracy: 1.0000 - val_loss: 2.6893 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 929/4000\n",
      "2/2 - 0s - loss: 9.7995e-04 - accuracy: 1.0000 - val_loss: 2.6903 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 930/4000\n",
      "2/2 - 0s - loss: 9.7708e-04 - accuracy: 1.0000 - val_loss: 2.6912 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 931/4000\n",
      "2/2 - 0s - loss: 9.7441e-04 - accuracy: 1.0000 - val_loss: 2.6920 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 932/4000\n",
      "2/2 - 0s - loss: 9.7147e-04 - accuracy: 1.0000 - val_loss: 2.6928 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 933/4000\n",
      "2/2 - 0s - loss: 9.6909e-04 - accuracy: 1.0000 - val_loss: 2.6936 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 934/4000\n",
      "2/2 - 0s - loss: 9.6604e-04 - accuracy: 1.0000 - val_loss: 2.6944 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 935/4000\n",
      "2/2 - 0s - loss: 9.6339e-04 - accuracy: 1.0000 - val_loss: 2.6953 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 936/4000\n",
      "2/2 - 0s - loss: 9.6104e-04 - accuracy: 1.0000 - val_loss: 2.6965 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 937/4000\n",
      "2/2 - 0s - loss: 9.5824e-04 - accuracy: 1.0000 - val_loss: 2.6974 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 938/4000\n",
      "2/2 - 0s - loss: 9.5543e-04 - accuracy: 1.0000 - val_loss: 2.6983 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 939/4000\n",
      "2/2 - 0s - loss: 9.5230e-04 - accuracy: 1.0000 - val_loss: 2.6990 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 940/4000\n",
      "2/2 - 0s - loss: 9.4987e-04 - accuracy: 1.0000 - val_loss: 2.6996 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 941/4000\n",
      "2/2 - 0s - loss: 9.4727e-04 - accuracy: 1.0000 - val_loss: 2.7005 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 942/4000\n",
      "2/2 - 0s - loss: 9.4474e-04 - accuracy: 1.0000 - val_loss: 2.7013 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 943/4000\n",
      "2/2 - 0s - loss: 9.4206e-04 - accuracy: 1.0000 - val_loss: 2.7022 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 944/4000\n",
      "2/2 - 0s - loss: 9.3913e-04 - accuracy: 1.0000 - val_loss: 2.7031 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 945/4000\n",
      "2/2 - 0s - loss: 9.3658e-04 - accuracy: 1.0000 - val_loss: 2.7039 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 946/4000\n",
      "2/2 - 0s - loss: 9.3401e-04 - accuracy: 1.0000 - val_loss: 2.7048 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 947/4000\n",
      "2/2 - 0s - loss: 9.3114e-04 - accuracy: 1.0000 - val_loss: 2.7057 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 948/4000\n",
      "2/2 - 0s - loss: 9.2878e-04 - accuracy: 1.0000 - val_loss: 2.7066 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 949/4000\n",
      "2/2 - 0s - loss: 9.2650e-04 - accuracy: 1.0000 - val_loss: 2.7074 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 950/4000\n",
      "2/2 - 0s - loss: 9.2360e-04 - accuracy: 1.0000 - val_loss: 2.7083 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 951/4000\n",
      "2/2 - 0s - loss: 9.2106e-04 - accuracy: 1.0000 - val_loss: 2.7092 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 952/4000\n",
      "2/2 - 0s - loss: 9.1847e-04 - accuracy: 1.0000 - val_loss: 2.7100 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 953/4000\n",
      "2/2 - 0s - loss: 9.1599e-04 - accuracy: 1.0000 - val_loss: 2.7110 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 954/4000\n",
      "2/2 - 0s - loss: 9.1364e-04 - accuracy: 1.0000 - val_loss: 2.7121 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 955/4000\n",
      "2/2 - 0s - loss: 9.1070e-04 - accuracy: 1.0000 - val_loss: 2.7129 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 956/4000\n",
      "2/2 - 0s - loss: 9.0838e-04 - accuracy: 1.0000 - val_loss: 2.7138 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 957/4000\n",
      "2/2 - 0s - loss: 9.0566e-04 - accuracy: 1.0000 - val_loss: 2.7148 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 958/4000\n",
      "2/2 - 0s - loss: 9.0335e-04 - accuracy: 1.0000 - val_loss: 2.7158 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 959/4000\n",
      "2/2 - 0s - loss: 9.0088e-04 - accuracy: 1.0000 - val_loss: 2.7168 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 960/4000\n",
      "2/2 - 0s - loss: 8.9829e-04 - accuracy: 1.0000 - val_loss: 2.7176 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 961/4000\n",
      "2/2 - 0s - loss: 8.9575e-04 - accuracy: 1.0000 - val_loss: 2.7186 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 962/4000\n",
      "2/2 - 0s - loss: 8.9342e-04 - accuracy: 1.0000 - val_loss: 2.7195 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 963/4000\n",
      "2/2 - 0s - loss: 8.9078e-04 - accuracy: 1.0000 - val_loss: 2.7205 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 964/4000\n",
      "2/2 - 0s - loss: 8.8860e-04 - accuracy: 1.0000 - val_loss: 2.7216 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 965/4000\n",
      "2/2 - 0s - loss: 8.8627e-04 - accuracy: 1.0000 - val_loss: 2.7227 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 966/4000\n",
      "2/2 - 0s - loss: 8.8374e-04 - accuracy: 1.0000 - val_loss: 2.7235 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 967/4000\n",
      "2/2 - 0s - loss: 8.8137e-04 - accuracy: 1.0000 - val_loss: 2.7244 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 968/4000\n",
      "2/2 - 0s - loss: 8.7907e-04 - accuracy: 1.0000 - val_loss: 2.7250 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 969/4000\n",
      "2/2 - 0s - loss: 8.7650e-04 - accuracy: 1.0000 - val_loss: 2.7257 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 970/4000\n",
      "2/2 - 0s - loss: 8.7416e-04 - accuracy: 1.0000 - val_loss: 2.7264 - val_accuracy: 0.7250 - 80ms/epoch - 40ms/step\n",
      "Epoch 971/4000\n",
      "2/2 - 0s - loss: 8.7162e-04 - accuracy: 1.0000 - val_loss: 2.7273 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 972/4000\n",
      "2/2 - 0s - loss: 8.6964e-04 - accuracy: 1.0000 - val_loss: 2.7282 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 973/4000\n",
      "2/2 - 0s - loss: 8.6697e-04 - accuracy: 1.0000 - val_loss: 2.7291 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 974/4000\n",
      "2/2 - 0s - loss: 8.6479e-04 - accuracy: 1.0000 - val_loss: 2.7301 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 975/4000\n",
      "2/2 - 0s - loss: 8.6255e-04 - accuracy: 1.0000 - val_loss: 2.7310 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 976/4000\n",
      "2/2 - 0s - loss: 8.6006e-04 - accuracy: 1.0000 - val_loss: 2.7318 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 977/4000\n",
      "2/2 - 0s - loss: 8.5783e-04 - accuracy: 1.0000 - val_loss: 2.7325 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 978/4000\n",
      "2/2 - 0s - loss: 8.5558e-04 - accuracy: 1.0000 - val_loss: 2.7332 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 979/4000\n",
      "2/2 - 0s - loss: 8.5331e-04 - accuracy: 1.0000 - val_loss: 2.7339 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 980/4000\n",
      "2/2 - 0s - loss: 8.5109e-04 - accuracy: 1.0000 - val_loss: 2.7347 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 981/4000\n",
      "2/2 - 0s - loss: 8.4849e-04 - accuracy: 1.0000 - val_loss: 2.7356 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/4000\n",
      "2/2 - 0s - loss: 8.4636e-04 - accuracy: 1.0000 - val_loss: 2.7366 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 983/4000\n",
      "2/2 - 0s - loss: 8.4415e-04 - accuracy: 1.0000 - val_loss: 2.7375 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 984/4000\n",
      "2/2 - 0s - loss: 8.4177e-04 - accuracy: 1.0000 - val_loss: 2.7383 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 985/4000\n",
      "2/2 - 0s - loss: 8.3949e-04 - accuracy: 1.0000 - val_loss: 2.7392 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 986/4000\n",
      "2/2 - 0s - loss: 8.3758e-04 - accuracy: 1.0000 - val_loss: 2.7401 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 987/4000\n",
      "2/2 - 0s - loss: 8.3515e-04 - accuracy: 1.0000 - val_loss: 2.7409 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 988/4000\n",
      "2/2 - 0s - loss: 8.3311e-04 - accuracy: 1.0000 - val_loss: 2.7418 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 989/4000\n",
      "2/2 - 0s - loss: 8.3087e-04 - accuracy: 1.0000 - val_loss: 2.7425 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 990/4000\n",
      "2/2 - 0s - loss: 8.2865e-04 - accuracy: 1.0000 - val_loss: 2.7432 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 991/4000\n",
      "2/2 - 0s - loss: 8.2634e-04 - accuracy: 1.0000 - val_loss: 2.7440 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 992/4000\n",
      "2/2 - 0s - loss: 8.2434e-04 - accuracy: 1.0000 - val_loss: 2.7448 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 993/4000\n",
      "2/2 - 0s - loss: 8.2208e-04 - accuracy: 1.0000 - val_loss: 2.7456 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 994/4000\n",
      "2/2 - 0s - loss: 8.1997e-04 - accuracy: 1.0000 - val_loss: 2.7464 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 995/4000\n",
      "2/2 - 0s - loss: 8.1780e-04 - accuracy: 1.0000 - val_loss: 2.7472 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 996/4000\n",
      "2/2 - 0s - loss: 8.1549e-04 - accuracy: 1.0000 - val_loss: 2.7478 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 997/4000\n",
      "2/2 - 0s - loss: 8.1374e-04 - accuracy: 1.0000 - val_loss: 2.7485 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 998/4000\n",
      "2/2 - 0s - loss: 8.1147e-04 - accuracy: 1.0000 - val_loss: 2.7494 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 999/4000\n",
      "2/2 - 0s - loss: 8.0925e-04 - accuracy: 1.0000 - val_loss: 2.7502 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1000/4000\n",
      "2/2 - 0s - loss: 8.0719e-04 - accuracy: 1.0000 - val_loss: 2.7510 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1001/4000\n",
      "2/2 - 0s - loss: 8.0512e-04 - accuracy: 1.0000 - val_loss: 2.7519 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1002/4000\n",
      "2/2 - 0s - loss: 8.0297e-04 - accuracy: 1.0000 - val_loss: 2.7527 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1003/4000\n",
      "2/2 - 0s - loss: 8.0068e-04 - accuracy: 1.0000 - val_loss: 2.7536 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1004/4000\n",
      "2/2 - 0s - loss: 7.9877e-04 - accuracy: 1.0000 - val_loss: 2.7545 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1005/4000\n",
      "2/2 - 0s - loss: 7.9682e-04 - accuracy: 1.0000 - val_loss: 2.7553 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1006/4000\n",
      "2/2 - 0s - loss: 7.9486e-04 - accuracy: 1.0000 - val_loss: 2.7563 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1007/4000\n",
      "2/2 - 0s - loss: 7.9252e-04 - accuracy: 1.0000 - val_loss: 2.7570 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1008/4000\n",
      "2/2 - 0s - loss: 7.9041e-04 - accuracy: 1.0000 - val_loss: 2.7579 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1009/4000\n",
      "2/2 - 0s - loss: 7.8844e-04 - accuracy: 1.0000 - val_loss: 2.7587 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1010/4000\n",
      "2/2 - 0s - loss: 7.8626e-04 - accuracy: 1.0000 - val_loss: 2.7594 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1011/4000\n",
      "2/2 - 0s - loss: 7.8438e-04 - accuracy: 1.0000 - val_loss: 2.7603 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1012/4000\n",
      "2/2 - 0s - loss: 7.8212e-04 - accuracy: 1.0000 - val_loss: 2.7610 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1013/4000\n",
      "2/2 - 0s - loss: 7.8040e-04 - accuracy: 1.0000 - val_loss: 2.7617 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1014/4000\n",
      "2/2 - 0s - loss: 7.7827e-04 - accuracy: 1.0000 - val_loss: 2.7624 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1015/4000\n",
      "2/2 - 0s - loss: 7.7617e-04 - accuracy: 1.0000 - val_loss: 2.7631 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 1016/4000\n",
      "2/2 - 0s - loss: 7.7424e-04 - accuracy: 1.0000 - val_loss: 2.7639 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1017/4000\n",
      "2/2 - 0s - loss: 7.7222e-04 - accuracy: 1.0000 - val_loss: 2.7646 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1018/4000\n",
      "2/2 - 0s - loss: 7.7022e-04 - accuracy: 1.0000 - val_loss: 2.7654 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1019/4000\n",
      "2/2 - 0s - loss: 7.6831e-04 - accuracy: 1.0000 - val_loss: 2.7661 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1020/4000\n",
      "2/2 - 0s - loss: 7.6632e-04 - accuracy: 1.0000 - val_loss: 2.7669 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1021/4000\n",
      "2/2 - 0s - loss: 7.6440e-04 - accuracy: 1.0000 - val_loss: 2.7677 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1022/4000\n",
      "2/2 - 0s - loss: 7.6255e-04 - accuracy: 1.0000 - val_loss: 2.7685 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1023/4000\n",
      "2/2 - 0s - loss: 7.6043e-04 - accuracy: 1.0000 - val_loss: 2.7691 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1024/4000\n",
      "2/2 - 0s - loss: 7.5839e-04 - accuracy: 1.0000 - val_loss: 2.7699 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1025/4000\n",
      "2/2 - 0s - loss: 7.5652e-04 - accuracy: 1.0000 - val_loss: 2.7708 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1026/4000\n",
      "2/2 - 0s - loss: 7.5479e-04 - accuracy: 1.0000 - val_loss: 2.7716 - val_accuracy: 0.7250 - 42ms/epoch - 21ms/step\n",
      "Epoch 1027/4000\n",
      "2/2 - 0s - loss: 7.5256e-04 - accuracy: 1.0000 - val_loss: 2.7724 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1028/4000\n",
      "2/2 - 0s - loss: 7.5060e-04 - accuracy: 1.0000 - val_loss: 2.7732 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1029/4000\n",
      "2/2 - 0s - loss: 7.4880e-04 - accuracy: 1.0000 - val_loss: 2.7742 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1030/4000\n",
      "2/2 - 0s - loss: 7.4686e-04 - accuracy: 1.0000 - val_loss: 2.7750 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1031/4000\n",
      "2/2 - 0s - loss: 7.4490e-04 - accuracy: 1.0000 - val_loss: 2.7759 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1032/4000\n",
      "2/2 - 0s - loss: 7.4300e-04 - accuracy: 1.0000 - val_loss: 2.7767 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1033/4000\n",
      "2/2 - 0s - loss: 7.4114e-04 - accuracy: 1.0000 - val_loss: 2.7776 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1034/4000\n",
      "2/2 - 0s - loss: 7.3943e-04 - accuracy: 1.0000 - val_loss: 2.7784 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1035/4000\n",
      "2/2 - 0s - loss: 7.3732e-04 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1036/4000\n",
      "2/2 - 0s - loss: 7.3542e-04 - accuracy: 1.0000 - val_loss: 2.7802 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1037/4000\n",
      "2/2 - 0s - loss: 7.3352e-04 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1038/4000\n",
      "2/2 - 0s - loss: 7.3172e-04 - accuracy: 1.0000 - val_loss: 2.7818 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1039/4000\n",
      "2/2 - 0s - loss: 7.3008e-04 - accuracy: 1.0000 - val_loss: 2.7826 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1040/4000\n",
      "2/2 - 0s - loss: 7.2813e-04 - accuracy: 1.0000 - val_loss: 2.7834 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1041/4000\n",
      "2/2 - 0s - loss: 7.2634e-04 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1042/4000\n",
      "2/2 - 0s - loss: 7.2439e-04 - accuracy: 1.0000 - val_loss: 2.7852 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1043/4000\n",
      "2/2 - 0s - loss: 7.2275e-04 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1044/4000\n",
      "2/2 - 0s - loss: 7.2072e-04 - accuracy: 1.0000 - val_loss: 2.7868 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1045/4000\n",
      "2/2 - 0s - loss: 7.1893e-04 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1046/4000\n",
      "2/2 - 0s - loss: 7.1726e-04 - accuracy: 1.0000 - val_loss: 2.7883 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1047/4000\n",
      "2/2 - 0s - loss: 7.1525e-04 - accuracy: 1.0000 - val_loss: 2.7891 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1048/4000\n",
      "2/2 - 0s - loss: 7.1356e-04 - accuracy: 1.0000 - val_loss: 2.7898 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1049/4000\n",
      "2/2 - 0s - loss: 7.1177e-04 - accuracy: 1.0000 - val_loss: 2.7906 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1050/4000\n",
      "2/2 - 0s - loss: 7.0986e-04 - accuracy: 1.0000 - val_loss: 2.7914 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1051/4000\n",
      "2/2 - 0s - loss: 7.0808e-04 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1052/4000\n",
      "2/2 - 0s - loss: 7.0631e-04 - accuracy: 1.0000 - val_loss: 2.7929 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1053/4000\n",
      "2/2 - 0s - loss: 7.0453e-04 - accuracy: 1.0000 - val_loss: 2.7935 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1054/4000\n",
      "2/2 - 0s - loss: 7.0274e-04 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 1055/4000\n",
      "2/2 - 0s - loss: 7.0113e-04 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1056/4000\n",
      "2/2 - 0s - loss: 6.9935e-04 - accuracy: 1.0000 - val_loss: 2.7957 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1057/4000\n",
      "2/2 - 0s - loss: 6.9749e-04 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1058/4000\n",
      "2/2 - 0s - loss: 6.9584e-04 - accuracy: 1.0000 - val_loss: 2.7971 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1059/4000\n",
      "2/2 - 0s - loss: 6.9402e-04 - accuracy: 1.0000 - val_loss: 2.7979 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1060/4000\n",
      "2/2 - 0s - loss: 6.9232e-04 - accuracy: 1.0000 - val_loss: 2.7987 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1061/4000\n",
      "2/2 - 0s - loss: 6.9057e-04 - accuracy: 1.0000 - val_loss: 2.7996 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1062/4000\n",
      "2/2 - 0s - loss: 6.8916e-04 - accuracy: 1.0000 - val_loss: 2.8005 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1063/4000\n",
      "2/2 - 0s - loss: 6.8716e-04 - accuracy: 1.0000 - val_loss: 2.8013 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1064/4000\n",
      "2/2 - 0s - loss: 6.8550e-04 - accuracy: 1.0000 - val_loss: 2.8020 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1065/4000\n",
      "2/2 - 0s - loss: 6.8391e-04 - accuracy: 1.0000 - val_loss: 2.8029 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 1066/4000\n",
      "2/2 - 0s - loss: 6.8220e-04 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1067/4000\n",
      "2/2 - 0s - loss: 6.8056e-04 - accuracy: 1.0000 - val_loss: 2.8045 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1068/4000\n",
      "2/2 - 0s - loss: 6.7877e-04 - accuracy: 1.0000 - val_loss: 2.8053 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1069/4000\n",
      "2/2 - 0s - loss: 6.7704e-04 - accuracy: 1.0000 - val_loss: 2.8061 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1070/4000\n",
      "2/2 - 0s - loss: 6.7555e-04 - accuracy: 1.0000 - val_loss: 2.8068 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1071/4000\n",
      "2/2 - 0s - loss: 6.7385e-04 - accuracy: 1.0000 - val_loss: 2.8076 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 1072/4000\n",
      "2/2 - 0s - loss: 6.7227e-04 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1073/4000\n",
      "2/2 - 0s - loss: 6.7051e-04 - accuracy: 1.0000 - val_loss: 2.8092 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1074/4000\n",
      "2/2 - 0s - loss: 6.6914e-04 - accuracy: 1.0000 - val_loss: 2.8102 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1075/4000\n",
      "2/2 - 0s - loss: 6.6748e-04 - accuracy: 1.0000 - val_loss: 2.8108 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1076/4000\n",
      "2/2 - 0s - loss: 6.6575e-04 - accuracy: 1.0000 - val_loss: 2.8114 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1077/4000\n",
      "2/2 - 0s - loss: 6.6413e-04 - accuracy: 1.0000 - val_loss: 2.8121 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1078/4000\n",
      "2/2 - 0s - loss: 6.6253e-04 - accuracy: 1.0000 - val_loss: 2.8128 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1079/4000\n",
      "2/2 - 0s - loss: 6.6082e-04 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1080/4000\n",
      "2/2 - 0s - loss: 6.5922e-04 - accuracy: 1.0000 - val_loss: 2.8144 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 1081/4000\n",
      "2/2 - 0s - loss: 6.5754e-04 - accuracy: 1.0000 - val_loss: 2.8153 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1082/4000\n",
      "2/2 - 0s - loss: 6.5629e-04 - accuracy: 1.0000 - val_loss: 2.8160 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1083/4000\n",
      "2/2 - 0s - loss: 6.5453e-04 - accuracy: 1.0000 - val_loss: 2.8167 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1084/4000\n",
      "2/2 - 0s - loss: 6.5301e-04 - accuracy: 1.0000 - val_loss: 2.8176 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1085/4000\n",
      "2/2 - 0s - loss: 6.5139e-04 - accuracy: 1.0000 - val_loss: 2.8183 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1086/4000\n",
      "2/2 - 0s - loss: 6.4977e-04 - accuracy: 1.0000 - val_loss: 2.8191 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1087/4000\n",
      "2/2 - 0s - loss: 6.4814e-04 - accuracy: 1.0000 - val_loss: 2.8199 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1088/4000\n",
      "2/2 - 0s - loss: 6.4664e-04 - accuracy: 1.0000 - val_loss: 2.8207 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1089/4000\n",
      "2/2 - 0s - loss: 6.4506e-04 - accuracy: 1.0000 - val_loss: 2.8214 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1090/4000\n",
      "2/2 - 0s - loss: 6.4352e-04 - accuracy: 1.0000 - val_loss: 2.8222 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1091/4000\n",
      "2/2 - 0s - loss: 6.4206e-04 - accuracy: 1.0000 - val_loss: 2.8230 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1092/4000\n",
      "2/2 - 0s - loss: 6.4041e-04 - accuracy: 1.0000 - val_loss: 2.8238 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1093/4000\n",
      "2/2 - 0s - loss: 6.3898e-04 - accuracy: 1.0000 - val_loss: 2.8244 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1094/4000\n",
      "2/2 - 0s - loss: 6.3727e-04 - accuracy: 1.0000 - val_loss: 2.8252 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 1095/4000\n",
      "2/2 - 0s - loss: 6.3579e-04 - accuracy: 1.0000 - val_loss: 2.8260 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1096/4000\n",
      "2/2 - 0s - loss: 6.3417e-04 - accuracy: 1.0000 - val_loss: 2.8268 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1097/4000\n",
      "2/2 - 0s - loss: 6.3286e-04 - accuracy: 1.0000 - val_loss: 2.8276 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1098/4000\n",
      "2/2 - 0s - loss: 6.3118e-04 - accuracy: 1.0000 - val_loss: 2.8282 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1099/4000\n",
      "2/2 - 0s - loss: 6.2972e-04 - accuracy: 1.0000 - val_loss: 2.8287 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1100/4000\n",
      "2/2 - 0s - loss: 6.2821e-04 - accuracy: 1.0000 - val_loss: 2.8294 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1101/4000\n",
      "2/2 - 0s - loss: 6.2670e-04 - accuracy: 1.0000 - val_loss: 2.8302 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1102/4000\n",
      "2/2 - 0s - loss: 6.2515e-04 - accuracy: 1.0000 - val_loss: 2.8310 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1103/4000\n",
      "2/2 - 0s - loss: 6.2364e-04 - accuracy: 1.0000 - val_loss: 2.8319 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1104/4000\n",
      "2/2 - 0s - loss: 6.2224e-04 - accuracy: 1.0000 - val_loss: 2.8327 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1105/4000\n",
      "2/2 - 0s - loss: 6.2061e-04 - accuracy: 1.0000 - val_loss: 2.8333 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1106/4000\n",
      "2/2 - 0s - loss: 6.1920e-04 - accuracy: 1.0000 - val_loss: 2.8341 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1107/4000\n",
      "2/2 - 0s - loss: 6.1775e-04 - accuracy: 1.0000 - val_loss: 2.8348 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1108/4000\n",
      "2/2 - 0s - loss: 6.1636e-04 - accuracy: 1.0000 - val_loss: 2.8356 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1109/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 6.1490e-04 - accuracy: 1.0000 - val_loss: 2.8363 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1110/4000\n",
      "2/2 - 0s - loss: 6.1335e-04 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1111/4000\n",
      "2/2 - 0s - loss: 6.1197e-04 - accuracy: 1.0000 - val_loss: 2.8378 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1112/4000\n",
      "2/2 - 0s - loss: 6.1048e-04 - accuracy: 1.0000 - val_loss: 2.8385 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1113/4000\n",
      "2/2 - 0s - loss: 6.0915e-04 - accuracy: 1.0000 - val_loss: 2.8391 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1114/4000\n",
      "2/2 - 0s - loss: 6.0760e-04 - accuracy: 1.0000 - val_loss: 2.8399 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1115/4000\n",
      "2/2 - 0s - loss: 6.0619e-04 - accuracy: 1.0000 - val_loss: 2.8406 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1116/4000\n",
      "2/2 - 0s - loss: 6.0476e-04 - accuracy: 1.0000 - val_loss: 2.8414 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1117/4000\n",
      "2/2 - 0s - loss: 6.0337e-04 - accuracy: 1.0000 - val_loss: 2.8421 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1118/4000\n",
      "2/2 - 0s - loss: 6.0185e-04 - accuracy: 1.0000 - val_loss: 2.8429 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1119/4000\n",
      "2/2 - 0s - loss: 6.0052e-04 - accuracy: 1.0000 - val_loss: 2.8437 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1120/4000\n",
      "2/2 - 0s - loss: 5.9912e-04 - accuracy: 1.0000 - val_loss: 2.8445 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1121/4000\n",
      "2/2 - 0s - loss: 5.9770e-04 - accuracy: 1.0000 - val_loss: 2.8451 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1122/4000\n",
      "2/2 - 0s - loss: 5.9646e-04 - accuracy: 1.0000 - val_loss: 2.8457 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1123/4000\n",
      "2/2 - 0s - loss: 5.9499e-04 - accuracy: 1.0000 - val_loss: 2.8465 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1124/4000\n",
      "2/2 - 0s - loss: 5.9352e-04 - accuracy: 1.0000 - val_loss: 2.8473 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1125/4000\n",
      "2/2 - 0s - loss: 5.9208e-04 - accuracy: 1.0000 - val_loss: 2.8480 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1126/4000\n",
      "2/2 - 0s - loss: 5.9092e-04 - accuracy: 1.0000 - val_loss: 2.8486 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1127/4000\n",
      "2/2 - 0s - loss: 5.8948e-04 - accuracy: 1.0000 - val_loss: 2.8495 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 1128/4000\n",
      "2/2 - 0s - loss: 5.8812e-04 - accuracy: 1.0000 - val_loss: 2.8502 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1129/4000\n",
      "2/2 - 0s - loss: 5.8665e-04 - accuracy: 1.0000 - val_loss: 2.8509 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1130/4000\n",
      "2/2 - 0s - loss: 5.8524e-04 - accuracy: 1.0000 - val_loss: 2.8517 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1131/4000\n",
      "2/2 - 0s - loss: 5.8397e-04 - accuracy: 1.0000 - val_loss: 2.8524 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1132/4000\n",
      "2/2 - 0s - loss: 5.8260e-04 - accuracy: 1.0000 - val_loss: 2.8531 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 1133/4000\n",
      "2/2 - 0s - loss: 5.8119e-04 - accuracy: 1.0000 - val_loss: 2.8537 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1134/4000\n",
      "2/2 - 0s - loss: 5.7991e-04 - accuracy: 1.0000 - val_loss: 2.8543 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1135/4000\n",
      "2/2 - 0s - loss: 5.7855e-04 - accuracy: 1.0000 - val_loss: 2.8550 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1136/4000\n",
      "2/2 - 0s - loss: 5.7718e-04 - accuracy: 1.0000 - val_loss: 2.8558 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1137/4000\n",
      "2/2 - 0s - loss: 5.7588e-04 - accuracy: 1.0000 - val_loss: 2.8566 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1138/4000\n",
      "2/2 - 0s - loss: 5.7444e-04 - accuracy: 1.0000 - val_loss: 2.8574 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1139/4000\n",
      "2/2 - 0s - loss: 5.7321e-04 - accuracy: 1.0000 - val_loss: 2.8582 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1140/4000\n",
      "2/2 - 0s - loss: 5.7190e-04 - accuracy: 1.0000 - val_loss: 2.8590 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1141/4000\n",
      "2/2 - 0s - loss: 5.7064e-04 - accuracy: 1.0000 - val_loss: 2.8598 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1142/4000\n",
      "2/2 - 0s - loss: 5.6928e-04 - accuracy: 1.0000 - val_loss: 2.8605 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1143/4000\n",
      "2/2 - 0s - loss: 5.6792e-04 - accuracy: 1.0000 - val_loss: 2.8612 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1144/4000\n",
      "2/2 - 0s - loss: 5.6685e-04 - accuracy: 1.0000 - val_loss: 2.8619 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1145/4000\n",
      "2/2 - 0s - loss: 5.6536e-04 - accuracy: 1.0000 - val_loss: 2.8628 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1146/4000\n",
      "2/2 - 0s - loss: 5.6401e-04 - accuracy: 1.0000 - val_loss: 2.8638 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1147/4000\n",
      "2/2 - 0s - loss: 5.6272e-04 - accuracy: 1.0000 - val_loss: 2.8646 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1148/4000\n",
      "2/2 - 0s - loss: 5.6147e-04 - accuracy: 1.0000 - val_loss: 2.8653 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1149/4000\n",
      "2/2 - 0s - loss: 5.6015e-04 - accuracy: 1.0000 - val_loss: 2.8661 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1150/4000\n",
      "2/2 - 0s - loss: 5.5890e-04 - accuracy: 1.0000 - val_loss: 2.8668 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1151/4000\n",
      "2/2 - 0s - loss: 5.5763e-04 - accuracy: 1.0000 - val_loss: 2.8675 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1152/4000\n",
      "2/2 - 0s - loss: 5.5659e-04 - accuracy: 1.0000 - val_loss: 2.8684 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1153/4000\n",
      "2/2 - 0s - loss: 5.5509e-04 - accuracy: 1.0000 - val_loss: 2.8691 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1154/4000\n",
      "2/2 - 0s - loss: 5.5393e-04 - accuracy: 1.0000 - val_loss: 2.8697 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1155/4000\n",
      "2/2 - 0s - loss: 5.5247e-04 - accuracy: 1.0000 - val_loss: 2.8703 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1156/4000\n",
      "2/2 - 0s - loss: 5.5131e-04 - accuracy: 1.0000 - val_loss: 2.8710 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1157/4000\n",
      "2/2 - 0s - loss: 5.4999e-04 - accuracy: 1.0000 - val_loss: 2.8718 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1158/4000\n",
      "2/2 - 0s - loss: 5.4890e-04 - accuracy: 1.0000 - val_loss: 2.8726 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1159/4000\n",
      "2/2 - 0s - loss: 5.4764e-04 - accuracy: 1.0000 - val_loss: 2.8733 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1160/4000\n",
      "2/2 - 0s - loss: 5.4633e-04 - accuracy: 1.0000 - val_loss: 2.8740 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1161/4000\n",
      "2/2 - 0s - loss: 5.4512e-04 - accuracy: 1.0000 - val_loss: 2.8746 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1162/4000\n",
      "2/2 - 0s - loss: 5.4392e-04 - accuracy: 1.0000 - val_loss: 2.8751 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1163/4000\n",
      "2/2 - 0s - loss: 5.4266e-04 - accuracy: 1.0000 - val_loss: 2.8758 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1164/4000\n",
      "2/2 - 0s - loss: 5.4151e-04 - accuracy: 1.0000 - val_loss: 2.8764 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1165/4000\n",
      "2/2 - 0s - loss: 5.4022e-04 - accuracy: 1.0000 - val_loss: 2.8772 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1166/4000\n",
      "2/2 - 0s - loss: 5.3899e-04 - accuracy: 1.0000 - val_loss: 2.8780 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1167/4000\n",
      "2/2 - 0s - loss: 5.3775e-04 - accuracy: 1.0000 - val_loss: 2.8788 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1168/4000\n",
      "2/2 - 0s - loss: 5.3649e-04 - accuracy: 1.0000 - val_loss: 2.8795 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1169/4000\n",
      "2/2 - 0s - loss: 5.3532e-04 - accuracy: 1.0000 - val_loss: 2.8802 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1170/4000\n",
      "2/2 - 0s - loss: 5.3403e-04 - accuracy: 1.0000 - val_loss: 2.8808 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1171/4000\n",
      "2/2 - 0s - loss: 5.3295e-04 - accuracy: 1.0000 - val_loss: 2.8814 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1172/4000\n",
      "2/2 - 0s - loss: 5.3163e-04 - accuracy: 1.0000 - val_loss: 2.8820 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1173/4000\n",
      "2/2 - 0s - loss: 5.3045e-04 - accuracy: 1.0000 - val_loss: 2.8827 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1174/4000\n",
      "2/2 - 0s - loss: 5.2927e-04 - accuracy: 1.0000 - val_loss: 2.8834 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1175/4000\n",
      "2/2 - 0s - loss: 5.2802e-04 - accuracy: 1.0000 - val_loss: 2.8841 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1176/4000\n",
      "2/2 - 0s - loss: 5.2695e-04 - accuracy: 1.0000 - val_loss: 2.8848 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1177/4000\n",
      "2/2 - 0s - loss: 5.2573e-04 - accuracy: 1.0000 - val_loss: 2.8856 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1178/4000\n",
      "2/2 - 0s - loss: 5.2458e-04 - accuracy: 1.0000 - val_loss: 2.8863 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1179/4000\n",
      "2/2 - 0s - loss: 5.2339e-04 - accuracy: 1.0000 - val_loss: 2.8869 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1180/4000\n",
      "2/2 - 0s - loss: 5.2231e-04 - accuracy: 1.0000 - val_loss: 2.8877 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1181/4000\n",
      "2/2 - 0s - loss: 5.2108e-04 - accuracy: 1.0000 - val_loss: 2.8884 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1182/4000\n",
      "2/2 - 0s - loss: 5.2000e-04 - accuracy: 1.0000 - val_loss: 2.8891 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1183/4000\n",
      "2/2 - 0s - loss: 5.1874e-04 - accuracy: 1.0000 - val_loss: 2.8898 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1184/4000\n",
      "2/2 - 0s - loss: 5.1756e-04 - accuracy: 1.0000 - val_loss: 2.8905 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1185/4000\n",
      "2/2 - 0s - loss: 5.1648e-04 - accuracy: 1.0000 - val_loss: 2.8913 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1186/4000\n",
      "2/2 - 0s - loss: 5.1535e-04 - accuracy: 1.0000 - val_loss: 2.8920 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1187/4000\n",
      "2/2 - 0s - loss: 5.1416e-04 - accuracy: 1.0000 - val_loss: 2.8928 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1188/4000\n",
      "2/2 - 0s - loss: 5.1302e-04 - accuracy: 1.0000 - val_loss: 2.8935 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1189/4000\n",
      "2/2 - 0s - loss: 5.1190e-04 - accuracy: 1.0000 - val_loss: 2.8941 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1190/4000\n",
      "2/2 - 0s - loss: 5.1073e-04 - accuracy: 1.0000 - val_loss: 2.8948 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1191/4000\n",
      "2/2 - 0s - loss: 5.0965e-04 - accuracy: 1.0000 - val_loss: 2.8955 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1192/4000\n",
      "2/2 - 0s - loss: 5.0854e-04 - accuracy: 1.0000 - val_loss: 2.8962 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1193/4000\n",
      "2/2 - 0s - loss: 5.0739e-04 - accuracy: 1.0000 - val_loss: 2.8969 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1194/4000\n",
      "2/2 - 0s - loss: 5.0635e-04 - accuracy: 1.0000 - val_loss: 2.8976 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1195/4000\n",
      "2/2 - 0s - loss: 5.0523e-04 - accuracy: 1.0000 - val_loss: 2.8981 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1196/4000\n",
      "2/2 - 0s - loss: 5.0421e-04 - accuracy: 1.0000 - val_loss: 2.8989 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1197/4000\n",
      "2/2 - 0s - loss: 5.0303e-04 - accuracy: 1.0000 - val_loss: 2.8997 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1198/4000\n",
      "2/2 - 0s - loss: 5.0196e-04 - accuracy: 1.0000 - val_loss: 2.9004 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1199/4000\n",
      "2/2 - 0s - loss: 5.0088e-04 - accuracy: 1.0000 - val_loss: 2.9010 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1200/4000\n",
      "2/2 - 0s - loss: 4.9967e-04 - accuracy: 1.0000 - val_loss: 2.9016 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1201/4000\n",
      "2/2 - 0s - loss: 4.9871e-04 - accuracy: 1.0000 - val_loss: 2.9023 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1202/4000\n",
      "2/2 - 0s - loss: 4.9753e-04 - accuracy: 1.0000 - val_loss: 2.9030 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1203/4000\n",
      "2/2 - 0s - loss: 4.9637e-04 - accuracy: 1.0000 - val_loss: 2.9036 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1204/4000\n",
      "2/2 - 0s - loss: 4.9543e-04 - accuracy: 1.0000 - val_loss: 2.9040 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1205/4000\n",
      "2/2 - 0s - loss: 4.9432e-04 - accuracy: 1.0000 - val_loss: 2.9047 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1206/4000\n",
      "2/2 - 0s - loss: 4.9310e-04 - accuracy: 1.0000 - val_loss: 2.9055 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1207/4000\n",
      "2/2 - 0s - loss: 4.9209e-04 - accuracy: 1.0000 - val_loss: 2.9063 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1208/4000\n",
      "2/2 - 0s - loss: 4.9100e-04 - accuracy: 1.0000 - val_loss: 2.9070 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1209/4000\n",
      "2/2 - 0s - loss: 4.8997e-04 - accuracy: 1.0000 - val_loss: 2.9078 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1210/4000\n",
      "2/2 - 0s - loss: 4.8894e-04 - accuracy: 1.0000 - val_loss: 2.9085 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1211/4000\n",
      "2/2 - 0s - loss: 4.8776e-04 - accuracy: 1.0000 - val_loss: 2.9093 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1212/4000\n",
      "2/2 - 0s - loss: 4.8669e-04 - accuracy: 1.0000 - val_loss: 2.9100 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1213/4000\n",
      "2/2 - 0s - loss: 4.8557e-04 - accuracy: 1.0000 - val_loss: 2.9106 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1214/4000\n",
      "2/2 - 0s - loss: 4.8455e-04 - accuracy: 1.0000 - val_loss: 2.9111 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1215/4000\n",
      "2/2 - 0s - loss: 4.8356e-04 - accuracy: 1.0000 - val_loss: 2.9117 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1216/4000\n",
      "2/2 - 0s - loss: 4.8246e-04 - accuracy: 1.0000 - val_loss: 2.9124 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1217/4000\n",
      "2/2 - 0s - loss: 4.8139e-04 - accuracy: 1.0000 - val_loss: 2.9130 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1218/4000\n",
      "2/2 - 0s - loss: 4.8028e-04 - accuracy: 1.0000 - val_loss: 2.9137 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1219/4000\n",
      "2/2 - 0s - loss: 4.7931e-04 - accuracy: 1.0000 - val_loss: 2.9144 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1220/4000\n",
      "2/2 - 0s - loss: 4.7832e-04 - accuracy: 1.0000 - val_loss: 2.9151 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1221/4000\n",
      "2/2 - 0s - loss: 4.7721e-04 - accuracy: 1.0000 - val_loss: 2.9159 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1222/4000\n",
      "2/2 - 0s - loss: 4.7612e-04 - accuracy: 1.0000 - val_loss: 2.9166 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1223/4000\n",
      "2/2 - 0s - loss: 4.7527e-04 - accuracy: 1.0000 - val_loss: 2.9173 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1224/4000\n",
      "2/2 - 0s - loss: 4.7402e-04 - accuracy: 1.0000 - val_loss: 2.9181 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1225/4000\n",
      "2/2 - 0s - loss: 4.7308e-04 - accuracy: 1.0000 - val_loss: 2.9189 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1226/4000\n",
      "2/2 - 0s - loss: 4.7204e-04 - accuracy: 1.0000 - val_loss: 2.9196 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1227/4000\n",
      "2/2 - 0s - loss: 4.7098e-04 - accuracy: 1.0000 - val_loss: 2.9203 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1228/4000\n",
      "2/2 - 0s - loss: 4.6994e-04 - accuracy: 1.0000 - val_loss: 2.9210 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1229/4000\n",
      "2/2 - 0s - loss: 4.6892e-04 - accuracy: 1.0000 - val_loss: 2.9217 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1230/4000\n",
      "2/2 - 0s - loss: 4.6785e-04 - accuracy: 1.0000 - val_loss: 2.9225 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1231/4000\n",
      "2/2 - 0s - loss: 4.6691e-04 - accuracy: 1.0000 - val_loss: 2.9232 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1232/4000\n",
      "2/2 - 0s - loss: 4.6599e-04 - accuracy: 1.0000 - val_loss: 2.9239 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1233/4000\n",
      "2/2 - 0s - loss: 4.6489e-04 - accuracy: 1.0000 - val_loss: 2.9246 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1234/4000\n",
      "2/2 - 0s - loss: 4.6393e-04 - accuracy: 1.0000 - val_loss: 2.9253 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1235/4000\n",
      "2/2 - 0s - loss: 4.6289e-04 - accuracy: 1.0000 - val_loss: 2.9260 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1236/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 4.6188e-04 - accuracy: 1.0000 - val_loss: 2.9268 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1237/4000\n",
      "2/2 - 0s - loss: 4.6093e-04 - accuracy: 1.0000 - val_loss: 2.9276 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1238/4000\n",
      "2/2 - 0s - loss: 4.5999e-04 - accuracy: 1.0000 - val_loss: 2.9284 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1239/4000\n",
      "2/2 - 0s - loss: 4.5893e-04 - accuracy: 1.0000 - val_loss: 2.9291 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1240/4000\n",
      "2/2 - 0s - loss: 4.5797e-04 - accuracy: 1.0000 - val_loss: 2.9298 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1241/4000\n",
      "2/2 - 0s - loss: 4.5701e-04 - accuracy: 1.0000 - val_loss: 2.9305 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1242/4000\n",
      "2/2 - 0s - loss: 4.5602e-04 - accuracy: 1.0000 - val_loss: 2.9312 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1243/4000\n",
      "2/2 - 0s - loss: 4.5506e-04 - accuracy: 1.0000 - val_loss: 2.9319 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1244/4000\n",
      "2/2 - 0s - loss: 4.5404e-04 - accuracy: 1.0000 - val_loss: 2.9325 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1245/4000\n",
      "2/2 - 0s - loss: 4.5307e-04 - accuracy: 1.0000 - val_loss: 2.9330 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1246/4000\n",
      "2/2 - 0s - loss: 4.5215e-04 - accuracy: 1.0000 - val_loss: 2.9337 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1247/4000\n",
      "2/2 - 0s - loss: 4.5114e-04 - accuracy: 1.0000 - val_loss: 2.9343 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1248/4000\n",
      "2/2 - 0s - loss: 4.5021e-04 - accuracy: 1.0000 - val_loss: 2.9351 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1249/4000\n",
      "2/2 - 0s - loss: 4.4927e-04 - accuracy: 1.0000 - val_loss: 2.9359 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1250/4000\n",
      "2/2 - 0s - loss: 4.4826e-04 - accuracy: 1.0000 - val_loss: 2.9366 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1251/4000\n",
      "2/2 - 0s - loss: 4.4744e-04 - accuracy: 1.0000 - val_loss: 2.9372 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1252/4000\n",
      "2/2 - 0s - loss: 4.4639e-04 - accuracy: 1.0000 - val_loss: 2.9379 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1253/4000\n",
      "2/2 - 0s - loss: 4.4538e-04 - accuracy: 1.0000 - val_loss: 2.9386 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1254/4000\n",
      "2/2 - 0s - loss: 4.4452e-04 - accuracy: 1.0000 - val_loss: 2.9392 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1255/4000\n",
      "2/2 - 0s - loss: 4.4354e-04 - accuracy: 1.0000 - val_loss: 2.9399 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1256/4000\n",
      "2/2 - 0s - loss: 4.4260e-04 - accuracy: 1.0000 - val_loss: 2.9405 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1257/4000\n",
      "2/2 - 0s - loss: 4.4172e-04 - accuracy: 1.0000 - val_loss: 2.9411 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1258/4000\n",
      "2/2 - 0s - loss: 4.4062e-04 - accuracy: 1.0000 - val_loss: 2.9417 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1259/4000\n",
      "2/2 - 0s - loss: 4.3968e-04 - accuracy: 1.0000 - val_loss: 2.9423 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1260/4000\n",
      "2/2 - 0s - loss: 4.3881e-04 - accuracy: 1.0000 - val_loss: 2.9430 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1261/4000\n",
      "2/2 - 0s - loss: 4.3786e-04 - accuracy: 1.0000 - val_loss: 2.9435 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1262/4000\n",
      "2/2 - 0s - loss: 4.3699e-04 - accuracy: 1.0000 - val_loss: 2.9442 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1263/4000\n",
      "2/2 - 0s - loss: 4.3604e-04 - accuracy: 1.0000 - val_loss: 2.9448 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1264/4000\n",
      "2/2 - 0s - loss: 4.3511e-04 - accuracy: 1.0000 - val_loss: 2.9453 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1265/4000\n",
      "2/2 - 0s - loss: 4.3426e-04 - accuracy: 1.0000 - val_loss: 2.9458 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1266/4000\n",
      "2/2 - 0s - loss: 4.3327e-04 - accuracy: 1.0000 - val_loss: 2.9465 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1267/4000\n",
      "2/2 - 0s - loss: 4.3236e-04 - accuracy: 1.0000 - val_loss: 2.9470 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1268/4000\n",
      "2/2 - 0s - loss: 4.3149e-04 - accuracy: 1.0000 - val_loss: 2.9476 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1269/4000\n",
      "2/2 - 0s - loss: 4.3061e-04 - accuracy: 1.0000 - val_loss: 2.9482 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1270/4000\n",
      "2/2 - 0s - loss: 4.2965e-04 - accuracy: 1.0000 - val_loss: 2.9487 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1271/4000\n",
      "2/2 - 0s - loss: 4.2875e-04 - accuracy: 1.0000 - val_loss: 2.9492 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1272/4000\n",
      "2/2 - 0s - loss: 4.2784e-04 - accuracy: 1.0000 - val_loss: 2.9497 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1273/4000\n",
      "2/2 - 0s - loss: 4.2691e-04 - accuracy: 1.0000 - val_loss: 2.9503 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1274/4000\n",
      "2/2 - 0s - loss: 4.2615e-04 - accuracy: 1.0000 - val_loss: 2.9508 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1275/4000\n",
      "2/2 - 0s - loss: 4.2521e-04 - accuracy: 1.0000 - val_loss: 2.9514 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1276/4000\n",
      "2/2 - 0s - loss: 4.2432e-04 - accuracy: 1.0000 - val_loss: 2.9520 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1277/4000\n",
      "2/2 - 0s - loss: 4.2342e-04 - accuracy: 1.0000 - val_loss: 2.9526 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1278/4000\n",
      "2/2 - 0s - loss: 4.2258e-04 - accuracy: 1.0000 - val_loss: 2.9534 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1279/4000\n",
      "2/2 - 0s - loss: 4.2169e-04 - accuracy: 1.0000 - val_loss: 2.9541 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1280/4000\n",
      "2/2 - 0s - loss: 4.2082e-04 - accuracy: 1.0000 - val_loss: 2.9549 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1281/4000\n",
      "2/2 - 0s - loss: 4.1997e-04 - accuracy: 1.0000 - val_loss: 2.9555 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1282/4000\n",
      "2/2 - 0s - loss: 4.1914e-04 - accuracy: 1.0000 - val_loss: 2.9563 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1283/4000\n",
      "2/2 - 0s - loss: 4.1825e-04 - accuracy: 1.0000 - val_loss: 2.9568 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1284/4000\n",
      "2/2 - 0s - loss: 4.1737e-04 - accuracy: 1.0000 - val_loss: 2.9574 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1285/4000\n",
      "2/2 - 0s - loss: 4.1643e-04 - accuracy: 1.0000 - val_loss: 2.9580 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1286/4000\n",
      "2/2 - 0s - loss: 4.1564e-04 - accuracy: 1.0000 - val_loss: 2.9587 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1287/4000\n",
      "2/2 - 0s - loss: 4.1477e-04 - accuracy: 1.0000 - val_loss: 2.9594 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1288/4000\n",
      "2/2 - 0s - loss: 4.1391e-04 - accuracy: 1.0000 - val_loss: 2.9601 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1289/4000\n",
      "2/2 - 0s - loss: 4.1302e-04 - accuracy: 1.0000 - val_loss: 2.9607 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1290/4000\n",
      "2/2 - 0s - loss: 4.1218e-04 - accuracy: 1.0000 - val_loss: 2.9614 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1291/4000\n",
      "2/2 - 0s - loss: 4.1135e-04 - accuracy: 1.0000 - val_loss: 2.9620 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1292/4000\n",
      "2/2 - 0s - loss: 4.1049e-04 - accuracy: 1.0000 - val_loss: 2.9627 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1293/4000\n",
      "2/2 - 0s - loss: 4.0962e-04 - accuracy: 1.0000 - val_loss: 2.9633 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1294/4000\n",
      "2/2 - 0s - loss: 4.0885e-04 - accuracy: 1.0000 - val_loss: 2.9638 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 1295/4000\n",
      "2/2 - 0s - loss: 4.0798e-04 - accuracy: 1.0000 - val_loss: 2.9644 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 1296/4000\n",
      "2/2 - 0s - loss: 4.0714e-04 - accuracy: 1.0000 - val_loss: 2.9650 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 1297/4000\n",
      "2/2 - 0s - loss: 4.0640e-04 - accuracy: 1.0000 - val_loss: 2.9658 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 1298/4000\n",
      "2/2 - 0s - loss: 4.0546e-04 - accuracy: 1.0000 - val_loss: 2.9665 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1299/4000\n",
      "2/2 - 0s - loss: 4.0465e-04 - accuracy: 1.0000 - val_loss: 2.9671 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1300/4000\n",
      "2/2 - 0s - loss: 4.0382e-04 - accuracy: 1.0000 - val_loss: 2.9678 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1301/4000\n",
      "2/2 - 0s - loss: 4.0297e-04 - accuracy: 1.0000 - val_loss: 2.9684 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1302/4000\n",
      "2/2 - 0s - loss: 4.0219e-04 - accuracy: 1.0000 - val_loss: 2.9690 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1303/4000\n",
      "2/2 - 0s - loss: 4.0140e-04 - accuracy: 1.0000 - val_loss: 2.9696 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1304/4000\n",
      "2/2 - 0s - loss: 4.0059e-04 - accuracy: 1.0000 - val_loss: 2.9703 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 1305/4000\n",
      "2/2 - 0s - loss: 3.9966e-04 - accuracy: 1.0000 - val_loss: 2.9710 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1306/4000\n",
      "2/2 - 0s - loss: 3.9894e-04 - accuracy: 1.0000 - val_loss: 2.9717 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1307/4000\n",
      "2/2 - 0s - loss: 3.9804e-04 - accuracy: 1.0000 - val_loss: 2.9724 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1308/4000\n",
      "2/2 - 0s - loss: 3.9722e-04 - accuracy: 1.0000 - val_loss: 2.9730 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 1309/4000\n",
      "2/2 - 0s - loss: 3.9648e-04 - accuracy: 1.0000 - val_loss: 2.9737 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1310/4000\n",
      "2/2 - 0s - loss: 3.9566e-04 - accuracy: 1.0000 - val_loss: 2.9742 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1311/4000\n",
      "2/2 - 0s - loss: 3.9494e-04 - accuracy: 1.0000 - val_loss: 2.9747 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1312/4000\n",
      "2/2 - 0s - loss: 3.9407e-04 - accuracy: 1.0000 - val_loss: 2.9754 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1313/4000\n",
      "2/2 - 0s - loss: 3.9319e-04 - accuracy: 1.0000 - val_loss: 2.9761 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1314/4000\n",
      "2/2 - 0s - loss: 3.9246e-04 - accuracy: 1.0000 - val_loss: 2.9767 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1315/4000\n",
      "2/2 - 0s - loss: 3.9160e-04 - accuracy: 1.0000 - val_loss: 2.9774 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1316/4000\n",
      "2/2 - 0s - loss: 3.9091e-04 - accuracy: 1.0000 - val_loss: 2.9780 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 1317/4000\n",
      "2/2 - 0s - loss: 3.9006e-04 - accuracy: 1.0000 - val_loss: 2.9786 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1318/4000\n",
      "2/2 - 0s - loss: 3.8929e-04 - accuracy: 1.0000 - val_loss: 2.9791 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1319/4000\n",
      "2/2 - 0s - loss: 3.8845e-04 - accuracy: 1.0000 - val_loss: 2.9798 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1320/4000\n",
      "2/2 - 0s - loss: 3.8770e-04 - accuracy: 1.0000 - val_loss: 2.9805 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1321/4000\n",
      "2/2 - 0s - loss: 3.8697e-04 - accuracy: 1.0000 - val_loss: 2.9811 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1322/4000\n",
      "2/2 - 0s - loss: 3.8617e-04 - accuracy: 1.0000 - val_loss: 2.9818 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1323/4000\n",
      "2/2 - 0s - loss: 3.8537e-04 - accuracy: 1.0000 - val_loss: 2.9825 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1324/4000\n",
      "2/2 - 0s - loss: 3.8458e-04 - accuracy: 1.0000 - val_loss: 2.9832 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1325/4000\n",
      "2/2 - 0s - loss: 3.8386e-04 - accuracy: 1.0000 - val_loss: 2.9838 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1326/4000\n",
      "2/2 - 0s - loss: 3.8304e-04 - accuracy: 1.0000 - val_loss: 2.9845 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1327/4000\n",
      "2/2 - 0s - loss: 3.8228e-04 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1328/4000\n",
      "2/2 - 0s - loss: 3.8153e-04 - accuracy: 1.0000 - val_loss: 2.9860 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 1329/4000\n",
      "2/2 - 0s - loss: 3.8076e-04 - accuracy: 1.0000 - val_loss: 2.9867 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1330/4000\n",
      "2/2 - 0s - loss: 3.7995e-04 - accuracy: 1.0000 - val_loss: 2.9872 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1331/4000\n",
      "2/2 - 0s - loss: 3.7931e-04 - accuracy: 1.0000 - val_loss: 2.9878 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1332/4000\n",
      "2/2 - 0s - loss: 3.7841e-04 - accuracy: 1.0000 - val_loss: 2.9884 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1333/4000\n",
      "2/2 - 0s - loss: 3.7764e-04 - accuracy: 1.0000 - val_loss: 2.9892 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 1334/4000\n",
      "2/2 - 0s - loss: 3.7695e-04 - accuracy: 1.0000 - val_loss: 2.9899 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1335/4000\n",
      "2/2 - 0s - loss: 3.7616e-04 - accuracy: 1.0000 - val_loss: 2.9906 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1336/4000\n",
      "2/2 - 0s - loss: 3.7540e-04 - accuracy: 1.0000 - val_loss: 2.9914 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1337/4000\n",
      "2/2 - 0s - loss: 3.7465e-04 - accuracy: 1.0000 - val_loss: 2.9922 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1338/4000\n",
      "2/2 - 0s - loss: 3.7387e-04 - accuracy: 1.0000 - val_loss: 2.9928 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1339/4000\n",
      "2/2 - 0s - loss: 3.7314e-04 - accuracy: 1.0000 - val_loss: 2.9936 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1340/4000\n",
      "2/2 - 0s - loss: 3.7242e-04 - accuracy: 1.0000 - val_loss: 2.9943 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1341/4000\n",
      "2/2 - 0s - loss: 3.7165e-04 - accuracy: 1.0000 - val_loss: 2.9948 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1342/4000\n",
      "2/2 - 0s - loss: 3.7091e-04 - accuracy: 1.0000 - val_loss: 2.9954 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1343/4000\n",
      "2/2 - 0s - loss: 3.7014e-04 - accuracy: 1.0000 - val_loss: 2.9961 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1344/4000\n",
      "2/2 - 0s - loss: 3.6944e-04 - accuracy: 1.0000 - val_loss: 2.9967 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1345/4000\n",
      "2/2 - 0s - loss: 3.6863e-04 - accuracy: 1.0000 - val_loss: 2.9973 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1346/4000\n",
      "2/2 - 0s - loss: 3.6793e-04 - accuracy: 1.0000 - val_loss: 2.9979 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1347/4000\n",
      "2/2 - 0s - loss: 3.6732e-04 - accuracy: 1.0000 - val_loss: 2.9987 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1348/4000\n",
      "2/2 - 0s - loss: 3.6643e-04 - accuracy: 1.0000 - val_loss: 2.9993 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1349/4000\n",
      "2/2 - 0s - loss: 3.6575e-04 - accuracy: 1.0000 - val_loss: 2.9999 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1350/4000\n",
      "2/2 - 0s - loss: 3.6509e-04 - accuracy: 1.0000 - val_loss: 3.0006 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1351/4000\n",
      "2/2 - 0s - loss: 3.6432e-04 - accuracy: 1.0000 - val_loss: 3.0011 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1352/4000\n",
      "2/2 - 0s - loss: 3.6357e-04 - accuracy: 1.0000 - val_loss: 3.0017 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1353/4000\n",
      "2/2 - 0s - loss: 3.6293e-04 - accuracy: 1.0000 - val_loss: 3.0022 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1354/4000\n",
      "2/2 - 0s - loss: 3.6223e-04 - accuracy: 1.0000 - val_loss: 3.0029 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1355/4000\n",
      "2/2 - 0s - loss: 3.6149e-04 - accuracy: 1.0000 - val_loss: 3.0034 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1356/4000\n",
      "2/2 - 0s - loss: 3.6072e-04 - accuracy: 1.0000 - val_loss: 3.0040 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1357/4000\n",
      "2/2 - 0s - loss: 3.6001e-04 - accuracy: 1.0000 - val_loss: 3.0046 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1358/4000\n",
      "2/2 - 0s - loss: 3.5924e-04 - accuracy: 1.0000 - val_loss: 3.0053 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1359/4000\n",
      "2/2 - 0s - loss: 3.5853e-04 - accuracy: 1.0000 - val_loss: 3.0059 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1360/4000\n",
      "2/2 - 0s - loss: 3.5783e-04 - accuracy: 1.0000 - val_loss: 3.0066 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1361/4000\n",
      "2/2 - 0s - loss: 3.5713e-04 - accuracy: 1.0000 - val_loss: 3.0072 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1362/4000\n",
      "2/2 - 0s - loss: 3.5643e-04 - accuracy: 1.0000 - val_loss: 3.0079 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1363/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 3.5574e-04 - accuracy: 1.0000 - val_loss: 3.0085 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1364/4000\n",
      "2/2 - 0s - loss: 3.5504e-04 - accuracy: 1.0000 - val_loss: 3.0090 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1365/4000\n",
      "2/2 - 0s - loss: 3.5429e-04 - accuracy: 1.0000 - val_loss: 3.0097 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1366/4000\n",
      "2/2 - 0s - loss: 3.5366e-04 - accuracy: 1.0000 - val_loss: 3.0104 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1367/4000\n",
      "2/2 - 0s - loss: 3.5297e-04 - accuracy: 1.0000 - val_loss: 3.0110 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1368/4000\n",
      "2/2 - 0s - loss: 3.5225e-04 - accuracy: 1.0000 - val_loss: 3.0115 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1369/4000\n",
      "2/2 - 0s - loss: 3.5153e-04 - accuracy: 1.0000 - val_loss: 3.0121 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 1370/4000\n",
      "2/2 - 0s - loss: 3.5088e-04 - accuracy: 1.0000 - val_loss: 3.0126 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 1371/4000\n",
      "2/2 - 0s - loss: 3.5017e-04 - accuracy: 1.0000 - val_loss: 3.0131 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1372/4000\n",
      "2/2 - 0s - loss: 3.4948e-04 - accuracy: 1.0000 - val_loss: 3.0137 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1373/4000\n",
      "2/2 - 0s - loss: 3.4880e-04 - accuracy: 1.0000 - val_loss: 3.0144 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1374/4000\n",
      "2/2 - 0s - loss: 3.4815e-04 - accuracy: 1.0000 - val_loss: 3.0151 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1375/4000\n",
      "2/2 - 0s - loss: 3.4749e-04 - accuracy: 1.0000 - val_loss: 3.0158 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1376/4000\n",
      "2/2 - 0s - loss: 3.4681e-04 - accuracy: 1.0000 - val_loss: 3.0164 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1377/4000\n",
      "2/2 - 0s - loss: 3.4609e-04 - accuracy: 1.0000 - val_loss: 3.0169 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1378/4000\n",
      "2/2 - 0s - loss: 3.4547e-04 - accuracy: 1.0000 - val_loss: 3.0175 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1379/4000\n",
      "2/2 - 0s - loss: 3.4476e-04 - accuracy: 1.0000 - val_loss: 3.0181 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1380/4000\n",
      "2/2 - 0s - loss: 3.4415e-04 - accuracy: 1.0000 - val_loss: 3.0186 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1381/4000\n",
      "2/2 - 0s - loss: 3.4347e-04 - accuracy: 1.0000 - val_loss: 3.0192 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1382/4000\n",
      "2/2 - 0s - loss: 3.4276e-04 - accuracy: 1.0000 - val_loss: 3.0198 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1383/4000\n",
      "2/2 - 0s - loss: 3.4213e-04 - accuracy: 1.0000 - val_loss: 3.0203 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1384/4000\n",
      "2/2 - 0s - loss: 3.4141e-04 - accuracy: 1.0000 - val_loss: 3.0209 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1385/4000\n",
      "2/2 - 0s - loss: 3.4074e-04 - accuracy: 1.0000 - val_loss: 3.0215 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1386/4000\n",
      "2/2 - 0s - loss: 3.4013e-04 - accuracy: 1.0000 - val_loss: 3.0221 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1387/4000\n",
      "2/2 - 0s - loss: 3.3945e-04 - accuracy: 1.0000 - val_loss: 3.0225 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1388/4000\n",
      "2/2 - 0s - loss: 3.3875e-04 - accuracy: 1.0000 - val_loss: 3.0230 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1389/4000\n",
      "2/2 - 0s - loss: 3.3812e-04 - accuracy: 1.0000 - val_loss: 3.0236 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1390/4000\n",
      "2/2 - 0s - loss: 3.3748e-04 - accuracy: 1.0000 - val_loss: 3.0241 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1391/4000\n",
      "2/2 - 0s - loss: 3.3678e-04 - accuracy: 1.0000 - val_loss: 3.0247 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1392/4000\n",
      "2/2 - 0s - loss: 3.3619e-04 - accuracy: 1.0000 - val_loss: 3.0253 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1393/4000\n",
      "2/2 - 0s - loss: 3.3547e-04 - accuracy: 1.0000 - val_loss: 3.0259 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1394/4000\n",
      "2/2 - 0s - loss: 3.3485e-04 - accuracy: 1.0000 - val_loss: 3.0264 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1395/4000\n",
      "2/2 - 0s - loss: 3.3425e-04 - accuracy: 1.0000 - val_loss: 3.0270 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1396/4000\n",
      "2/2 - 0s - loss: 3.3352e-04 - accuracy: 1.0000 - val_loss: 3.0276 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1397/4000\n",
      "2/2 - 0s - loss: 3.3288e-04 - accuracy: 1.0000 - val_loss: 3.0282 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1398/4000\n",
      "2/2 - 0s - loss: 3.3224e-04 - accuracy: 1.0000 - val_loss: 3.0287 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1399/4000\n",
      "2/2 - 0s - loss: 3.3161e-04 - accuracy: 1.0000 - val_loss: 3.0293 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1400/4000\n",
      "2/2 - 0s - loss: 3.3095e-04 - accuracy: 1.0000 - val_loss: 3.0299 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1401/4000\n",
      "2/2 - 0s - loss: 3.3035e-04 - accuracy: 1.0000 - val_loss: 3.0305 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1402/4000\n",
      "2/2 - 0s - loss: 3.2974e-04 - accuracy: 1.0000 - val_loss: 3.0312 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1403/4000\n",
      "2/2 - 0s - loss: 3.2912e-04 - accuracy: 1.0000 - val_loss: 3.0319 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1404/4000\n",
      "2/2 - 0s - loss: 3.2843e-04 - accuracy: 1.0000 - val_loss: 3.0326 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1405/4000\n",
      "2/2 - 0s - loss: 3.2779e-04 - accuracy: 1.0000 - val_loss: 3.0332 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1406/4000\n",
      "2/2 - 0s - loss: 3.2713e-04 - accuracy: 1.0000 - val_loss: 3.0339 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1407/4000\n",
      "2/2 - 0s - loss: 3.2655e-04 - accuracy: 1.0000 - val_loss: 3.0346 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1408/4000\n",
      "2/2 - 0s - loss: 3.2597e-04 - accuracy: 1.0000 - val_loss: 3.0351 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1409/4000\n",
      "2/2 - 0s - loss: 3.2530e-04 - accuracy: 1.0000 - val_loss: 3.0357 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1410/4000\n",
      "2/2 - 0s - loss: 3.2465e-04 - accuracy: 1.0000 - val_loss: 3.0364 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1411/4000\n",
      "2/2 - 0s - loss: 3.2408e-04 - accuracy: 1.0000 - val_loss: 3.0370 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1412/4000\n",
      "2/2 - 0s - loss: 3.2345e-04 - accuracy: 1.0000 - val_loss: 3.0377 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1413/4000\n",
      "2/2 - 0s - loss: 3.2285e-04 - accuracy: 1.0000 - val_loss: 3.0383 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1414/4000\n",
      "2/2 - 0s - loss: 3.2220e-04 - accuracy: 1.0000 - val_loss: 3.0389 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1415/4000\n",
      "2/2 - 0s - loss: 3.2155e-04 - accuracy: 1.0000 - val_loss: 3.0395 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1416/4000\n",
      "2/2 - 0s - loss: 3.2096e-04 - accuracy: 1.0000 - val_loss: 3.0401 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1417/4000\n",
      "2/2 - 0s - loss: 3.2033e-04 - accuracy: 1.0000 - val_loss: 3.0407 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1418/4000\n",
      "2/2 - 0s - loss: 3.1974e-04 - accuracy: 1.0000 - val_loss: 3.0413 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1419/4000\n",
      "2/2 - 0s - loss: 3.1915e-04 - accuracy: 1.0000 - val_loss: 3.0419 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1420/4000\n",
      "2/2 - 0s - loss: 3.1851e-04 - accuracy: 1.0000 - val_loss: 3.0424 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 1421/4000\n",
      "2/2 - 0s - loss: 3.1788e-04 - accuracy: 1.0000 - val_loss: 3.0431 - val_accuracy: 0.7250 - 115ms/epoch - 57ms/step\n",
      "Epoch 1422/4000\n",
      "2/2 - 0s - loss: 3.1730e-04 - accuracy: 1.0000 - val_loss: 3.0435 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 1423/4000\n",
      "2/2 - 0s - loss: 3.1672e-04 - accuracy: 1.0000 - val_loss: 3.0442 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 1424/4000\n",
      "2/2 - 0s - loss: 3.1611e-04 - accuracy: 1.0000 - val_loss: 3.0447 - val_accuracy: 0.7250 - 96ms/epoch - 48ms/step\n",
      "Epoch 1425/4000\n",
      "2/2 - 0s - loss: 3.1544e-04 - accuracy: 1.0000 - val_loss: 3.0454 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1426/4000\n",
      "2/2 - 0s - loss: 3.1484e-04 - accuracy: 1.0000 - val_loss: 3.0460 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/4000\n",
      "2/2 - 0s - loss: 3.1427e-04 - accuracy: 1.0000 - val_loss: 3.0467 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1428/4000\n",
      "2/2 - 0s - loss: 3.1366e-04 - accuracy: 1.0000 - val_loss: 3.0473 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1429/4000\n",
      "2/2 - 0s - loss: 3.1305e-04 - accuracy: 1.0000 - val_loss: 3.0479 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1430/4000\n",
      "2/2 - 0s - loss: 3.1240e-04 - accuracy: 1.0000 - val_loss: 3.0484 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 1431/4000\n",
      "2/2 - 0s - loss: 3.1182e-04 - accuracy: 1.0000 - val_loss: 3.0489 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1432/4000\n",
      "2/2 - 0s - loss: 3.1131e-04 - accuracy: 1.0000 - val_loss: 3.0495 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1433/4000\n",
      "2/2 - 0s - loss: 3.1068e-04 - accuracy: 1.0000 - val_loss: 3.0502 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1434/4000\n",
      "2/2 - 0s - loss: 3.1012e-04 - accuracy: 1.0000 - val_loss: 3.0510 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1435/4000\n",
      "2/2 - 0s - loss: 3.0949e-04 - accuracy: 1.0000 - val_loss: 3.0515 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1436/4000\n",
      "2/2 - 0s - loss: 3.0894e-04 - accuracy: 1.0000 - val_loss: 3.0520 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1437/4000\n",
      "2/2 - 0s - loss: 3.0837e-04 - accuracy: 1.0000 - val_loss: 3.0525 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1438/4000\n",
      "2/2 - 0s - loss: 3.0774e-04 - accuracy: 1.0000 - val_loss: 3.0530 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1439/4000\n",
      "2/2 - 0s - loss: 3.0716e-04 - accuracy: 1.0000 - val_loss: 3.0536 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1440/4000\n",
      "2/2 - 0s - loss: 3.0660e-04 - accuracy: 1.0000 - val_loss: 3.0543 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1441/4000\n",
      "2/2 - 0s - loss: 3.0607e-04 - accuracy: 1.0000 - val_loss: 3.0549 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1442/4000\n",
      "2/2 - 0s - loss: 3.0543e-04 - accuracy: 1.0000 - val_loss: 3.0555 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1443/4000\n",
      "2/2 - 0s - loss: 3.0486e-04 - accuracy: 1.0000 - val_loss: 3.0561 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1444/4000\n",
      "2/2 - 0s - loss: 3.0429e-04 - accuracy: 1.0000 - val_loss: 3.0566 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1445/4000\n",
      "2/2 - 0s - loss: 3.0370e-04 - accuracy: 1.0000 - val_loss: 3.0572 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1446/4000\n",
      "2/2 - 0s - loss: 3.0315e-04 - accuracy: 1.0000 - val_loss: 3.0578 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 1447/4000\n",
      "2/2 - 0s - loss: 3.0256e-04 - accuracy: 1.0000 - val_loss: 3.0583 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1448/4000\n",
      "2/2 - 0s - loss: 3.0196e-04 - accuracy: 1.0000 - val_loss: 3.0589 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1449/4000\n",
      "2/2 - 0s - loss: 3.0143e-04 - accuracy: 1.0000 - val_loss: 3.0595 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1450/4000\n",
      "2/2 - 0s - loss: 3.0088e-04 - accuracy: 1.0000 - val_loss: 3.0601 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1451/4000\n",
      "2/2 - 0s - loss: 3.0029e-04 - accuracy: 1.0000 - val_loss: 3.0607 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1452/4000\n",
      "2/2 - 0s - loss: 2.9973e-04 - accuracy: 1.0000 - val_loss: 3.0613 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1453/4000\n",
      "2/2 - 0s - loss: 2.9917e-04 - accuracy: 1.0000 - val_loss: 3.0619 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 1454/4000\n",
      "2/2 - 0s - loss: 2.9864e-04 - accuracy: 1.0000 - val_loss: 3.0625 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 1455/4000\n",
      "2/2 - 0s - loss: 2.9806e-04 - accuracy: 1.0000 - val_loss: 3.0629 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 1456/4000\n",
      "2/2 - 0s - loss: 2.9753e-04 - accuracy: 1.0000 - val_loss: 3.0635 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1457/4000\n",
      "2/2 - 0s - loss: 2.9702e-04 - accuracy: 1.0000 - val_loss: 3.0638 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1458/4000\n",
      "2/2 - 0s - loss: 2.9641e-04 - accuracy: 1.0000 - val_loss: 3.0643 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1459/4000\n",
      "2/2 - 0s - loss: 2.9588e-04 - accuracy: 1.0000 - val_loss: 3.0649 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1460/4000\n",
      "2/2 - 0s - loss: 2.9532e-04 - accuracy: 1.0000 - val_loss: 3.0654 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1461/4000\n",
      "2/2 - 0s - loss: 2.9476e-04 - accuracy: 1.0000 - val_loss: 3.0659 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1462/4000\n",
      "2/2 - 0s - loss: 2.9417e-04 - accuracy: 1.0000 - val_loss: 3.0665 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1463/4000\n",
      "2/2 - 0s - loss: 2.9368e-04 - accuracy: 1.0000 - val_loss: 3.0670 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1464/4000\n",
      "2/2 - 0s - loss: 2.9308e-04 - accuracy: 1.0000 - val_loss: 3.0676 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1465/4000\n",
      "2/2 - 0s - loss: 2.9253e-04 - accuracy: 1.0000 - val_loss: 3.0681 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1466/4000\n",
      "2/2 - 0s - loss: 2.9198e-04 - accuracy: 1.0000 - val_loss: 3.0686 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1467/4000\n",
      "2/2 - 0s - loss: 2.9147e-04 - accuracy: 1.0000 - val_loss: 3.0692 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1468/4000\n",
      "2/2 - 0s - loss: 2.9092e-04 - accuracy: 1.0000 - val_loss: 3.0698 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1469/4000\n",
      "2/2 - 0s - loss: 2.9038e-04 - accuracy: 1.0000 - val_loss: 3.0704 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1470/4000\n",
      "2/2 - 0s - loss: 2.8980e-04 - accuracy: 1.0000 - val_loss: 3.0709 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1471/4000\n",
      "2/2 - 0s - loss: 2.8931e-04 - accuracy: 1.0000 - val_loss: 3.0715 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1472/4000\n",
      "2/2 - 0s - loss: 2.8872e-04 - accuracy: 1.0000 - val_loss: 3.0720 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1473/4000\n",
      "2/2 - 0s - loss: 2.8823e-04 - accuracy: 1.0000 - val_loss: 3.0725 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1474/4000\n",
      "2/2 - 0s - loss: 2.8768e-04 - accuracy: 1.0000 - val_loss: 3.0731 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1475/4000\n",
      "2/2 - 0s - loss: 2.8710e-04 - accuracy: 1.0000 - val_loss: 3.0737 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1476/4000\n",
      "2/2 - 0s - loss: 2.8660e-04 - accuracy: 1.0000 - val_loss: 3.0743 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1477/4000\n",
      "2/2 - 0s - loss: 2.8608e-04 - accuracy: 1.0000 - val_loss: 3.0749 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1478/4000\n",
      "2/2 - 0s - loss: 2.8557e-04 - accuracy: 1.0000 - val_loss: 3.0755 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1479/4000\n",
      "2/2 - 0s - loss: 2.8499e-04 - accuracy: 1.0000 - val_loss: 3.0762 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1480/4000\n",
      "2/2 - 0s - loss: 2.8443e-04 - accuracy: 1.0000 - val_loss: 3.0769 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1481/4000\n",
      "2/2 - 0s - loss: 2.8392e-04 - accuracy: 1.0000 - val_loss: 3.0776 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 1482/4000\n",
      "2/2 - 0s - loss: 2.8340e-04 - accuracy: 1.0000 - val_loss: 3.0782 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1483/4000\n",
      "2/2 - 0s - loss: 2.8287e-04 - accuracy: 1.0000 - val_loss: 3.0789 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1484/4000\n",
      "2/2 - 0s - loss: 2.8235e-04 - accuracy: 1.0000 - val_loss: 3.0795 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1485/4000\n",
      "2/2 - 0s - loss: 2.8183e-04 - accuracy: 1.0000 - val_loss: 3.0801 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1486/4000\n",
      "2/2 - 0s - loss: 2.8136e-04 - accuracy: 1.0000 - val_loss: 3.0808 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1487/4000\n",
      "2/2 - 0s - loss: 2.8083e-04 - accuracy: 1.0000 - val_loss: 3.0814 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1488/4000\n",
      "2/2 - 0s - loss: 2.8025e-04 - accuracy: 1.0000 - val_loss: 3.0820 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1489/4000\n",
      "2/2 - 0s - loss: 2.7976e-04 - accuracy: 1.0000 - val_loss: 3.0825 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1490/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.7926e-04 - accuracy: 1.0000 - val_loss: 3.0830 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1491/4000\n",
      "2/2 - 0s - loss: 2.7876e-04 - accuracy: 1.0000 - val_loss: 3.0837 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1492/4000\n",
      "2/2 - 0s - loss: 2.7824e-04 - accuracy: 1.0000 - val_loss: 3.0844 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1493/4000\n",
      "2/2 - 0s - loss: 2.7770e-04 - accuracy: 1.0000 - val_loss: 3.0851 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1494/4000\n",
      "2/2 - 0s - loss: 2.7719e-04 - accuracy: 1.0000 - val_loss: 3.0856 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1495/4000\n",
      "2/2 - 0s - loss: 2.7668e-04 - accuracy: 1.0000 - val_loss: 3.0862 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1496/4000\n",
      "2/2 - 0s - loss: 2.7617e-04 - accuracy: 1.0000 - val_loss: 3.0868 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1497/4000\n",
      "2/2 - 0s - loss: 2.7567e-04 - accuracy: 1.0000 - val_loss: 3.0874 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1498/4000\n",
      "2/2 - 0s - loss: 2.7520e-04 - accuracy: 1.0000 - val_loss: 3.0881 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1499/4000\n",
      "2/2 - 0s - loss: 2.7465e-04 - accuracy: 1.0000 - val_loss: 3.0887 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1500/4000\n",
      "2/2 - 0s - loss: 2.7420e-04 - accuracy: 1.0000 - val_loss: 3.0892 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1501/4000\n",
      "2/2 - 0s - loss: 2.7365e-04 - accuracy: 1.0000 - val_loss: 3.0898 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1502/4000\n",
      "2/2 - 0s - loss: 2.7310e-04 - accuracy: 1.0000 - val_loss: 3.0905 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1503/4000\n",
      "2/2 - 0s - loss: 2.7266e-04 - accuracy: 1.0000 - val_loss: 3.0912 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1504/4000\n",
      "2/2 - 0s - loss: 2.7216e-04 - accuracy: 1.0000 - val_loss: 3.0917 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1505/4000\n",
      "2/2 - 0s - loss: 2.7165e-04 - accuracy: 1.0000 - val_loss: 3.0924 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1506/4000\n",
      "2/2 - 0s - loss: 2.7117e-04 - accuracy: 1.0000 - val_loss: 3.0929 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1507/4000\n",
      "2/2 - 0s - loss: 2.7064e-04 - accuracy: 1.0000 - val_loss: 3.0935 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1508/4000\n",
      "2/2 - 0s - loss: 2.7018e-04 - accuracy: 1.0000 - val_loss: 3.0940 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1509/4000\n",
      "2/2 - 0s - loss: 2.6971e-04 - accuracy: 1.0000 - val_loss: 3.0946 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1510/4000\n",
      "2/2 - 0s - loss: 2.6916e-04 - accuracy: 1.0000 - val_loss: 3.0952 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1511/4000\n",
      "2/2 - 0s - loss: 2.6867e-04 - accuracy: 1.0000 - val_loss: 3.0957 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1512/4000\n",
      "2/2 - 0s - loss: 2.6820e-04 - accuracy: 1.0000 - val_loss: 3.0963 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1513/4000\n",
      "2/2 - 0s - loss: 2.6770e-04 - accuracy: 1.0000 - val_loss: 3.0968 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 1514/4000\n",
      "2/2 - 0s - loss: 2.6723e-04 - accuracy: 1.0000 - val_loss: 3.0973 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1515/4000\n",
      "2/2 - 0s - loss: 2.6671e-04 - accuracy: 1.0000 - val_loss: 3.0978 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1516/4000\n",
      "2/2 - 0s - loss: 2.6620e-04 - accuracy: 1.0000 - val_loss: 3.0983 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1517/4000\n",
      "2/2 - 0s - loss: 2.6574e-04 - accuracy: 1.0000 - val_loss: 3.0987 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1518/4000\n",
      "2/2 - 0s - loss: 2.6528e-04 - accuracy: 1.0000 - val_loss: 3.0992 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1519/4000\n",
      "2/2 - 0s - loss: 2.6477e-04 - accuracy: 1.0000 - val_loss: 3.0998 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1520/4000\n",
      "2/2 - 0s - loss: 2.6432e-04 - accuracy: 1.0000 - val_loss: 3.1003 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1521/4000\n",
      "2/2 - 0s - loss: 2.6384e-04 - accuracy: 1.0000 - val_loss: 3.1009 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 1522/4000\n",
      "2/2 - 0s - loss: 2.6332e-04 - accuracy: 1.0000 - val_loss: 3.1014 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1523/4000\n",
      "2/2 - 0s - loss: 2.6285e-04 - accuracy: 1.0000 - val_loss: 3.1020 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1524/4000\n",
      "2/2 - 0s - loss: 2.6238e-04 - accuracy: 1.0000 - val_loss: 3.1025 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1525/4000\n",
      "2/2 - 0s - loss: 2.6193e-04 - accuracy: 1.0000 - val_loss: 3.1030 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1526/4000\n",
      "2/2 - 0s - loss: 2.6147e-04 - accuracy: 1.0000 - val_loss: 3.1037 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1527/4000\n",
      "2/2 - 0s - loss: 2.6096e-04 - accuracy: 1.0000 - val_loss: 3.1043 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1528/4000\n",
      "2/2 - 0s - loss: 2.6050e-04 - accuracy: 1.0000 - val_loss: 3.1048 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 1529/4000\n",
      "2/2 - 0s - loss: 2.6001e-04 - accuracy: 1.0000 - val_loss: 3.1054 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1530/4000\n",
      "2/2 - 0s - loss: 2.5953e-04 - accuracy: 1.0000 - val_loss: 3.1059 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1531/4000\n",
      "2/2 - 0s - loss: 2.5908e-04 - accuracy: 1.0000 - val_loss: 3.1065 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1532/4000\n",
      "2/2 - 0s - loss: 2.5862e-04 - accuracy: 1.0000 - val_loss: 3.1071 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1533/4000\n",
      "2/2 - 0s - loss: 2.5817e-04 - accuracy: 1.0000 - val_loss: 3.1075 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1534/4000\n",
      "2/2 - 0s - loss: 2.5770e-04 - accuracy: 1.0000 - val_loss: 3.1081 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1535/4000\n",
      "2/2 - 0s - loss: 2.5722e-04 - accuracy: 1.0000 - val_loss: 3.1086 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1536/4000\n",
      "2/2 - 0s - loss: 2.5674e-04 - accuracy: 1.0000 - val_loss: 3.1091 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1537/4000\n",
      "2/2 - 0s - loss: 2.5630e-04 - accuracy: 1.0000 - val_loss: 3.1094 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1538/4000\n",
      "2/2 - 0s - loss: 2.5583e-04 - accuracy: 1.0000 - val_loss: 3.1099 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1539/4000\n",
      "2/2 - 0s - loss: 2.5535e-04 - accuracy: 1.0000 - val_loss: 3.1104 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1540/4000\n",
      "2/2 - 0s - loss: 2.5490e-04 - accuracy: 1.0000 - val_loss: 3.1109 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1541/4000\n",
      "2/2 - 0s - loss: 2.5444e-04 - accuracy: 1.0000 - val_loss: 3.1115 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1542/4000\n",
      "2/2 - 0s - loss: 2.5401e-04 - accuracy: 1.0000 - val_loss: 3.1120 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1543/4000\n",
      "2/2 - 0s - loss: 2.5354e-04 - accuracy: 1.0000 - val_loss: 3.1126 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1544/4000\n",
      "2/2 - 0s - loss: 2.5305e-04 - accuracy: 1.0000 - val_loss: 3.1131 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1545/4000\n",
      "2/2 - 0s - loss: 2.5262e-04 - accuracy: 1.0000 - val_loss: 3.1136 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1546/4000\n",
      "2/2 - 0s - loss: 2.5217e-04 - accuracy: 1.0000 - val_loss: 3.1141 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1547/4000\n",
      "2/2 - 0s - loss: 2.5169e-04 - accuracy: 1.0000 - val_loss: 3.1147 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1548/4000\n",
      "2/2 - 0s - loss: 2.5123e-04 - accuracy: 1.0000 - val_loss: 3.1153 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1549/4000\n",
      "2/2 - 0s - loss: 2.5079e-04 - accuracy: 1.0000 - val_loss: 3.1158 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1550/4000\n",
      "2/2 - 0s - loss: 2.5035e-04 - accuracy: 1.0000 - val_loss: 3.1163 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1551/4000\n",
      "2/2 - 0s - loss: 2.4988e-04 - accuracy: 1.0000 - val_loss: 3.1169 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1552/4000\n",
      "2/2 - 0s - loss: 2.4947e-04 - accuracy: 1.0000 - val_loss: 3.1175 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1553/4000\n",
      "2/2 - 0s - loss: 2.4901e-04 - accuracy: 1.0000 - val_loss: 3.1181 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1554/4000\n",
      "2/2 - 0s - loss: 2.4858e-04 - accuracy: 1.0000 - val_loss: 3.1186 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1555/4000\n",
      "2/2 - 0s - loss: 2.4813e-04 - accuracy: 1.0000 - val_loss: 3.1192 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1556/4000\n",
      "2/2 - 0s - loss: 2.4770e-04 - accuracy: 1.0000 - val_loss: 3.1198 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1557/4000\n",
      "2/2 - 0s - loss: 2.4724e-04 - accuracy: 1.0000 - val_loss: 3.1203 - val_accuracy: 0.7250 - 43ms/epoch - 22ms/step\n",
      "Epoch 1558/4000\n",
      "2/2 - 0s - loss: 2.4684e-04 - accuracy: 1.0000 - val_loss: 3.1209 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1559/4000\n",
      "2/2 - 0s - loss: 2.4629e-04 - accuracy: 1.0000 - val_loss: 3.1215 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1560/4000\n",
      "2/2 - 0s - loss: 2.4590e-04 - accuracy: 1.0000 - val_loss: 3.1221 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1561/4000\n",
      "2/2 - 0s - loss: 2.4545e-04 - accuracy: 1.0000 - val_loss: 3.1228 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1562/4000\n",
      "2/2 - 0s - loss: 2.4498e-04 - accuracy: 1.0000 - val_loss: 3.1234 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1563/4000\n",
      "2/2 - 0s - loss: 2.4456e-04 - accuracy: 1.0000 - val_loss: 3.1240 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1564/4000\n",
      "2/2 - 0s - loss: 2.4412e-04 - accuracy: 1.0000 - val_loss: 3.1246 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1565/4000\n",
      "2/2 - 0s - loss: 2.4367e-04 - accuracy: 1.0000 - val_loss: 3.1251 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1566/4000\n",
      "2/2 - 0s - loss: 2.4323e-04 - accuracy: 1.0000 - val_loss: 3.1258 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1567/4000\n",
      "2/2 - 0s - loss: 2.4282e-04 - accuracy: 1.0000 - val_loss: 3.1264 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1568/4000\n",
      "2/2 - 0s - loss: 2.4237e-04 - accuracy: 1.0000 - val_loss: 3.1270 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1569/4000\n",
      "2/2 - 0s - loss: 2.4198e-04 - accuracy: 1.0000 - val_loss: 3.1276 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1570/4000\n",
      "2/2 - 0s - loss: 2.4152e-04 - accuracy: 1.0000 - val_loss: 3.1282 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1571/4000\n",
      "2/2 - 0s - loss: 2.4113e-04 - accuracy: 1.0000 - val_loss: 3.1289 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1572/4000\n",
      "2/2 - 0s - loss: 2.4064e-04 - accuracy: 1.0000 - val_loss: 3.1294 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1573/4000\n",
      "2/2 - 0s - loss: 2.4022e-04 - accuracy: 1.0000 - val_loss: 3.1299 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1574/4000\n",
      "2/2 - 0s - loss: 2.3981e-04 - accuracy: 1.0000 - val_loss: 3.1303 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1575/4000\n",
      "2/2 - 0s - loss: 2.3938e-04 - accuracy: 1.0000 - val_loss: 3.1309 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1576/4000\n",
      "2/2 - 0s - loss: 2.3893e-04 - accuracy: 1.0000 - val_loss: 3.1315 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1577/4000\n",
      "2/2 - 0s - loss: 2.3854e-04 - accuracy: 1.0000 - val_loss: 3.1319 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1578/4000\n",
      "2/2 - 0s - loss: 2.3809e-04 - accuracy: 1.0000 - val_loss: 3.1325 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1579/4000\n",
      "2/2 - 0s - loss: 2.3768e-04 - accuracy: 1.0000 - val_loss: 3.1331 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1580/4000\n",
      "2/2 - 0s - loss: 2.3729e-04 - accuracy: 1.0000 - val_loss: 3.1337 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1581/4000\n",
      "2/2 - 0s - loss: 2.3687e-04 - accuracy: 1.0000 - val_loss: 3.1342 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1582/4000\n",
      "2/2 - 0s - loss: 2.3643e-04 - accuracy: 1.0000 - val_loss: 3.1349 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1583/4000\n",
      "2/2 - 0s - loss: 2.3602e-04 - accuracy: 1.0000 - val_loss: 3.1355 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1584/4000\n",
      "2/2 - 0s - loss: 2.3563e-04 - accuracy: 1.0000 - val_loss: 3.1360 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1585/4000\n",
      "2/2 - 0s - loss: 2.3518e-04 - accuracy: 1.0000 - val_loss: 3.1365 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1586/4000\n",
      "2/2 - 0s - loss: 2.3480e-04 - accuracy: 1.0000 - val_loss: 3.1371 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1587/4000\n",
      "2/2 - 0s - loss: 2.3436e-04 - accuracy: 1.0000 - val_loss: 3.1376 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1588/4000\n",
      "2/2 - 0s - loss: 2.3392e-04 - accuracy: 1.0000 - val_loss: 3.1382 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1589/4000\n",
      "2/2 - 0s - loss: 2.3350e-04 - accuracy: 1.0000 - val_loss: 3.1388 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1590/4000\n",
      "2/2 - 0s - loss: 2.3310e-04 - accuracy: 1.0000 - val_loss: 3.1394 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1591/4000\n",
      "2/2 - 0s - loss: 2.3270e-04 - accuracy: 1.0000 - val_loss: 3.1400 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1592/4000\n",
      "2/2 - 0s - loss: 2.3228e-04 - accuracy: 1.0000 - val_loss: 3.1405 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1593/4000\n",
      "2/2 - 0s - loss: 2.3190e-04 - accuracy: 1.0000 - val_loss: 3.1411 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1594/4000\n",
      "2/2 - 0s - loss: 2.3148e-04 - accuracy: 1.0000 - val_loss: 3.1416 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 1595/4000\n",
      "2/2 - 0s - loss: 2.3107e-04 - accuracy: 1.0000 - val_loss: 3.1422 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1596/4000\n",
      "2/2 - 0s - loss: 2.3067e-04 - accuracy: 1.0000 - val_loss: 3.1427 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1597/4000\n",
      "2/2 - 0s - loss: 2.3026e-04 - accuracy: 1.0000 - val_loss: 3.1431 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1598/4000\n",
      "2/2 - 0s - loss: 2.2983e-04 - accuracy: 1.0000 - val_loss: 3.1436 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1599/4000\n",
      "2/2 - 0s - loss: 2.2946e-04 - accuracy: 1.0000 - val_loss: 3.1442 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1600/4000\n",
      "2/2 - 0s - loss: 2.2904e-04 - accuracy: 1.0000 - val_loss: 3.1448 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1601/4000\n",
      "2/2 - 0s - loss: 2.2864e-04 - accuracy: 1.0000 - val_loss: 3.1453 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1602/4000\n",
      "2/2 - 0s - loss: 2.2823e-04 - accuracy: 1.0000 - val_loss: 3.1459 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1603/4000\n",
      "2/2 - 0s - loss: 2.2784e-04 - accuracy: 1.0000 - val_loss: 3.1465 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1604/4000\n",
      "2/2 - 0s - loss: 2.2745e-04 - accuracy: 1.0000 - val_loss: 3.1470 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1605/4000\n",
      "2/2 - 0s - loss: 2.2708e-04 - accuracy: 1.0000 - val_loss: 3.1476 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 1606/4000\n",
      "2/2 - 0s - loss: 2.2663e-04 - accuracy: 1.0000 - val_loss: 3.1481 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1607/4000\n",
      "2/2 - 0s - loss: 2.2626e-04 - accuracy: 1.0000 - val_loss: 3.1487 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1608/4000\n",
      "2/2 - 0s - loss: 2.2587e-04 - accuracy: 1.0000 - val_loss: 3.1492 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1609/4000\n",
      "2/2 - 0s - loss: 2.2548e-04 - accuracy: 1.0000 - val_loss: 3.1497 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1610/4000\n",
      "2/2 - 0s - loss: 2.2509e-04 - accuracy: 1.0000 - val_loss: 3.1503 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1611/4000\n",
      "2/2 - 0s - loss: 2.2468e-04 - accuracy: 1.0000 - val_loss: 3.1509 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1612/4000\n",
      "2/2 - 0s - loss: 2.2426e-04 - accuracy: 1.0000 - val_loss: 3.1515 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1613/4000\n",
      "2/2 - 0s - loss: 2.2387e-04 - accuracy: 1.0000 - val_loss: 3.1521 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1614/4000\n",
      "2/2 - 0s - loss: 2.2351e-04 - accuracy: 1.0000 - val_loss: 3.1528 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1615/4000\n",
      "2/2 - 0s - loss: 2.2310e-04 - accuracy: 1.0000 - val_loss: 3.1532 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 1616/4000\n",
      "2/2 - 0s - loss: 2.2273e-04 - accuracy: 1.0000 - val_loss: 3.1537 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1617/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.2231e-04 - accuracy: 1.0000 - val_loss: 3.1542 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1618/4000\n",
      "2/2 - 0s - loss: 2.2195e-04 - accuracy: 1.0000 - val_loss: 3.1548 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1619/4000\n",
      "2/2 - 0s - loss: 2.2154e-04 - accuracy: 1.0000 - val_loss: 3.1552 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1620/4000\n",
      "2/2 - 0s - loss: 2.2112e-04 - accuracy: 1.0000 - val_loss: 3.1557 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1621/4000\n",
      "2/2 - 0s - loss: 2.2076e-04 - accuracy: 1.0000 - val_loss: 3.1563 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1622/4000\n",
      "2/2 - 0s - loss: 2.2038e-04 - accuracy: 1.0000 - val_loss: 3.1568 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1623/4000\n",
      "2/2 - 0s - loss: 2.2002e-04 - accuracy: 1.0000 - val_loss: 3.1574 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 1624/4000\n",
      "2/2 - 0s - loss: 2.1960e-04 - accuracy: 1.0000 - val_loss: 3.1578 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 1625/4000\n",
      "2/2 - 0s - loss: 2.1922e-04 - accuracy: 1.0000 - val_loss: 3.1583 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1626/4000\n",
      "2/2 - 0s - loss: 2.1886e-04 - accuracy: 1.0000 - val_loss: 3.1590 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1627/4000\n",
      "2/2 - 0s - loss: 2.1845e-04 - accuracy: 1.0000 - val_loss: 3.1595 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1628/4000\n",
      "2/2 - 0s - loss: 2.1808e-04 - accuracy: 1.0000 - val_loss: 3.1600 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 1629/4000\n",
      "2/2 - 0s - loss: 2.1770e-04 - accuracy: 1.0000 - val_loss: 3.1605 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1630/4000\n",
      "2/2 - 0s - loss: 2.1732e-04 - accuracy: 1.0000 - val_loss: 3.1611 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 1631/4000\n",
      "2/2 - 0s - loss: 2.1691e-04 - accuracy: 1.0000 - val_loss: 3.1617 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1632/4000\n",
      "2/2 - 0s - loss: 2.1659e-04 - accuracy: 1.0000 - val_loss: 3.1624 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1633/4000\n",
      "2/2 - 0s - loss: 2.1621e-04 - accuracy: 1.0000 - val_loss: 3.1629 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1634/4000\n",
      "2/2 - 0s - loss: 2.1583e-04 - accuracy: 1.0000 - val_loss: 3.1634 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1635/4000\n",
      "2/2 - 0s - loss: 2.1551e-04 - accuracy: 1.0000 - val_loss: 3.1639 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1636/4000\n",
      "2/2 - 0s - loss: 2.1510e-04 - accuracy: 1.0000 - val_loss: 3.1644 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1637/4000\n",
      "2/2 - 0s - loss: 2.1472e-04 - accuracy: 1.0000 - val_loss: 3.1650 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1638/4000\n",
      "2/2 - 0s - loss: 2.1435e-04 - accuracy: 1.0000 - val_loss: 3.1655 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1639/4000\n",
      "2/2 - 0s - loss: 2.1400e-04 - accuracy: 1.0000 - val_loss: 3.1661 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1640/4000\n",
      "2/2 - 0s - loss: 2.1361e-04 - accuracy: 1.0000 - val_loss: 3.1666 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1641/4000\n",
      "2/2 - 0s - loss: 2.1323e-04 - accuracy: 1.0000 - val_loss: 3.1672 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1642/4000\n",
      "2/2 - 0s - loss: 2.1287e-04 - accuracy: 1.0000 - val_loss: 3.1678 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1643/4000\n",
      "2/2 - 0s - loss: 2.1251e-04 - accuracy: 1.0000 - val_loss: 3.1684 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1644/4000\n",
      "2/2 - 0s - loss: 2.1213e-04 - accuracy: 1.0000 - val_loss: 3.1689 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1645/4000\n",
      "2/2 - 0s - loss: 2.1177e-04 - accuracy: 1.0000 - val_loss: 3.1695 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1646/4000\n",
      "2/2 - 0s - loss: 2.1139e-04 - accuracy: 1.0000 - val_loss: 3.1700 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1647/4000\n",
      "2/2 - 0s - loss: 2.1105e-04 - accuracy: 1.0000 - val_loss: 3.1704 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1648/4000\n",
      "2/2 - 0s - loss: 2.1072e-04 - accuracy: 1.0000 - val_loss: 3.1711 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1649/4000\n",
      "2/2 - 0s - loss: 2.1032e-04 - accuracy: 1.0000 - val_loss: 3.1716 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1650/4000\n",
      "2/2 - 0s - loss: 2.0997e-04 - accuracy: 1.0000 - val_loss: 3.1721 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1651/4000\n",
      "2/2 - 0s - loss: 2.0962e-04 - accuracy: 1.0000 - val_loss: 3.1725 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1652/4000\n",
      "2/2 - 0s - loss: 2.0930e-04 - accuracy: 1.0000 - val_loss: 3.1730 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1653/4000\n",
      "2/2 - 0s - loss: 2.0887e-04 - accuracy: 1.0000 - val_loss: 3.1735 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1654/4000\n",
      "2/2 - 0s - loss: 2.0859e-04 - accuracy: 1.0000 - val_loss: 3.1740 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1655/4000\n",
      "2/2 - 0s - loss: 2.0818e-04 - accuracy: 1.0000 - val_loss: 3.1744 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1656/4000\n",
      "2/2 - 0s - loss: 2.0781e-04 - accuracy: 1.0000 - val_loss: 3.1751 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1657/4000\n",
      "2/2 - 0s - loss: 2.0748e-04 - accuracy: 1.0000 - val_loss: 3.1756 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1658/4000\n",
      "2/2 - 0s - loss: 2.0712e-04 - accuracy: 1.0000 - val_loss: 3.1762 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 1659/4000\n",
      "2/2 - 0s - loss: 2.0678e-04 - accuracy: 1.0000 - val_loss: 3.1766 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1660/4000\n",
      "2/2 - 0s - loss: 2.0643e-04 - accuracy: 1.0000 - val_loss: 3.1772 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1661/4000\n",
      "2/2 - 0s - loss: 2.0606e-04 - accuracy: 1.0000 - val_loss: 3.1778 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1662/4000\n",
      "2/2 - 0s - loss: 2.0570e-04 - accuracy: 1.0000 - val_loss: 3.1783 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1663/4000\n",
      "2/2 - 0s - loss: 2.0537e-04 - accuracy: 1.0000 - val_loss: 3.1790 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1664/4000\n",
      "2/2 - 0s - loss: 2.0502e-04 - accuracy: 1.0000 - val_loss: 3.1795 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1665/4000\n",
      "2/2 - 0s - loss: 2.0462e-04 - accuracy: 1.0000 - val_loss: 3.1800 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1666/4000\n",
      "2/2 - 0s - loss: 2.0428e-04 - accuracy: 1.0000 - val_loss: 3.1805 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1667/4000\n",
      "2/2 - 0s - loss: 2.0393e-04 - accuracy: 1.0000 - val_loss: 3.1810 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1668/4000\n",
      "2/2 - 0s - loss: 2.0357e-04 - accuracy: 1.0000 - val_loss: 3.1815 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1669/4000\n",
      "2/2 - 0s - loss: 2.0325e-04 - accuracy: 1.0000 - val_loss: 3.1820 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1670/4000\n",
      "2/2 - 0s - loss: 2.0291e-04 - accuracy: 1.0000 - val_loss: 3.1826 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1671/4000\n",
      "2/2 - 0s - loss: 2.0256e-04 - accuracy: 1.0000 - val_loss: 3.1831 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1672/4000\n",
      "2/2 - 0s - loss: 2.0221e-04 - accuracy: 1.0000 - val_loss: 3.1836 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1673/4000\n",
      "2/2 - 0s - loss: 2.0185e-04 - accuracy: 1.0000 - val_loss: 3.1842 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1674/4000\n",
      "2/2 - 0s - loss: 2.0150e-04 - accuracy: 1.0000 - val_loss: 3.1847 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1675/4000\n",
      "2/2 - 0s - loss: 2.0116e-04 - accuracy: 1.0000 - val_loss: 3.1852 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 1676/4000\n",
      "2/2 - 0s - loss: 2.0081e-04 - accuracy: 1.0000 - val_loss: 3.1858 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1677/4000\n",
      "2/2 - 0s - loss: 2.0050e-04 - accuracy: 1.0000 - val_loss: 3.1863 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1678/4000\n",
      "2/2 - 0s - loss: 2.0016e-04 - accuracy: 1.0000 - val_loss: 3.1868 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1679/4000\n",
      "2/2 - 0s - loss: 1.9979e-04 - accuracy: 1.0000 - val_loss: 3.1872 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1680/4000\n",
      "2/2 - 0s - loss: 1.9947e-04 - accuracy: 1.0000 - val_loss: 3.1876 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1681/4000\n",
      "2/2 - 0s - loss: 1.9912e-04 - accuracy: 1.0000 - val_loss: 3.1882 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1682/4000\n",
      "2/2 - 0s - loss: 1.9881e-04 - accuracy: 1.0000 - val_loss: 3.1887 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1683/4000\n",
      "2/2 - 0s - loss: 1.9844e-04 - accuracy: 1.0000 - val_loss: 3.1893 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1684/4000\n",
      "2/2 - 0s - loss: 1.9809e-04 - accuracy: 1.0000 - val_loss: 3.1897 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1685/4000\n",
      "2/2 - 0s - loss: 1.9774e-04 - accuracy: 1.0000 - val_loss: 3.1903 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1686/4000\n",
      "2/2 - 0s - loss: 1.9745e-04 - accuracy: 1.0000 - val_loss: 3.1909 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1687/4000\n",
      "2/2 - 0s - loss: 1.9708e-04 - accuracy: 1.0000 - val_loss: 3.1914 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1688/4000\n",
      "2/2 - 0s - loss: 1.9678e-04 - accuracy: 1.0000 - val_loss: 3.1918 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1689/4000\n",
      "2/2 - 0s - loss: 1.9644e-04 - accuracy: 1.0000 - val_loss: 3.1922 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1690/4000\n",
      "2/2 - 0s - loss: 1.9610e-04 - accuracy: 1.0000 - val_loss: 3.1928 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1691/4000\n",
      "2/2 - 0s - loss: 1.9577e-04 - accuracy: 1.0000 - val_loss: 3.1934 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1692/4000\n",
      "2/2 - 0s - loss: 1.9544e-04 - accuracy: 1.0000 - val_loss: 3.1940 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 1693/4000\n",
      "2/2 - 0s - loss: 1.9513e-04 - accuracy: 1.0000 - val_loss: 3.1945 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1694/4000\n",
      "2/2 - 0s - loss: 1.9477e-04 - accuracy: 1.0000 - val_loss: 3.1950 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1695/4000\n",
      "2/2 - 0s - loss: 1.9444e-04 - accuracy: 1.0000 - val_loss: 3.1955 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1696/4000\n",
      "2/2 - 0s - loss: 1.9415e-04 - accuracy: 1.0000 - val_loss: 3.1960 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1697/4000\n",
      "2/2 - 0s - loss: 1.9381e-04 - accuracy: 1.0000 - val_loss: 3.1965 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1698/4000\n",
      "2/2 - 0s - loss: 1.9348e-04 - accuracy: 1.0000 - val_loss: 3.1970 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 1699/4000\n",
      "2/2 - 0s - loss: 1.9315e-04 - accuracy: 1.0000 - val_loss: 3.1975 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1700/4000\n",
      "2/2 - 0s - loss: 1.9283e-04 - accuracy: 1.0000 - val_loss: 3.1980 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1701/4000\n",
      "2/2 - 0s - loss: 1.9251e-04 - accuracy: 1.0000 - val_loss: 3.1985 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1702/4000\n",
      "2/2 - 0s - loss: 1.9220e-04 - accuracy: 1.0000 - val_loss: 3.1991 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1703/4000\n",
      "2/2 - 0s - loss: 1.9185e-04 - accuracy: 1.0000 - val_loss: 3.1996 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1704/4000\n",
      "2/2 - 0s - loss: 1.9155e-04 - accuracy: 1.0000 - val_loss: 3.2001 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1705/4000\n",
      "2/2 - 0s - loss: 1.9120e-04 - accuracy: 1.0000 - val_loss: 3.2007 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1706/4000\n",
      "2/2 - 0s - loss: 1.9089e-04 - accuracy: 1.0000 - val_loss: 3.2013 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1707/4000\n",
      "2/2 - 0s - loss: 1.9060e-04 - accuracy: 1.0000 - val_loss: 3.2019 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1708/4000\n",
      "2/2 - 0s - loss: 1.9025e-04 - accuracy: 1.0000 - val_loss: 3.2024 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1709/4000\n",
      "2/2 - 0s - loss: 1.8993e-04 - accuracy: 1.0000 - val_loss: 3.2028 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1710/4000\n",
      "2/2 - 0s - loss: 1.8962e-04 - accuracy: 1.0000 - val_loss: 3.2033 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1711/4000\n",
      "2/2 - 0s - loss: 1.8930e-04 - accuracy: 1.0000 - val_loss: 3.2039 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1712/4000\n",
      "2/2 - 0s - loss: 1.8898e-04 - accuracy: 1.0000 - val_loss: 3.2045 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 1713/4000\n",
      "2/2 - 0s - loss: 1.8864e-04 - accuracy: 1.0000 - val_loss: 3.2051 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1714/4000\n",
      "2/2 - 0s - loss: 1.8834e-04 - accuracy: 1.0000 - val_loss: 3.2056 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1715/4000\n",
      "2/2 - 0s - loss: 1.8804e-04 - accuracy: 1.0000 - val_loss: 3.2061 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1716/4000\n",
      "2/2 - 0s - loss: 1.8772e-04 - accuracy: 1.0000 - val_loss: 3.2066 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 1717/4000\n",
      "2/2 - 0s - loss: 1.8743e-04 - accuracy: 1.0000 - val_loss: 3.2073 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1718/4000\n",
      "2/2 - 0s - loss: 1.8707e-04 - accuracy: 1.0000 - val_loss: 3.2078 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1719/4000\n",
      "2/2 - 0s - loss: 1.8680e-04 - accuracy: 1.0000 - val_loss: 3.2083 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 1720/4000\n",
      "2/2 - 0s - loss: 1.8646e-04 - accuracy: 1.0000 - val_loss: 3.2088 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1721/4000\n",
      "2/2 - 0s - loss: 1.8616e-04 - accuracy: 1.0000 - val_loss: 3.2093 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1722/4000\n",
      "2/2 - 0s - loss: 1.8582e-04 - accuracy: 1.0000 - val_loss: 3.2099 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 1723/4000\n",
      "2/2 - 0s - loss: 1.8555e-04 - accuracy: 1.0000 - val_loss: 3.2105 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1724/4000\n",
      "2/2 - 0s - loss: 1.8521e-04 - accuracy: 1.0000 - val_loss: 3.2110 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1725/4000\n",
      "2/2 - 0s - loss: 1.8494e-04 - accuracy: 1.0000 - val_loss: 3.2116 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1726/4000\n",
      "2/2 - 0s - loss: 1.8461e-04 - accuracy: 1.0000 - val_loss: 3.2121 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1727/4000\n",
      "2/2 - 0s - loss: 1.8432e-04 - accuracy: 1.0000 - val_loss: 3.2125 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1728/4000\n",
      "2/2 - 0s - loss: 1.8400e-04 - accuracy: 1.0000 - val_loss: 3.2131 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1729/4000\n",
      "2/2 - 0s - loss: 1.8370e-04 - accuracy: 1.0000 - val_loss: 3.2135 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 1730/4000\n",
      "2/2 - 0s - loss: 1.8336e-04 - accuracy: 1.0000 - val_loss: 3.2141 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1731/4000\n",
      "2/2 - 0s - loss: 1.8310e-04 - accuracy: 1.0000 - val_loss: 3.2147 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 1732/4000\n",
      "2/2 - 0s - loss: 1.8279e-04 - accuracy: 1.0000 - val_loss: 3.2152 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1733/4000\n",
      "2/2 - 0s - loss: 1.8252e-04 - accuracy: 1.0000 - val_loss: 3.2156 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1734/4000\n",
      "2/2 - 0s - loss: 1.8219e-04 - accuracy: 1.0000 - val_loss: 3.2161 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1735/4000\n",
      "2/2 - 0s - loss: 1.8190e-04 - accuracy: 1.0000 - val_loss: 3.2167 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1736/4000\n",
      "2/2 - 0s - loss: 1.8159e-04 - accuracy: 1.0000 - val_loss: 3.2173 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1737/4000\n",
      "2/2 - 0s - loss: 1.8127e-04 - accuracy: 1.0000 - val_loss: 3.2178 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1738/4000\n",
      "2/2 - 0s - loss: 1.8098e-04 - accuracy: 1.0000 - val_loss: 3.2184 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1739/4000\n",
      "2/2 - 0s - loss: 1.8066e-04 - accuracy: 1.0000 - val_loss: 3.2189 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1740/4000\n",
      "2/2 - 0s - loss: 1.8036e-04 - accuracy: 1.0000 - val_loss: 3.2194 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1741/4000\n",
      "2/2 - 0s - loss: 1.8005e-04 - accuracy: 1.0000 - val_loss: 3.2198 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1742/4000\n",
      "2/2 - 0s - loss: 1.7978e-04 - accuracy: 1.0000 - val_loss: 3.2204 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1743/4000\n",
      "2/2 - 0s - loss: 1.7949e-04 - accuracy: 1.0000 - val_loss: 3.2209 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1744/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.7918e-04 - accuracy: 1.0000 - val_loss: 3.2215 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1745/4000\n",
      "2/2 - 0s - loss: 1.7885e-04 - accuracy: 1.0000 - val_loss: 3.2220 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1746/4000\n",
      "2/2 - 0s - loss: 1.7857e-04 - accuracy: 1.0000 - val_loss: 3.2225 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1747/4000\n",
      "2/2 - 0s - loss: 1.7827e-04 - accuracy: 1.0000 - val_loss: 3.2230 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1748/4000\n",
      "2/2 - 0s - loss: 1.7796e-04 - accuracy: 1.0000 - val_loss: 3.2236 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1749/4000\n",
      "2/2 - 0s - loss: 1.7770e-04 - accuracy: 1.0000 - val_loss: 3.2243 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1750/4000\n",
      "2/2 - 0s - loss: 1.7739e-04 - accuracy: 1.0000 - val_loss: 3.2248 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1751/4000\n",
      "2/2 - 0s - loss: 1.7713e-04 - accuracy: 1.0000 - val_loss: 3.2253 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1752/4000\n",
      "2/2 - 0s - loss: 1.7684e-04 - accuracy: 1.0000 - val_loss: 3.2258 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1753/4000\n",
      "2/2 - 0s - loss: 1.7653e-04 - accuracy: 1.0000 - val_loss: 3.2263 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1754/4000\n",
      "2/2 - 0s - loss: 1.7622e-04 - accuracy: 1.0000 - val_loss: 3.2268 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1755/4000\n",
      "2/2 - 0s - loss: 1.7597e-04 - accuracy: 1.0000 - val_loss: 3.2275 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1756/4000\n",
      "2/2 - 0s - loss: 1.7565e-04 - accuracy: 1.0000 - val_loss: 3.2279 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1757/4000\n",
      "2/2 - 0s - loss: 1.7537e-04 - accuracy: 1.0000 - val_loss: 3.2286 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1758/4000\n",
      "2/2 - 0s - loss: 1.7507e-04 - accuracy: 1.0000 - val_loss: 3.2292 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1759/4000\n",
      "2/2 - 0s - loss: 1.7477e-04 - accuracy: 1.0000 - val_loss: 3.2296 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1760/4000\n",
      "2/2 - 0s - loss: 1.7450e-04 - accuracy: 1.0000 - val_loss: 3.2300 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1761/4000\n",
      "2/2 - 0s - loss: 1.7422e-04 - accuracy: 1.0000 - val_loss: 3.2305 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1762/4000\n",
      "2/2 - 0s - loss: 1.7392e-04 - accuracy: 1.0000 - val_loss: 3.2309 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1763/4000\n",
      "2/2 - 0s - loss: 1.7366e-04 - accuracy: 1.0000 - val_loss: 3.2314 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1764/4000\n",
      "2/2 - 0s - loss: 1.7337e-04 - accuracy: 1.0000 - val_loss: 3.2319 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1765/4000\n",
      "2/2 - 0s - loss: 1.7307e-04 - accuracy: 1.0000 - val_loss: 3.2324 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1766/4000\n",
      "2/2 - 0s - loss: 1.7279e-04 - accuracy: 1.0000 - val_loss: 3.2329 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1767/4000\n",
      "2/2 - 0s - loss: 1.7250e-04 - accuracy: 1.0000 - val_loss: 3.2334 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1768/4000\n",
      "2/2 - 0s - loss: 1.7224e-04 - accuracy: 1.0000 - val_loss: 3.2338 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1769/4000\n",
      "2/2 - 0s - loss: 1.7193e-04 - accuracy: 1.0000 - val_loss: 3.2344 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1770/4000\n",
      "2/2 - 0s - loss: 1.7167e-04 - accuracy: 1.0000 - val_loss: 3.2349 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1771/4000\n",
      "2/2 - 0s - loss: 1.7142e-04 - accuracy: 1.0000 - val_loss: 3.2354 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1772/4000\n",
      "2/2 - 0s - loss: 1.7112e-04 - accuracy: 1.0000 - val_loss: 3.2359 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1773/4000\n",
      "2/2 - 0s - loss: 1.7080e-04 - accuracy: 1.0000 - val_loss: 3.2365 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1774/4000\n",
      "2/2 - 0s - loss: 1.7055e-04 - accuracy: 1.0000 - val_loss: 3.2370 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1775/4000\n",
      "2/2 - 0s - loss: 1.7023e-04 - accuracy: 1.0000 - val_loss: 3.2375 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1776/4000\n",
      "2/2 - 0s - loss: 1.6998e-04 - accuracy: 1.0000 - val_loss: 3.2380 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1777/4000\n",
      "2/2 - 0s - loss: 1.6972e-04 - accuracy: 1.0000 - val_loss: 3.2385 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1778/4000\n",
      "2/2 - 0s - loss: 1.6941e-04 - accuracy: 1.0000 - val_loss: 3.2390 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1779/4000\n",
      "2/2 - 0s - loss: 1.6916e-04 - accuracy: 1.0000 - val_loss: 3.2394 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1780/4000\n",
      "2/2 - 0s - loss: 1.6889e-04 - accuracy: 1.0000 - val_loss: 3.2399 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1781/4000\n",
      "2/2 - 0s - loss: 1.6859e-04 - accuracy: 1.0000 - val_loss: 3.2402 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 1782/4000\n",
      "2/2 - 0s - loss: 1.6830e-04 - accuracy: 1.0000 - val_loss: 3.2406 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 1783/4000\n",
      "2/2 - 0s - loss: 1.6805e-04 - accuracy: 1.0000 - val_loss: 3.2411 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1784/4000\n",
      "2/2 - 0s - loss: 1.6776e-04 - accuracy: 1.0000 - val_loss: 3.2415 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1785/4000\n",
      "2/2 - 0s - loss: 1.6750e-04 - accuracy: 1.0000 - val_loss: 3.2420 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1786/4000\n",
      "2/2 - 0s - loss: 1.6720e-04 - accuracy: 1.0000 - val_loss: 3.2425 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 1787/4000\n",
      "2/2 - 0s - loss: 1.6697e-04 - accuracy: 1.0000 - val_loss: 3.2429 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1788/4000\n",
      "2/2 - 0s - loss: 1.6670e-04 - accuracy: 1.0000 - val_loss: 3.2434 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1789/4000\n",
      "2/2 - 0s - loss: 1.6643e-04 - accuracy: 1.0000 - val_loss: 3.2439 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1790/4000\n",
      "2/2 - 0s - loss: 1.6615e-04 - accuracy: 1.0000 - val_loss: 3.2444 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1791/4000\n",
      "2/2 - 0s - loss: 1.6590e-04 - accuracy: 1.0000 - val_loss: 3.2449 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1792/4000\n",
      "2/2 - 0s - loss: 1.6560e-04 - accuracy: 1.0000 - val_loss: 3.2453 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 1793/4000\n",
      "2/2 - 0s - loss: 1.6536e-04 - accuracy: 1.0000 - val_loss: 3.2457 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1794/4000\n",
      "2/2 - 0s - loss: 1.6508e-04 - accuracy: 1.0000 - val_loss: 3.2463 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1795/4000\n",
      "2/2 - 0s - loss: 1.6479e-04 - accuracy: 1.0000 - val_loss: 3.2468 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1796/4000\n",
      "2/2 - 0s - loss: 1.6453e-04 - accuracy: 1.0000 - val_loss: 3.2474 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1797/4000\n",
      "2/2 - 0s - loss: 1.6427e-04 - accuracy: 1.0000 - val_loss: 3.2480 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1798/4000\n",
      "2/2 - 0s - loss: 1.6404e-04 - accuracy: 1.0000 - val_loss: 3.2486 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1799/4000\n",
      "2/2 - 0s - loss: 1.6374e-04 - accuracy: 1.0000 - val_loss: 3.2491 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1800/4000\n",
      "2/2 - 0s - loss: 1.6347e-04 - accuracy: 1.0000 - val_loss: 3.2495 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1801/4000\n",
      "2/2 - 0s - loss: 1.6322e-04 - accuracy: 1.0000 - val_loss: 3.2501 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1802/4000\n",
      "2/2 - 0s - loss: 1.6294e-04 - accuracy: 1.0000 - val_loss: 3.2506 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1803/4000\n",
      "2/2 - 0s - loss: 1.6270e-04 - accuracy: 1.0000 - val_loss: 3.2512 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1804/4000\n",
      "2/2 - 0s - loss: 1.6239e-04 - accuracy: 1.0000 - val_loss: 3.2516 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1805/4000\n",
      "2/2 - 0s - loss: 1.6216e-04 - accuracy: 1.0000 - val_loss: 3.2522 - val_accuracy: 0.7250 - 87ms/epoch - 43ms/step\n",
      "Epoch 1806/4000\n",
      "2/2 - 0s - loss: 1.6185e-04 - accuracy: 1.0000 - val_loss: 3.2527 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1807/4000\n",
      "2/2 - 0s - loss: 1.6162e-04 - accuracy: 1.0000 - val_loss: 3.2533 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1808/4000\n",
      "2/2 - 0s - loss: 1.6134e-04 - accuracy: 1.0000 - val_loss: 3.2538 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 1809/4000\n",
      "2/2 - 0s - loss: 1.6107e-04 - accuracy: 1.0000 - val_loss: 3.2542 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1810/4000\n",
      "2/2 - 0s - loss: 1.6082e-04 - accuracy: 1.0000 - val_loss: 3.2548 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1811/4000\n",
      "2/2 - 0s - loss: 1.6057e-04 - accuracy: 1.0000 - val_loss: 3.2553 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1812/4000\n",
      "2/2 - 0s - loss: 1.6027e-04 - accuracy: 1.0000 - val_loss: 3.2558 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1813/4000\n",
      "2/2 - 0s - loss: 1.6002e-04 - accuracy: 1.0000 - val_loss: 3.2564 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 1814/4000\n",
      "2/2 - 0s - loss: 1.5980e-04 - accuracy: 1.0000 - val_loss: 3.2569 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1815/4000\n",
      "2/2 - 0s - loss: 1.5952e-04 - accuracy: 1.0000 - val_loss: 3.2574 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1816/4000\n",
      "2/2 - 0s - loss: 1.5926e-04 - accuracy: 1.0000 - val_loss: 3.2579 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 1817/4000\n",
      "2/2 - 0s - loss: 1.5900e-04 - accuracy: 1.0000 - val_loss: 3.2584 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1818/4000\n",
      "2/2 - 0s - loss: 1.5874e-04 - accuracy: 1.0000 - val_loss: 3.2588 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1819/4000\n",
      "2/2 - 0s - loss: 1.5848e-04 - accuracy: 1.0000 - val_loss: 3.2593 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1820/4000\n",
      "2/2 - 0s - loss: 1.5824e-04 - accuracy: 1.0000 - val_loss: 3.2599 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1821/4000\n",
      "2/2 - 0s - loss: 1.5796e-04 - accuracy: 1.0000 - val_loss: 3.2604 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1822/4000\n",
      "2/2 - 0s - loss: 1.5770e-04 - accuracy: 1.0000 - val_loss: 3.2608 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1823/4000\n",
      "2/2 - 0s - loss: 1.5747e-04 - accuracy: 1.0000 - val_loss: 3.2613 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 1824/4000\n",
      "2/2 - 0s - loss: 1.5720e-04 - accuracy: 1.0000 - val_loss: 3.2617 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1825/4000\n",
      "2/2 - 0s - loss: 1.5698e-04 - accuracy: 1.0000 - val_loss: 3.2622 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1826/4000\n",
      "2/2 - 0s - loss: 1.5669e-04 - accuracy: 1.0000 - val_loss: 3.2628 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1827/4000\n",
      "2/2 - 0s - loss: 1.5643e-04 - accuracy: 1.0000 - val_loss: 3.2633 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1828/4000\n",
      "2/2 - 0s - loss: 1.5618e-04 - accuracy: 1.0000 - val_loss: 3.2638 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1829/4000\n",
      "2/2 - 0s - loss: 1.5592e-04 - accuracy: 1.0000 - val_loss: 3.2642 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1830/4000\n",
      "2/2 - 0s - loss: 1.5569e-04 - accuracy: 1.0000 - val_loss: 3.2647 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1831/4000\n",
      "2/2 - 0s - loss: 1.5544e-04 - accuracy: 1.0000 - val_loss: 3.2653 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1832/4000\n",
      "2/2 - 0s - loss: 1.5518e-04 - accuracy: 1.0000 - val_loss: 3.2658 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1833/4000\n",
      "2/2 - 0s - loss: 1.5492e-04 - accuracy: 1.0000 - val_loss: 3.2663 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1834/4000\n",
      "2/2 - 0s - loss: 1.5467e-04 - accuracy: 1.0000 - val_loss: 3.2669 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1835/4000\n",
      "2/2 - 0s - loss: 1.5442e-04 - accuracy: 1.0000 - val_loss: 3.2673 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1836/4000\n",
      "2/2 - 0s - loss: 1.5418e-04 - accuracy: 1.0000 - val_loss: 3.2678 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1837/4000\n",
      "2/2 - 0s - loss: 1.5392e-04 - accuracy: 1.0000 - val_loss: 3.2683 - val_accuracy: 0.7250 - 45ms/epoch - 23ms/step\n",
      "Epoch 1838/4000\n",
      "2/2 - 0s - loss: 1.5368e-04 - accuracy: 1.0000 - val_loss: 3.2688 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1839/4000\n",
      "2/2 - 0s - loss: 1.5343e-04 - accuracy: 1.0000 - val_loss: 3.2694 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1840/4000\n",
      "2/2 - 0s - loss: 1.5319e-04 - accuracy: 1.0000 - val_loss: 3.2700 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1841/4000\n",
      "2/2 - 0s - loss: 1.5293e-04 - accuracy: 1.0000 - val_loss: 3.2704 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1842/4000\n",
      "2/2 - 0s - loss: 1.5270e-04 - accuracy: 1.0000 - val_loss: 3.2708 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1843/4000\n",
      "2/2 - 0s - loss: 1.5246e-04 - accuracy: 1.0000 - val_loss: 3.2713 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1844/4000\n",
      "2/2 - 0s - loss: 1.5221e-04 - accuracy: 1.0000 - val_loss: 3.2718 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1845/4000\n",
      "2/2 - 0s - loss: 1.5193e-04 - accuracy: 1.0000 - val_loss: 3.2723 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1846/4000\n",
      "2/2 - 0s - loss: 1.5170e-04 - accuracy: 1.0000 - val_loss: 3.2728 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1847/4000\n",
      "2/2 - 0s - loss: 1.5145e-04 - accuracy: 1.0000 - val_loss: 3.2733 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1848/4000\n",
      "2/2 - 0s - loss: 1.5123e-04 - accuracy: 1.0000 - val_loss: 3.2738 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1849/4000\n",
      "2/2 - 0s - loss: 1.5097e-04 - accuracy: 1.0000 - val_loss: 3.2743 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1850/4000\n",
      "2/2 - 0s - loss: 1.5073e-04 - accuracy: 1.0000 - val_loss: 3.2748 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1851/4000\n",
      "2/2 - 0s - loss: 1.5051e-04 - accuracy: 1.0000 - val_loss: 3.2753 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1852/4000\n",
      "2/2 - 0s - loss: 1.5024e-04 - accuracy: 1.0000 - val_loss: 3.2756 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1853/4000\n",
      "2/2 - 0s - loss: 1.5001e-04 - accuracy: 1.0000 - val_loss: 3.2760 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1854/4000\n",
      "2/2 - 0s - loss: 1.4978e-04 - accuracy: 1.0000 - val_loss: 3.2764 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 1855/4000\n",
      "2/2 - 0s - loss: 1.4954e-04 - accuracy: 1.0000 - val_loss: 3.2769 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1856/4000\n",
      "2/2 - 0s - loss: 1.4930e-04 - accuracy: 1.0000 - val_loss: 3.2775 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1857/4000\n",
      "2/2 - 0s - loss: 1.4905e-04 - accuracy: 1.0000 - val_loss: 3.2780 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1858/4000\n",
      "2/2 - 0s - loss: 1.4881e-04 - accuracy: 1.0000 - val_loss: 3.2785 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1859/4000\n",
      "2/2 - 0s - loss: 1.4860e-04 - accuracy: 1.0000 - val_loss: 3.2791 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1860/4000\n",
      "2/2 - 0s - loss: 1.4835e-04 - accuracy: 1.0000 - val_loss: 3.2796 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1861/4000\n",
      "2/2 - 0s - loss: 1.4811e-04 - accuracy: 1.0000 - val_loss: 3.2800 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1862/4000\n",
      "2/2 - 0s - loss: 1.4787e-04 - accuracy: 1.0000 - val_loss: 3.2805 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1863/4000\n",
      "2/2 - 0s - loss: 1.4763e-04 - accuracy: 1.0000 - val_loss: 3.2809 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1864/4000\n",
      "2/2 - 0s - loss: 1.4740e-04 - accuracy: 1.0000 - val_loss: 3.2813 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1865/4000\n",
      "2/2 - 0s - loss: 1.4716e-04 - accuracy: 1.0000 - val_loss: 3.2818 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1866/4000\n",
      "2/2 - 0s - loss: 1.4695e-04 - accuracy: 1.0000 - val_loss: 3.2822 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1867/4000\n",
      "2/2 - 0s - loss: 1.4671e-04 - accuracy: 1.0000 - val_loss: 3.2827 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1868/4000\n",
      "2/2 - 0s - loss: 1.4648e-04 - accuracy: 1.0000 - val_loss: 3.2832 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1869/4000\n",
      "2/2 - 0s - loss: 1.4624e-04 - accuracy: 1.0000 - val_loss: 3.2836 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1870/4000\n",
      "2/2 - 0s - loss: 1.4605e-04 - accuracy: 1.0000 - val_loss: 3.2841 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1871/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.4578e-04 - accuracy: 1.0000 - val_loss: 3.2847 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1872/4000\n",
      "2/2 - 0s - loss: 1.4553e-04 - accuracy: 1.0000 - val_loss: 3.2854 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1873/4000\n",
      "2/2 - 0s - loss: 1.4532e-04 - accuracy: 1.0000 - val_loss: 3.2860 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 1874/4000\n",
      "2/2 - 0s - loss: 1.4508e-04 - accuracy: 1.0000 - val_loss: 3.2865 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1875/4000\n",
      "2/2 - 0s - loss: 1.4485e-04 - accuracy: 1.0000 - val_loss: 3.2872 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1876/4000\n",
      "2/2 - 0s - loss: 1.4467e-04 - accuracy: 1.0000 - val_loss: 3.2878 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1877/4000\n",
      "2/2 - 0s - loss: 1.4438e-04 - accuracy: 1.0000 - val_loss: 3.2883 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1878/4000\n",
      "2/2 - 0s - loss: 1.4415e-04 - accuracy: 1.0000 - val_loss: 3.2887 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1879/4000\n",
      "2/2 - 0s - loss: 1.4392e-04 - accuracy: 1.0000 - val_loss: 3.2891 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1880/4000\n",
      "2/2 - 0s - loss: 1.4372e-04 - accuracy: 1.0000 - val_loss: 3.2896 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1881/4000\n",
      "2/2 - 0s - loss: 1.4347e-04 - accuracy: 1.0000 - val_loss: 3.2901 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1882/4000\n",
      "2/2 - 0s - loss: 1.4323e-04 - accuracy: 1.0000 - val_loss: 3.2907 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1883/4000\n",
      "2/2 - 0s - loss: 1.4303e-04 - accuracy: 1.0000 - val_loss: 3.2912 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1884/4000\n",
      "2/2 - 0s - loss: 1.4281e-04 - accuracy: 1.0000 - val_loss: 3.2917 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1885/4000\n",
      "2/2 - 0s - loss: 1.4256e-04 - accuracy: 1.0000 - val_loss: 3.2922 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1886/4000\n",
      "2/2 - 0s - loss: 1.4233e-04 - accuracy: 1.0000 - val_loss: 3.2927 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1887/4000\n",
      "2/2 - 0s - loss: 1.4210e-04 - accuracy: 1.0000 - val_loss: 3.2933 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1888/4000\n",
      "2/2 - 0s - loss: 1.4187e-04 - accuracy: 1.0000 - val_loss: 3.2938 - val_accuracy: 0.7250 - 45ms/epoch - 23ms/step\n",
      "Epoch 1889/4000\n",
      "2/2 - 0s - loss: 1.4164e-04 - accuracy: 1.0000 - val_loss: 3.2943 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1890/4000\n",
      "2/2 - 0s - loss: 1.4143e-04 - accuracy: 1.0000 - val_loss: 3.2948 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1891/4000\n",
      "2/2 - 0s - loss: 1.4120e-04 - accuracy: 1.0000 - val_loss: 3.2953 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1892/4000\n",
      "2/2 - 0s - loss: 1.4098e-04 - accuracy: 1.0000 - val_loss: 3.2958 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1893/4000\n",
      "2/2 - 0s - loss: 1.4076e-04 - accuracy: 1.0000 - val_loss: 3.2963 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1894/4000\n",
      "2/2 - 0s - loss: 1.4055e-04 - accuracy: 1.0000 - val_loss: 3.2968 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1895/4000\n",
      "2/2 - 0s - loss: 1.4028e-04 - accuracy: 1.0000 - val_loss: 3.2973 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 1896/4000\n",
      "2/2 - 0s - loss: 1.4008e-04 - accuracy: 1.0000 - val_loss: 3.2977 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 1897/4000\n",
      "2/2 - 0s - loss: 1.3986e-04 - accuracy: 1.0000 - val_loss: 3.2983 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1898/4000\n",
      "2/2 - 0s - loss: 1.3962e-04 - accuracy: 1.0000 - val_loss: 3.2988 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1899/4000\n",
      "2/2 - 0s - loss: 1.3945e-04 - accuracy: 1.0000 - val_loss: 3.2994 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1900/4000\n",
      "2/2 - 0s - loss: 1.3921e-04 - accuracy: 1.0000 - val_loss: 3.2998 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1901/4000\n",
      "2/2 - 0s - loss: 1.3897e-04 - accuracy: 1.0000 - val_loss: 3.3003 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1902/4000\n",
      "2/2 - 0s - loss: 1.3877e-04 - accuracy: 1.0000 - val_loss: 3.3008 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1903/4000\n",
      "2/2 - 0s - loss: 1.3858e-04 - accuracy: 1.0000 - val_loss: 3.3011 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1904/4000\n",
      "2/2 - 0s - loss: 1.3832e-04 - accuracy: 1.0000 - val_loss: 3.3016 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1905/4000\n",
      "2/2 - 0s - loss: 1.3812e-04 - accuracy: 1.0000 - val_loss: 3.3022 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1906/4000\n",
      "2/2 - 0s - loss: 1.3788e-04 - accuracy: 1.0000 - val_loss: 3.3027 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1907/4000\n",
      "2/2 - 0s - loss: 1.3767e-04 - accuracy: 1.0000 - val_loss: 3.3032 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1908/4000\n",
      "2/2 - 0s - loss: 1.3744e-04 - accuracy: 1.0000 - val_loss: 3.3038 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1909/4000\n",
      "2/2 - 0s - loss: 1.3725e-04 - accuracy: 1.0000 - val_loss: 3.3043 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 1910/4000\n",
      "2/2 - 0s - loss: 1.3702e-04 - accuracy: 1.0000 - val_loss: 3.3048 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1911/4000\n",
      "2/2 - 0s - loss: 1.3681e-04 - accuracy: 1.0000 - val_loss: 3.3053 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1912/4000\n",
      "2/2 - 0s - loss: 1.3659e-04 - accuracy: 1.0000 - val_loss: 3.3059 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1913/4000\n",
      "2/2 - 0s - loss: 1.3637e-04 - accuracy: 1.0000 - val_loss: 3.3063 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1914/4000\n",
      "2/2 - 0s - loss: 1.3618e-04 - accuracy: 1.0000 - val_loss: 3.3067 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1915/4000\n",
      "2/2 - 0s - loss: 1.3597e-04 - accuracy: 1.0000 - val_loss: 3.3072 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1916/4000\n",
      "2/2 - 0s - loss: 1.3573e-04 - accuracy: 1.0000 - val_loss: 3.3077 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 1917/4000\n",
      "2/2 - 0s - loss: 1.3551e-04 - accuracy: 1.0000 - val_loss: 3.3082 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1918/4000\n",
      "2/2 - 0s - loss: 1.3532e-04 - accuracy: 1.0000 - val_loss: 3.3087 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1919/4000\n",
      "2/2 - 0s - loss: 1.3510e-04 - accuracy: 1.0000 - val_loss: 3.3091 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1920/4000\n",
      "2/2 - 0s - loss: 1.3489e-04 - accuracy: 1.0000 - val_loss: 3.3095 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1921/4000\n",
      "2/2 - 0s - loss: 1.3469e-04 - accuracy: 1.0000 - val_loss: 3.3099 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1922/4000\n",
      "2/2 - 0s - loss: 1.3446e-04 - accuracy: 1.0000 - val_loss: 3.3104 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1923/4000\n",
      "2/2 - 0s - loss: 1.3427e-04 - accuracy: 1.0000 - val_loss: 3.3109 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1924/4000\n",
      "2/2 - 0s - loss: 1.3405e-04 - accuracy: 1.0000 - val_loss: 3.3114 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 1925/4000\n",
      "2/2 - 0s - loss: 1.3386e-04 - accuracy: 1.0000 - val_loss: 3.3119 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 1926/4000\n",
      "2/2 - 0s - loss: 1.3364e-04 - accuracy: 1.0000 - val_loss: 3.3124 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1927/4000\n",
      "2/2 - 0s - loss: 1.3343e-04 - accuracy: 1.0000 - val_loss: 3.3129 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1928/4000\n",
      "2/2 - 0s - loss: 1.3325e-04 - accuracy: 1.0000 - val_loss: 3.3135 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1929/4000\n",
      "2/2 - 0s - loss: 1.3300e-04 - accuracy: 1.0000 - val_loss: 3.3140 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1930/4000\n",
      "2/2 - 0s - loss: 1.3282e-04 - accuracy: 1.0000 - val_loss: 3.3146 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 1931/4000\n",
      "2/2 - 0s - loss: 1.3260e-04 - accuracy: 1.0000 - val_loss: 3.3151 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1932/4000\n",
      "2/2 - 0s - loss: 1.3241e-04 - accuracy: 1.0000 - val_loss: 3.3156 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1933/4000\n",
      "2/2 - 0s - loss: 1.3218e-04 - accuracy: 1.0000 - val_loss: 3.3161 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1934/4000\n",
      "2/2 - 0s - loss: 1.3197e-04 - accuracy: 1.0000 - val_loss: 3.3165 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1935/4000\n",
      "2/2 - 0s - loss: 1.3175e-04 - accuracy: 1.0000 - val_loss: 3.3170 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 1936/4000\n",
      "2/2 - 0s - loss: 1.3157e-04 - accuracy: 1.0000 - val_loss: 3.3174 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1937/4000\n",
      "2/2 - 0s - loss: 1.3137e-04 - accuracy: 1.0000 - val_loss: 3.3179 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 1938/4000\n",
      "2/2 - 0s - loss: 1.3115e-04 - accuracy: 1.0000 - val_loss: 3.3184 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1939/4000\n",
      "2/2 - 0s - loss: 1.3096e-04 - accuracy: 1.0000 - val_loss: 3.3188 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1940/4000\n",
      "2/2 - 0s - loss: 1.3074e-04 - accuracy: 1.0000 - val_loss: 3.3193 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1941/4000\n",
      "2/2 - 0s - loss: 1.3054e-04 - accuracy: 1.0000 - val_loss: 3.3198 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1942/4000\n",
      "2/2 - 0s - loss: 1.3034e-04 - accuracy: 1.0000 - val_loss: 3.3203 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1943/4000\n",
      "2/2 - 0s - loss: 1.3013e-04 - accuracy: 1.0000 - val_loss: 3.3208 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 1944/4000\n",
      "2/2 - 0s - loss: 1.2994e-04 - accuracy: 1.0000 - val_loss: 3.3212 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1945/4000\n",
      "2/2 - 0s - loss: 1.2975e-04 - accuracy: 1.0000 - val_loss: 3.3217 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 1946/4000\n",
      "2/2 - 0s - loss: 1.2955e-04 - accuracy: 1.0000 - val_loss: 3.3222 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1947/4000\n",
      "2/2 - 0s - loss: 1.2935e-04 - accuracy: 1.0000 - val_loss: 3.3227 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1948/4000\n",
      "2/2 - 0s - loss: 1.2912e-04 - accuracy: 1.0000 - val_loss: 3.3231 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1949/4000\n",
      "2/2 - 0s - loss: 1.2892e-04 - accuracy: 1.0000 - val_loss: 3.3235 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1950/4000\n",
      "2/2 - 0s - loss: 1.2875e-04 - accuracy: 1.0000 - val_loss: 3.3240 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 1951/4000\n",
      "2/2 - 0s - loss: 1.2853e-04 - accuracy: 1.0000 - val_loss: 3.3244 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 1952/4000\n",
      "2/2 - 0s - loss: 1.2834e-04 - accuracy: 1.0000 - val_loss: 3.3249 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 1953/4000\n",
      "2/2 - 0s - loss: 1.2812e-04 - accuracy: 1.0000 - val_loss: 3.3253 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 1954/4000\n",
      "2/2 - 0s - loss: 1.2794e-04 - accuracy: 1.0000 - val_loss: 3.3257 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1955/4000\n",
      "2/2 - 0s - loss: 1.2774e-04 - accuracy: 1.0000 - val_loss: 3.3261 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1956/4000\n",
      "2/2 - 0s - loss: 1.2754e-04 - accuracy: 1.0000 - val_loss: 3.3265 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1957/4000\n",
      "2/2 - 0s - loss: 1.2734e-04 - accuracy: 1.0000 - val_loss: 3.3270 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1958/4000\n",
      "2/2 - 0s - loss: 1.2714e-04 - accuracy: 1.0000 - val_loss: 3.3274 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1959/4000\n",
      "2/2 - 0s - loss: 1.2697e-04 - accuracy: 1.0000 - val_loss: 3.3280 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1960/4000\n",
      "2/2 - 0s - loss: 1.2676e-04 - accuracy: 1.0000 - val_loss: 3.3284 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1961/4000\n",
      "2/2 - 0s - loss: 1.2655e-04 - accuracy: 1.0000 - val_loss: 3.3289 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 1962/4000\n",
      "2/2 - 0s - loss: 1.2636e-04 - accuracy: 1.0000 - val_loss: 3.3293 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1963/4000\n",
      "2/2 - 0s - loss: 1.2617e-04 - accuracy: 1.0000 - val_loss: 3.3298 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1964/4000\n",
      "2/2 - 0s - loss: 1.2596e-04 - accuracy: 1.0000 - val_loss: 3.3304 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 1965/4000\n",
      "2/2 - 0s - loss: 1.2578e-04 - accuracy: 1.0000 - val_loss: 3.3309 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1966/4000\n",
      "2/2 - 0s - loss: 1.2559e-04 - accuracy: 1.0000 - val_loss: 3.3314 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1967/4000\n",
      "2/2 - 0s - loss: 1.2538e-04 - accuracy: 1.0000 - val_loss: 3.3319 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1968/4000\n",
      "2/2 - 0s - loss: 1.2520e-04 - accuracy: 1.0000 - val_loss: 3.3322 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 1969/4000\n",
      "2/2 - 0s - loss: 1.2502e-04 - accuracy: 1.0000 - val_loss: 3.3327 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 1970/4000\n",
      "2/2 - 0s - loss: 1.2480e-04 - accuracy: 1.0000 - val_loss: 3.3332 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1971/4000\n",
      "2/2 - 0s - loss: 1.2461e-04 - accuracy: 1.0000 - val_loss: 3.3337 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 1972/4000\n",
      "2/2 - 0s - loss: 1.2442e-04 - accuracy: 1.0000 - val_loss: 3.3342 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 1973/4000\n",
      "2/2 - 0s - loss: 1.2424e-04 - accuracy: 1.0000 - val_loss: 3.3347 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 1974/4000\n",
      "2/2 - 0s - loss: 1.2404e-04 - accuracy: 1.0000 - val_loss: 3.3351 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1975/4000\n",
      "2/2 - 0s - loss: 1.2386e-04 - accuracy: 1.0000 - val_loss: 3.3355 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 1976/4000\n",
      "2/2 - 0s - loss: 1.2365e-04 - accuracy: 1.0000 - val_loss: 3.3361 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1977/4000\n",
      "2/2 - 0s - loss: 1.2349e-04 - accuracy: 1.0000 - val_loss: 3.3367 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 1978/4000\n",
      "2/2 - 0s - loss: 1.2329e-04 - accuracy: 1.0000 - val_loss: 3.3372 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1979/4000\n",
      "2/2 - 0s - loss: 1.2310e-04 - accuracy: 1.0000 - val_loss: 3.3377 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1980/4000\n",
      "2/2 - 0s - loss: 1.2291e-04 - accuracy: 1.0000 - val_loss: 3.3381 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1981/4000\n",
      "2/2 - 0s - loss: 1.2271e-04 - accuracy: 1.0000 - val_loss: 3.3386 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 1982/4000\n",
      "2/2 - 0s - loss: 1.2253e-04 - accuracy: 1.0000 - val_loss: 3.3391 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1983/4000\n",
      "2/2 - 0s - loss: 1.2236e-04 - accuracy: 1.0000 - val_loss: 3.3395 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1984/4000\n",
      "2/2 - 0s - loss: 1.2216e-04 - accuracy: 1.0000 - val_loss: 3.3400 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1985/4000\n",
      "2/2 - 0s - loss: 1.2199e-04 - accuracy: 1.0000 - val_loss: 3.3406 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 1986/4000\n",
      "2/2 - 0s - loss: 1.2178e-04 - accuracy: 1.0000 - val_loss: 3.3411 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1987/4000\n",
      "2/2 - 0s - loss: 1.2157e-04 - accuracy: 1.0000 - val_loss: 3.3416 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 1988/4000\n",
      "2/2 - 0s - loss: 1.2143e-04 - accuracy: 1.0000 - val_loss: 3.3420 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 1989/4000\n",
      "2/2 - 0s - loss: 1.2121e-04 - accuracy: 1.0000 - val_loss: 3.3425 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 1990/4000\n",
      "2/2 - 0s - loss: 1.2106e-04 - accuracy: 1.0000 - val_loss: 3.3429 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 1991/4000\n",
      "2/2 - 0s - loss: 1.2087e-04 - accuracy: 1.0000 - val_loss: 3.3434 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 1992/4000\n",
      "2/2 - 0s - loss: 1.2067e-04 - accuracy: 1.0000 - val_loss: 3.3440 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 1993/4000\n",
      "2/2 - 0s - loss: 1.2048e-04 - accuracy: 1.0000 - val_loss: 3.3445 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 1994/4000\n",
      "2/2 - 0s - loss: 1.2030e-04 - accuracy: 1.0000 - val_loss: 3.3450 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 1995/4000\n",
      "2/2 - 0s - loss: 1.2013e-04 - accuracy: 1.0000 - val_loss: 3.3455 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 1996/4000\n",
      "2/2 - 0s - loss: 1.1994e-04 - accuracy: 1.0000 - val_loss: 3.3460 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 1997/4000\n",
      "2/2 - 0s - loss: 1.1975e-04 - accuracy: 1.0000 - val_loss: 3.3465 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 1998/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.1958e-04 - accuracy: 1.0000 - val_loss: 3.3470 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 1999/4000\n",
      "2/2 - 0s - loss: 1.1939e-04 - accuracy: 1.0000 - val_loss: 3.3474 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 2000/4000\n",
      "2/2 - 0s - loss: 1.1923e-04 - accuracy: 1.0000 - val_loss: 3.3479 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2001/4000\n",
      "2/2 - 0s - loss: 1.1903e-04 - accuracy: 1.0000 - val_loss: 3.3484 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2002/4000\n",
      "2/2 - 0s - loss: 1.1884e-04 - accuracy: 1.0000 - val_loss: 3.3489 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2003/4000\n",
      "2/2 - 0s - loss: 1.1867e-04 - accuracy: 1.0000 - val_loss: 3.3494 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2004/4000\n",
      "2/2 - 0s - loss: 1.1851e-04 - accuracy: 1.0000 - val_loss: 3.3499 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2005/4000\n",
      "2/2 - 0s - loss: 1.1830e-04 - accuracy: 1.0000 - val_loss: 3.3503 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2006/4000\n",
      "2/2 - 0s - loss: 1.1813e-04 - accuracy: 1.0000 - val_loss: 3.3507 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2007/4000\n",
      "2/2 - 0s - loss: 1.1795e-04 - accuracy: 1.0000 - val_loss: 3.3512 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2008/4000\n",
      "2/2 - 0s - loss: 1.1777e-04 - accuracy: 1.0000 - val_loss: 3.3518 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2009/4000\n",
      "2/2 - 0s - loss: 1.1759e-04 - accuracy: 1.0000 - val_loss: 3.3522 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2010/4000\n",
      "2/2 - 0s - loss: 1.1741e-04 - accuracy: 1.0000 - val_loss: 3.3528 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2011/4000\n",
      "2/2 - 0s - loss: 1.1724e-04 - accuracy: 1.0000 - val_loss: 3.3533 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2012/4000\n",
      "2/2 - 0s - loss: 1.1703e-04 - accuracy: 1.0000 - val_loss: 3.3538 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2013/4000\n",
      "2/2 - 0s - loss: 1.1688e-04 - accuracy: 1.0000 - val_loss: 3.3542 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2014/4000\n",
      "2/2 - 0s - loss: 1.1668e-04 - accuracy: 1.0000 - val_loss: 3.3547 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2015/4000\n",
      "2/2 - 0s - loss: 1.1649e-04 - accuracy: 1.0000 - val_loss: 3.3552 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2016/4000\n",
      "2/2 - 0s - loss: 1.1631e-04 - accuracy: 1.0000 - val_loss: 3.3557 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2017/4000\n",
      "2/2 - 0s - loss: 1.1616e-04 - accuracy: 1.0000 - val_loss: 3.3562 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2018/4000\n",
      "2/2 - 0s - loss: 1.1597e-04 - accuracy: 1.0000 - val_loss: 3.3567 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2019/4000\n",
      "2/2 - 0s - loss: 1.1581e-04 - accuracy: 1.0000 - val_loss: 3.3572 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2020/4000\n",
      "2/2 - 0s - loss: 1.1564e-04 - accuracy: 1.0000 - val_loss: 3.3577 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2021/4000\n",
      "2/2 - 0s - loss: 1.1546e-04 - accuracy: 1.0000 - val_loss: 3.3582 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 2022/4000\n",
      "2/2 - 0s - loss: 1.1527e-04 - accuracy: 1.0000 - val_loss: 3.3587 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2023/4000\n",
      "2/2 - 0s - loss: 1.1508e-04 - accuracy: 1.0000 - val_loss: 3.3593 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2024/4000\n",
      "2/2 - 0s - loss: 1.1492e-04 - accuracy: 1.0000 - val_loss: 3.3598 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 2025/4000\n",
      "2/2 - 0s - loss: 1.1476e-04 - accuracy: 1.0000 - val_loss: 3.3604 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 2026/4000\n",
      "2/2 - 0s - loss: 1.1458e-04 - accuracy: 1.0000 - val_loss: 3.3608 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2027/4000\n",
      "2/2 - 0s - loss: 1.1439e-04 - accuracy: 1.0000 - val_loss: 3.3613 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2028/4000\n",
      "2/2 - 0s - loss: 1.1422e-04 - accuracy: 1.0000 - val_loss: 3.3617 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 2029/4000\n",
      "2/2 - 0s - loss: 1.1405e-04 - accuracy: 1.0000 - val_loss: 3.3622 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2030/4000\n",
      "2/2 - 0s - loss: 1.1388e-04 - accuracy: 1.0000 - val_loss: 3.3628 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2031/4000\n",
      "2/2 - 0s - loss: 1.1369e-04 - accuracy: 1.0000 - val_loss: 3.3633 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2032/4000\n",
      "2/2 - 0s - loss: 1.1352e-04 - accuracy: 1.0000 - val_loss: 3.3638 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2033/4000\n",
      "2/2 - 0s - loss: 1.1337e-04 - accuracy: 1.0000 - val_loss: 3.3643 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2034/4000\n",
      "2/2 - 0s - loss: 1.1318e-04 - accuracy: 1.0000 - val_loss: 3.3647 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2035/4000\n",
      "2/2 - 0s - loss: 1.1302e-04 - accuracy: 1.0000 - val_loss: 3.3651 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2036/4000\n",
      "2/2 - 0s - loss: 1.1285e-04 - accuracy: 1.0000 - val_loss: 3.3655 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2037/4000\n",
      "2/2 - 0s - loss: 1.1265e-04 - accuracy: 1.0000 - val_loss: 3.3660 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 2038/4000\n",
      "2/2 - 0s - loss: 1.1250e-04 - accuracy: 1.0000 - val_loss: 3.3664 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2039/4000\n",
      "2/2 - 0s - loss: 1.1234e-04 - accuracy: 1.0000 - val_loss: 3.3670 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2040/4000\n",
      "2/2 - 0s - loss: 1.1216e-04 - accuracy: 1.0000 - val_loss: 3.3673 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2041/4000\n",
      "2/2 - 0s - loss: 1.1198e-04 - accuracy: 1.0000 - val_loss: 3.3677 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2042/4000\n",
      "2/2 - 0s - loss: 1.1185e-04 - accuracy: 1.0000 - val_loss: 3.3681 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 2043/4000\n",
      "2/2 - 0s - loss: 1.1166e-04 - accuracy: 1.0000 - val_loss: 3.3686 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2044/4000\n",
      "2/2 - 0s - loss: 1.1149e-04 - accuracy: 1.0000 - val_loss: 3.3691 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2045/4000\n",
      "2/2 - 0s - loss: 1.1131e-04 - accuracy: 1.0000 - val_loss: 3.3695 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2046/4000\n",
      "2/2 - 0s - loss: 1.1114e-04 - accuracy: 1.0000 - val_loss: 3.3699 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2047/4000\n",
      "2/2 - 0s - loss: 1.1098e-04 - accuracy: 1.0000 - val_loss: 3.3703 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2048/4000\n",
      "2/2 - 0s - loss: 1.1082e-04 - accuracy: 1.0000 - val_loss: 3.3707 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2049/4000\n",
      "2/2 - 0s - loss: 1.1066e-04 - accuracy: 1.0000 - val_loss: 3.3711 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2050/4000\n",
      "2/2 - 0s - loss: 1.1048e-04 - accuracy: 1.0000 - val_loss: 3.3715 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2051/4000\n",
      "2/2 - 0s - loss: 1.1032e-04 - accuracy: 1.0000 - val_loss: 3.3720 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2052/4000\n",
      "2/2 - 0s - loss: 1.1013e-04 - accuracy: 1.0000 - val_loss: 3.3725 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2053/4000\n",
      "2/2 - 0s - loss: 1.0998e-04 - accuracy: 1.0000 - val_loss: 3.3729 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2054/4000\n",
      "2/2 - 0s - loss: 1.0982e-04 - accuracy: 1.0000 - val_loss: 3.3733 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2055/4000\n",
      "2/2 - 0s - loss: 1.0967e-04 - accuracy: 1.0000 - val_loss: 3.3738 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2056/4000\n",
      "2/2 - 0s - loss: 1.0948e-04 - accuracy: 1.0000 - val_loss: 3.3742 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2057/4000\n",
      "2/2 - 0s - loss: 1.0931e-04 - accuracy: 1.0000 - val_loss: 3.3746 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2058/4000\n",
      "2/2 - 0s - loss: 1.0915e-04 - accuracy: 1.0000 - val_loss: 3.3751 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2059/4000\n",
      "2/2 - 0s - loss: 1.0899e-04 - accuracy: 1.0000 - val_loss: 3.3756 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2060/4000\n",
      "2/2 - 0s - loss: 1.0884e-04 - accuracy: 1.0000 - val_loss: 3.3760 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2061/4000\n",
      "2/2 - 0s - loss: 1.0866e-04 - accuracy: 1.0000 - val_loss: 3.3763 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2062/4000\n",
      "2/2 - 0s - loss: 1.0850e-04 - accuracy: 1.0000 - val_loss: 3.3767 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2063/4000\n",
      "2/2 - 0s - loss: 1.0834e-04 - accuracy: 1.0000 - val_loss: 3.3772 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2064/4000\n",
      "2/2 - 0s - loss: 1.0817e-04 - accuracy: 1.0000 - val_loss: 3.3777 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 2065/4000\n",
      "2/2 - 0s - loss: 1.0800e-04 - accuracy: 1.0000 - val_loss: 3.3781 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2066/4000\n",
      "2/2 - 0s - loss: 1.0785e-04 - accuracy: 1.0000 - val_loss: 3.3785 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2067/4000\n",
      "2/2 - 0s - loss: 1.0766e-04 - accuracy: 1.0000 - val_loss: 3.3789 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2068/4000\n",
      "2/2 - 0s - loss: 1.0753e-04 - accuracy: 1.0000 - val_loss: 3.3793 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2069/4000\n",
      "2/2 - 0s - loss: 1.0737e-04 - accuracy: 1.0000 - val_loss: 3.3798 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2070/4000\n",
      "2/2 - 0s - loss: 1.0720e-04 - accuracy: 1.0000 - val_loss: 3.3803 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2071/4000\n",
      "2/2 - 0s - loss: 1.0703e-04 - accuracy: 1.0000 - val_loss: 3.3807 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2072/4000\n",
      "2/2 - 0s - loss: 1.0686e-04 - accuracy: 1.0000 - val_loss: 3.3812 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2073/4000\n",
      "2/2 - 0s - loss: 1.0671e-04 - accuracy: 1.0000 - val_loss: 3.3816 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2074/4000\n",
      "2/2 - 0s - loss: 1.0656e-04 - accuracy: 1.0000 - val_loss: 3.3819 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2075/4000\n",
      "2/2 - 0s - loss: 1.0639e-04 - accuracy: 1.0000 - val_loss: 3.3823 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2076/4000\n",
      "2/2 - 0s - loss: 1.0624e-04 - accuracy: 1.0000 - val_loss: 3.3827 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 2077/4000\n",
      "2/2 - 0s - loss: 1.0609e-04 - accuracy: 1.0000 - val_loss: 3.3832 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2078/4000\n",
      "2/2 - 0s - loss: 1.0591e-04 - accuracy: 1.0000 - val_loss: 3.3837 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2079/4000\n",
      "2/2 - 0s - loss: 1.0574e-04 - accuracy: 1.0000 - val_loss: 3.3842 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2080/4000\n",
      "2/2 - 0s - loss: 1.0558e-04 - accuracy: 1.0000 - val_loss: 3.3847 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2081/4000\n",
      "2/2 - 0s - loss: 1.0543e-04 - accuracy: 1.0000 - val_loss: 3.3852 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2082/4000\n",
      "2/2 - 0s - loss: 1.0530e-04 - accuracy: 1.0000 - val_loss: 3.3856 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2083/4000\n",
      "2/2 - 0s - loss: 1.0513e-04 - accuracy: 1.0000 - val_loss: 3.3861 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2084/4000\n",
      "2/2 - 0s - loss: 1.0497e-04 - accuracy: 1.0000 - val_loss: 3.3866 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2085/4000\n",
      "2/2 - 0s - loss: 1.0481e-04 - accuracy: 1.0000 - val_loss: 3.3870 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2086/4000\n",
      "2/2 - 0s - loss: 1.0465e-04 - accuracy: 1.0000 - val_loss: 3.3875 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2087/4000\n",
      "2/2 - 0s - loss: 1.0451e-04 - accuracy: 1.0000 - val_loss: 3.3880 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2088/4000\n",
      "2/2 - 0s - loss: 1.0434e-04 - accuracy: 1.0000 - val_loss: 3.3885 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2089/4000\n",
      "2/2 - 0s - loss: 1.0419e-04 - accuracy: 1.0000 - val_loss: 3.3889 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2090/4000\n",
      "2/2 - 0s - loss: 1.0403e-04 - accuracy: 1.0000 - val_loss: 3.3892 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2091/4000\n",
      "2/2 - 0s - loss: 1.0388e-04 - accuracy: 1.0000 - val_loss: 3.3896 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2092/4000\n",
      "2/2 - 0s - loss: 1.0372e-04 - accuracy: 1.0000 - val_loss: 3.3899 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2093/4000\n",
      "2/2 - 0s - loss: 1.0355e-04 - accuracy: 1.0000 - val_loss: 3.3903 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2094/4000\n",
      "2/2 - 0s - loss: 1.0342e-04 - accuracy: 1.0000 - val_loss: 3.3907 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2095/4000\n",
      "2/2 - 0s - loss: 1.0324e-04 - accuracy: 1.0000 - val_loss: 3.3912 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2096/4000\n",
      "2/2 - 0s - loss: 1.0311e-04 - accuracy: 1.0000 - val_loss: 3.3917 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2097/4000\n",
      "2/2 - 0s - loss: 1.0295e-04 - accuracy: 1.0000 - val_loss: 3.3921 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2098/4000\n",
      "2/2 - 0s - loss: 1.0280e-04 - accuracy: 1.0000 - val_loss: 3.3926 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2099/4000\n",
      "2/2 - 0s - loss: 1.0264e-04 - accuracy: 1.0000 - val_loss: 3.3931 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2100/4000\n",
      "2/2 - 0s - loss: 1.0248e-04 - accuracy: 1.0000 - val_loss: 3.3936 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2101/4000\n",
      "2/2 - 0s - loss: 1.0232e-04 - accuracy: 1.0000 - val_loss: 3.3941 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2102/4000\n",
      "2/2 - 0s - loss: 1.0218e-04 - accuracy: 1.0000 - val_loss: 3.3946 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 2103/4000\n",
      "2/2 - 0s - loss: 1.0203e-04 - accuracy: 1.0000 - val_loss: 3.3950 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2104/4000\n",
      "2/2 - 0s - loss: 1.0188e-04 - accuracy: 1.0000 - val_loss: 3.3954 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2105/4000\n",
      "2/2 - 0s - loss: 1.0172e-04 - accuracy: 1.0000 - val_loss: 3.3958 - val_accuracy: 0.7250 - 83ms/epoch - 41ms/step\n",
      "Epoch 2106/4000\n",
      "2/2 - 0s - loss: 1.0158e-04 - accuracy: 1.0000 - val_loss: 3.3962 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2107/4000\n",
      "2/2 - 0s - loss: 1.0143e-04 - accuracy: 1.0000 - val_loss: 3.3965 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 2108/4000\n",
      "2/2 - 0s - loss: 1.0127e-04 - accuracy: 1.0000 - val_loss: 3.3970 - val_accuracy: 0.7250 - 79ms/epoch - 39ms/step\n",
      "Epoch 2109/4000\n",
      "2/2 - 0s - loss: 1.0112e-04 - accuracy: 1.0000 - val_loss: 3.3975 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2110/4000\n",
      "2/2 - 0s - loss: 1.0100e-04 - accuracy: 1.0000 - val_loss: 3.3979 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2111/4000\n",
      "2/2 - 0s - loss: 1.0082e-04 - accuracy: 1.0000 - val_loss: 3.3984 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2112/4000\n",
      "2/2 - 0s - loss: 1.0067e-04 - accuracy: 1.0000 - val_loss: 3.3989 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2113/4000\n",
      "2/2 - 0s - loss: 1.0051e-04 - accuracy: 1.0000 - val_loss: 3.3994 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2114/4000\n",
      "2/2 - 0s - loss: 1.0040e-04 - accuracy: 1.0000 - val_loss: 3.3998 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2115/4000\n",
      "2/2 - 0s - loss: 1.0023e-04 - accuracy: 1.0000 - val_loss: 3.4002 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2116/4000\n",
      "2/2 - 0s - loss: 1.0009e-04 - accuracy: 1.0000 - val_loss: 3.4007 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2117/4000\n",
      "2/2 - 0s - loss: 9.9925e-05 - accuracy: 1.0000 - val_loss: 3.4012 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2118/4000\n",
      "2/2 - 0s - loss: 9.9791e-05 - accuracy: 1.0000 - val_loss: 3.4016 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2119/4000\n",
      "2/2 - 0s - loss: 9.9638e-05 - accuracy: 1.0000 - val_loss: 3.4020 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2120/4000\n",
      "2/2 - 0s - loss: 9.9483e-05 - accuracy: 1.0000 - val_loss: 3.4024 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2121/4000\n",
      "2/2 - 0s - loss: 9.9336e-05 - accuracy: 1.0000 - val_loss: 3.4028 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2122/4000\n",
      "2/2 - 0s - loss: 9.9217e-05 - accuracy: 1.0000 - val_loss: 3.4032 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2123/4000\n",
      "2/2 - 0s - loss: 9.9055e-05 - accuracy: 1.0000 - val_loss: 3.4036 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2124/4000\n",
      "2/2 - 0s - loss: 9.8906e-05 - accuracy: 1.0000 - val_loss: 3.4041 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2125/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 9.8776e-05 - accuracy: 1.0000 - val_loss: 3.4045 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 2126/4000\n",
      "2/2 - 0s - loss: 9.8631e-05 - accuracy: 1.0000 - val_loss: 3.4050 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2127/4000\n",
      "2/2 - 0s - loss: 9.8463e-05 - accuracy: 1.0000 - val_loss: 3.4055 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2128/4000\n",
      "2/2 - 0s - loss: 9.8338e-05 - accuracy: 1.0000 - val_loss: 3.4060 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2129/4000\n",
      "2/2 - 0s - loss: 9.8172e-05 - accuracy: 1.0000 - val_loss: 3.4065 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2130/4000\n",
      "2/2 - 0s - loss: 9.8025e-05 - accuracy: 1.0000 - val_loss: 3.4070 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2131/4000\n",
      "2/2 - 0s - loss: 9.7869e-05 - accuracy: 1.0000 - val_loss: 3.4074 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2132/4000\n",
      "2/2 - 0s - loss: 9.7752e-05 - accuracy: 1.0000 - val_loss: 3.4079 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2133/4000\n",
      "2/2 - 0s - loss: 9.7586e-05 - accuracy: 1.0000 - val_loss: 3.4084 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2134/4000\n",
      "2/2 - 0s - loss: 9.7461e-05 - accuracy: 1.0000 - val_loss: 3.4089 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2135/4000\n",
      "2/2 - 0s - loss: 9.7305e-05 - accuracy: 1.0000 - val_loss: 3.4093 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2136/4000\n",
      "2/2 - 0s - loss: 9.7152e-05 - accuracy: 1.0000 - val_loss: 3.4098 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2137/4000\n",
      "2/2 - 0s - loss: 9.7029e-05 - accuracy: 1.0000 - val_loss: 3.4102 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2138/4000\n",
      "2/2 - 0s - loss: 9.6878e-05 - accuracy: 1.0000 - val_loss: 3.4106 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2139/4000\n",
      "2/2 - 0s - loss: 9.6735e-05 - accuracy: 1.0000 - val_loss: 3.4110 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2140/4000\n",
      "2/2 - 0s - loss: 9.6597e-05 - accuracy: 1.0000 - val_loss: 3.4114 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2141/4000\n",
      "2/2 - 0s - loss: 9.6441e-05 - accuracy: 1.0000 - val_loss: 3.4118 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2142/4000\n",
      "2/2 - 0s - loss: 9.6314e-05 - accuracy: 1.0000 - val_loss: 3.4123 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2143/4000\n",
      "2/2 - 0s - loss: 9.6184e-05 - accuracy: 1.0000 - val_loss: 3.4127 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2144/4000\n",
      "2/2 - 0s - loss: 9.6016e-05 - accuracy: 1.0000 - val_loss: 3.4131 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2145/4000\n",
      "2/2 - 0s - loss: 9.5892e-05 - accuracy: 1.0000 - val_loss: 3.4136 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2146/4000\n",
      "2/2 - 0s - loss: 9.5749e-05 - accuracy: 1.0000 - val_loss: 3.4140 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2147/4000\n",
      "2/2 - 0s - loss: 9.5618e-05 - accuracy: 1.0000 - val_loss: 3.4145 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2148/4000\n",
      "2/2 - 0s - loss: 9.5447e-05 - accuracy: 1.0000 - val_loss: 3.4149 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2149/4000\n",
      "2/2 - 0s - loss: 9.5324e-05 - accuracy: 1.0000 - val_loss: 3.4153 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2150/4000\n",
      "2/2 - 0s - loss: 9.5198e-05 - accuracy: 1.0000 - val_loss: 3.4158 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2151/4000\n",
      "2/2 - 0s - loss: 9.5026e-05 - accuracy: 1.0000 - val_loss: 3.4163 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2152/4000\n",
      "2/2 - 0s - loss: 9.4915e-05 - accuracy: 1.0000 - val_loss: 3.4167 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2153/4000\n",
      "2/2 - 0s - loss: 9.4766e-05 - accuracy: 1.0000 - val_loss: 3.4170 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2154/4000\n",
      "2/2 - 0s - loss: 9.4624e-05 - accuracy: 1.0000 - val_loss: 3.4175 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2155/4000\n",
      "2/2 - 0s - loss: 9.4481e-05 - accuracy: 1.0000 - val_loss: 3.4179 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2156/4000\n",
      "2/2 - 0s - loss: 9.4355e-05 - accuracy: 1.0000 - val_loss: 3.4184 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2157/4000\n",
      "2/2 - 0s - loss: 9.4204e-05 - accuracy: 1.0000 - val_loss: 3.4189 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2158/4000\n",
      "2/2 - 0s - loss: 9.4062e-05 - accuracy: 1.0000 - val_loss: 3.4194 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2159/4000\n",
      "2/2 - 0s - loss: 9.3911e-05 - accuracy: 1.0000 - val_loss: 3.4198 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2160/4000\n",
      "2/2 - 0s - loss: 9.3785e-05 - accuracy: 1.0000 - val_loss: 3.4202 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2161/4000\n",
      "2/2 - 0s - loss: 9.3647e-05 - accuracy: 1.0000 - val_loss: 3.4206 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2162/4000\n",
      "2/2 - 0s - loss: 9.3502e-05 - accuracy: 1.0000 - val_loss: 3.4210 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2163/4000\n",
      "2/2 - 0s - loss: 9.3361e-05 - accuracy: 1.0000 - val_loss: 3.4215 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2164/4000\n",
      "2/2 - 0s - loss: 9.3240e-05 - accuracy: 1.0000 - val_loss: 3.4219 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2165/4000\n",
      "2/2 - 0s - loss: 9.3097e-05 - accuracy: 1.0000 - val_loss: 3.4223 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2166/4000\n",
      "2/2 - 0s - loss: 9.2963e-05 - accuracy: 1.0000 - val_loss: 3.4229 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2167/4000\n",
      "2/2 - 0s - loss: 9.2823e-05 - accuracy: 1.0000 - val_loss: 3.4234 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2168/4000\n",
      "2/2 - 0s - loss: 9.2691e-05 - accuracy: 1.0000 - val_loss: 3.4239 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2169/4000\n",
      "2/2 - 0s - loss: 9.2563e-05 - accuracy: 1.0000 - val_loss: 3.4244 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2170/4000\n",
      "2/2 - 0s - loss: 9.2427e-05 - accuracy: 1.0000 - val_loss: 3.4249 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2171/4000\n",
      "2/2 - 0s - loss: 9.2297e-05 - accuracy: 1.0000 - val_loss: 3.4253 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 2172/4000\n",
      "2/2 - 0s - loss: 9.2127e-05 - accuracy: 1.0000 - val_loss: 3.4256 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2173/4000\n",
      "2/2 - 0s - loss: 9.2003e-05 - accuracy: 1.0000 - val_loss: 3.4260 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2174/4000\n",
      "2/2 - 0s - loss: 9.1869e-05 - accuracy: 1.0000 - val_loss: 3.4265 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2175/4000\n",
      "2/2 - 0s - loss: 9.1757e-05 - accuracy: 1.0000 - val_loss: 3.4269 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2176/4000\n",
      "2/2 - 0s - loss: 9.1608e-05 - accuracy: 1.0000 - val_loss: 3.4273 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2177/4000\n",
      "2/2 - 0s - loss: 9.1482e-05 - accuracy: 1.0000 - val_loss: 3.4278 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2178/4000\n",
      "2/2 - 0s - loss: 9.1367e-05 - accuracy: 1.0000 - val_loss: 3.4282 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2179/4000\n",
      "2/2 - 0s - loss: 9.1218e-05 - accuracy: 1.0000 - val_loss: 3.4286 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2180/4000\n",
      "2/2 - 0s - loss: 9.1073e-05 - accuracy: 1.0000 - val_loss: 3.4290 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2181/4000\n",
      "2/2 - 0s - loss: 9.0950e-05 - accuracy: 1.0000 - val_loss: 3.4295 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2182/4000\n",
      "2/2 - 0s - loss: 9.0816e-05 - accuracy: 1.0000 - val_loss: 3.4299 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2183/4000\n",
      "2/2 - 0s - loss: 9.0694e-05 - accuracy: 1.0000 - val_loss: 3.4304 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2184/4000\n",
      "2/2 - 0s - loss: 9.0565e-05 - accuracy: 1.0000 - val_loss: 3.4308 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2185/4000\n",
      "2/2 - 0s - loss: 9.0426e-05 - accuracy: 1.0000 - val_loss: 3.4312 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2186/4000\n",
      "2/2 - 0s - loss: 9.0309e-05 - accuracy: 1.0000 - val_loss: 3.4316 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2187/4000\n",
      "2/2 - 0s - loss: 9.0154e-05 - accuracy: 1.0000 - val_loss: 3.4321 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2188/4000\n",
      "2/2 - 0s - loss: 9.0018e-05 - accuracy: 1.0000 - val_loss: 3.4326 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2189/4000\n",
      "2/2 - 0s - loss: 8.9892e-05 - accuracy: 1.0000 - val_loss: 3.4331 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2190/4000\n",
      "2/2 - 0s - loss: 8.9764e-05 - accuracy: 1.0000 - val_loss: 3.4336 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2191/4000\n",
      "2/2 - 0s - loss: 8.9635e-05 - accuracy: 1.0000 - val_loss: 3.4342 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2192/4000\n",
      "2/2 - 0s - loss: 8.9486e-05 - accuracy: 1.0000 - val_loss: 3.4347 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 2193/4000\n",
      "2/2 - 0s - loss: 8.9368e-05 - accuracy: 1.0000 - val_loss: 3.4352 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2194/4000\n",
      "2/2 - 0s - loss: 8.9254e-05 - accuracy: 1.0000 - val_loss: 3.4357 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 2195/4000\n",
      "2/2 - 0s - loss: 8.9107e-05 - accuracy: 1.0000 - val_loss: 3.4362 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2196/4000\n",
      "2/2 - 0s - loss: 8.8973e-05 - accuracy: 1.0000 - val_loss: 3.4367 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2197/4000\n",
      "2/2 - 0s - loss: 8.8847e-05 - accuracy: 1.0000 - val_loss: 3.4371 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2198/4000\n",
      "2/2 - 0s - loss: 8.8719e-05 - accuracy: 1.0000 - val_loss: 3.4376 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2199/4000\n",
      "2/2 - 0s - loss: 8.8585e-05 - accuracy: 1.0000 - val_loss: 3.4381 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 2200/4000\n",
      "2/2 - 0s - loss: 8.8453e-05 - accuracy: 1.0000 - val_loss: 3.4385 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2201/4000\n",
      "2/2 - 0s - loss: 8.8332e-05 - accuracy: 1.0000 - val_loss: 3.4389 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2202/4000\n",
      "2/2 - 0s - loss: 8.8191e-05 - accuracy: 1.0000 - val_loss: 3.4393 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2203/4000\n",
      "2/2 - 0s - loss: 8.8064e-05 - accuracy: 1.0000 - val_loss: 3.4398 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2204/4000\n",
      "2/2 - 0s - loss: 8.7940e-05 - accuracy: 1.0000 - val_loss: 3.4402 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2205/4000\n",
      "2/2 - 0s - loss: 8.7819e-05 - accuracy: 1.0000 - val_loss: 3.4407 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2206/4000\n",
      "2/2 - 0s - loss: 8.7696e-05 - accuracy: 1.0000 - val_loss: 3.4412 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 2207/4000\n",
      "2/2 - 0s - loss: 8.7566e-05 - accuracy: 1.0000 - val_loss: 3.4416 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2208/4000\n",
      "2/2 - 0s - loss: 8.7436e-05 - accuracy: 1.0000 - val_loss: 3.4421 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 2209/4000\n",
      "2/2 - 0s - loss: 8.7319e-05 - accuracy: 1.0000 - val_loss: 3.4426 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2210/4000\n",
      "2/2 - 0s - loss: 8.7178e-05 - accuracy: 1.0000 - val_loss: 3.4430 - val_accuracy: 0.7250 - 83ms/epoch - 42ms/step\n",
      "Epoch 2211/4000\n",
      "2/2 - 0s - loss: 8.7046e-05 - accuracy: 1.0000 - val_loss: 3.4435 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2212/4000\n",
      "2/2 - 0s - loss: 8.6923e-05 - accuracy: 1.0000 - val_loss: 3.4439 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2213/4000\n",
      "2/2 - 0s - loss: 8.6806e-05 - accuracy: 1.0000 - val_loss: 3.4443 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2214/4000\n",
      "2/2 - 0s - loss: 8.6682e-05 - accuracy: 1.0000 - val_loss: 3.4447 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2215/4000\n",
      "2/2 - 0s - loss: 8.6557e-05 - accuracy: 1.0000 - val_loss: 3.4451 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2216/4000\n",
      "2/2 - 0s - loss: 8.6431e-05 - accuracy: 1.0000 - val_loss: 3.4456 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2217/4000\n",
      "2/2 - 0s - loss: 8.6293e-05 - accuracy: 1.0000 - val_loss: 3.4461 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2218/4000\n",
      "2/2 - 0s - loss: 8.6180e-05 - accuracy: 1.0000 - val_loss: 3.4467 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2219/4000\n",
      "2/2 - 0s - loss: 8.6055e-05 - accuracy: 1.0000 - val_loss: 3.4472 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2220/4000\n",
      "2/2 - 0s - loss: 8.5929e-05 - accuracy: 1.0000 - val_loss: 3.4477 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2221/4000\n",
      "2/2 - 0s - loss: 8.5808e-05 - accuracy: 1.0000 - val_loss: 3.4480 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2222/4000\n",
      "2/2 - 0s - loss: 8.5678e-05 - accuracy: 1.0000 - val_loss: 3.4483 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2223/4000\n",
      "2/2 - 0s - loss: 8.5567e-05 - accuracy: 1.0000 - val_loss: 3.4487 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2224/4000\n",
      "2/2 - 0s - loss: 8.5444e-05 - accuracy: 1.0000 - val_loss: 3.4492 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2225/4000\n",
      "2/2 - 0s - loss: 8.5316e-05 - accuracy: 1.0000 - val_loss: 3.4496 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2226/4000\n",
      "2/2 - 0s - loss: 8.5184e-05 - accuracy: 1.0000 - val_loss: 3.4501 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2227/4000\n",
      "2/2 - 0s - loss: 8.5056e-05 - accuracy: 1.0000 - val_loss: 3.4505 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2228/4000\n",
      "2/2 - 0s - loss: 8.4939e-05 - accuracy: 1.0000 - val_loss: 3.4510 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2229/4000\n",
      "2/2 - 0s - loss: 8.4809e-05 - accuracy: 1.0000 - val_loss: 3.4516 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2230/4000\n",
      "2/2 - 0s - loss: 8.4688e-05 - accuracy: 1.0000 - val_loss: 3.4520 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 2231/4000\n",
      "2/2 - 0s - loss: 8.4571e-05 - accuracy: 1.0000 - val_loss: 3.4524 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2232/4000\n",
      "2/2 - 0s - loss: 8.4450e-05 - accuracy: 1.0000 - val_loss: 3.4528 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2233/4000\n",
      "2/2 - 0s - loss: 8.4337e-05 - accuracy: 1.0000 - val_loss: 3.4533 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2234/4000\n",
      "2/2 - 0s - loss: 8.4213e-05 - accuracy: 1.0000 - val_loss: 3.4537 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2235/4000\n",
      "2/2 - 0s - loss: 8.4071e-05 - accuracy: 1.0000 - val_loss: 3.4542 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2236/4000\n",
      "2/2 - 0s - loss: 8.3967e-05 - accuracy: 1.0000 - val_loss: 3.4547 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2237/4000\n",
      "2/2 - 0s - loss: 8.3845e-05 - accuracy: 1.0000 - val_loss: 3.4551 - val_accuracy: 0.7250 - 77ms/epoch - 39ms/step\n",
      "Epoch 2238/4000\n",
      "2/2 - 0s - loss: 8.3730e-05 - accuracy: 1.0000 - val_loss: 3.4556 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2239/4000\n",
      "2/2 - 0s - loss: 8.3603e-05 - accuracy: 1.0000 - val_loss: 3.4560 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2240/4000\n",
      "2/2 - 0s - loss: 8.3492e-05 - accuracy: 1.0000 - val_loss: 3.4565 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2241/4000\n",
      "2/2 - 0s - loss: 8.3368e-05 - accuracy: 1.0000 - val_loss: 3.4569 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2242/4000\n",
      "2/2 - 0s - loss: 8.3251e-05 - accuracy: 1.0000 - val_loss: 3.4573 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2243/4000\n",
      "2/2 - 0s - loss: 8.3124e-05 - accuracy: 1.0000 - val_loss: 3.4578 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2244/4000\n",
      "2/2 - 0s - loss: 8.3004e-05 - accuracy: 1.0000 - val_loss: 3.4582 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2245/4000\n",
      "2/2 - 0s - loss: 8.2879e-05 - accuracy: 1.0000 - val_loss: 3.4586 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2246/4000\n",
      "2/2 - 0s - loss: 8.2768e-05 - accuracy: 1.0000 - val_loss: 3.4590 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2247/4000\n",
      "2/2 - 0s - loss: 8.2649e-05 - accuracy: 1.0000 - val_loss: 3.4594 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2248/4000\n",
      "2/2 - 0s - loss: 8.2547e-05 - accuracy: 1.0000 - val_loss: 3.4598 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2249/4000\n",
      "2/2 - 0s - loss: 8.2411e-05 - accuracy: 1.0000 - val_loss: 3.4603 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2250/4000\n",
      "2/2 - 0s - loss: 8.2287e-05 - accuracy: 1.0000 - val_loss: 3.4607 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 2251/4000\n",
      "2/2 - 0s - loss: 8.2183e-05 - accuracy: 1.0000 - val_loss: 3.4611 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 2252/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 8.2068e-05 - accuracy: 1.0000 - val_loss: 3.4616 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2253/4000\n",
      "2/2 - 0s - loss: 8.1928e-05 - accuracy: 1.0000 - val_loss: 3.4620 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2254/4000\n",
      "2/2 - 0s - loss: 8.1813e-05 - accuracy: 1.0000 - val_loss: 3.4623 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2255/4000\n",
      "2/2 - 0s - loss: 8.1698e-05 - accuracy: 1.0000 - val_loss: 3.4627 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2256/4000\n",
      "2/2 - 0s - loss: 8.1583e-05 - accuracy: 1.0000 - val_loss: 3.4631 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2257/4000\n",
      "2/2 - 0s - loss: 8.1470e-05 - accuracy: 1.0000 - val_loss: 3.4636 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2258/4000\n",
      "2/2 - 0s - loss: 8.1346e-05 - accuracy: 1.0000 - val_loss: 3.4641 - val_accuracy: 0.7250 - 79ms/epoch - 39ms/step\n",
      "Epoch 2259/4000\n",
      "2/2 - 0s - loss: 8.1229e-05 - accuracy: 1.0000 - val_loss: 3.4645 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 2260/4000\n",
      "2/2 - 0s - loss: 8.1121e-05 - accuracy: 1.0000 - val_loss: 3.4649 - val_accuracy: 0.7250 - 87ms/epoch - 44ms/step\n",
      "Epoch 2261/4000\n",
      "2/2 - 0s - loss: 8.0999e-05 - accuracy: 1.0000 - val_loss: 3.4654 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 2262/4000\n",
      "2/2 - 0s - loss: 8.0876e-05 - accuracy: 1.0000 - val_loss: 3.4658 - val_accuracy: 0.7250 - 99ms/epoch - 49ms/step\n",
      "Epoch 2263/4000\n",
      "2/2 - 0s - loss: 8.0761e-05 - accuracy: 1.0000 - val_loss: 3.4661 - val_accuracy: 0.7250 - 84ms/epoch - 42ms/step\n",
      "Epoch 2264/4000\n",
      "2/2 - 0s - loss: 8.0655e-05 - accuracy: 1.0000 - val_loss: 3.4664 - val_accuracy: 0.7250 - 80ms/epoch - 40ms/step\n",
      "Epoch 2265/4000\n",
      "2/2 - 0s - loss: 8.0529e-05 - accuracy: 1.0000 - val_loss: 3.4668 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 2266/4000\n",
      "2/2 - 0s - loss: 8.0425e-05 - accuracy: 1.0000 - val_loss: 3.4672 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 2267/4000\n",
      "2/2 - 0s - loss: 8.0327e-05 - accuracy: 1.0000 - val_loss: 3.4676 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2268/4000\n",
      "2/2 - 0s - loss: 8.0193e-05 - accuracy: 1.0000 - val_loss: 3.4680 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2269/4000\n",
      "2/2 - 0s - loss: 8.0082e-05 - accuracy: 1.0000 - val_loss: 3.4683 - val_accuracy: 0.7250 - 100ms/epoch - 50ms/step\n",
      "Epoch 2270/4000\n",
      "2/2 - 0s - loss: 7.9971e-05 - accuracy: 1.0000 - val_loss: 3.4687 - val_accuracy: 0.7250 - 83ms/epoch - 42ms/step\n",
      "Epoch 2271/4000\n",
      "2/2 - 0s - loss: 7.9863e-05 - accuracy: 1.0000 - val_loss: 3.4692 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2272/4000\n",
      "2/2 - 0s - loss: 7.9733e-05 - accuracy: 1.0000 - val_loss: 3.4696 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2273/4000\n",
      "2/2 - 0s - loss: 7.9614e-05 - accuracy: 1.0000 - val_loss: 3.4700 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2274/4000\n",
      "2/2 - 0s - loss: 7.9512e-05 - accuracy: 1.0000 - val_loss: 3.4703 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2275/4000\n",
      "2/2 - 0s - loss: 7.9390e-05 - accuracy: 1.0000 - val_loss: 3.4708 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 2276/4000\n",
      "2/2 - 0s - loss: 7.9295e-05 - accuracy: 1.0000 - val_loss: 3.4712 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2277/4000\n",
      "2/2 - 0s - loss: 7.9173e-05 - accuracy: 1.0000 - val_loss: 3.4716 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2278/4000\n",
      "2/2 - 0s - loss: 7.9065e-05 - accuracy: 1.0000 - val_loss: 3.4721 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2279/4000\n",
      "2/2 - 0s - loss: 7.8946e-05 - accuracy: 1.0000 - val_loss: 3.4726 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2280/4000\n",
      "2/2 - 0s - loss: 7.8831e-05 - accuracy: 1.0000 - val_loss: 3.4730 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2281/4000\n",
      "2/2 - 0s - loss: 7.8724e-05 - accuracy: 1.0000 - val_loss: 3.4735 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2282/4000\n",
      "2/2 - 0s - loss: 7.8618e-05 - accuracy: 1.0000 - val_loss: 3.4740 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2283/4000\n",
      "2/2 - 0s - loss: 7.8499e-05 - accuracy: 1.0000 - val_loss: 3.4744 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2284/4000\n",
      "2/2 - 0s - loss: 7.8371e-05 - accuracy: 1.0000 - val_loss: 3.4749 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2285/4000\n",
      "2/2 - 0s - loss: 7.8273e-05 - accuracy: 1.0000 - val_loss: 3.4753 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2286/4000\n",
      "2/2 - 0s - loss: 7.8173e-05 - accuracy: 1.0000 - val_loss: 3.4757 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2287/4000\n",
      "2/2 - 0s - loss: 7.8049e-05 - accuracy: 1.0000 - val_loss: 3.4762 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2288/4000\n",
      "2/2 - 0s - loss: 7.7952e-05 - accuracy: 1.0000 - val_loss: 3.4767 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2289/4000\n",
      "2/2 - 0s - loss: 7.7854e-05 - accuracy: 1.0000 - val_loss: 3.4771 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2290/4000\n",
      "2/2 - 0s - loss: 7.7734e-05 - accuracy: 1.0000 - val_loss: 3.4775 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2291/4000\n",
      "2/2 - 0s - loss: 7.7602e-05 - accuracy: 1.0000 - val_loss: 3.4779 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2292/4000\n",
      "2/2 - 0s - loss: 7.7500e-05 - accuracy: 1.0000 - val_loss: 3.4783 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2293/4000\n",
      "2/2 - 0s - loss: 7.7396e-05 - accuracy: 1.0000 - val_loss: 3.4788 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2294/4000\n",
      "2/2 - 0s - loss: 7.7275e-05 - accuracy: 1.0000 - val_loss: 3.4792 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2295/4000\n",
      "2/2 - 0s - loss: 7.7158e-05 - accuracy: 1.0000 - val_loss: 3.4796 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2296/4000\n",
      "2/2 - 0s - loss: 7.7055e-05 - accuracy: 1.0000 - val_loss: 3.4799 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2297/4000\n",
      "2/2 - 0s - loss: 7.6934e-05 - accuracy: 1.0000 - val_loss: 3.4804 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2298/4000\n",
      "2/2 - 0s - loss: 7.6830e-05 - accuracy: 1.0000 - val_loss: 3.4810 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2299/4000\n",
      "2/2 - 0s - loss: 7.6715e-05 - accuracy: 1.0000 - val_loss: 3.4814 - val_accuracy: 0.7250 - 85ms/epoch - 42ms/step\n",
      "Epoch 2300/4000\n",
      "2/2 - 0s - loss: 7.6617e-05 - accuracy: 1.0000 - val_loss: 3.4818 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2301/4000\n",
      "2/2 - 0s - loss: 7.6513e-05 - accuracy: 1.0000 - val_loss: 3.4822 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2302/4000\n",
      "2/2 - 0s - loss: 7.6381e-05 - accuracy: 1.0000 - val_loss: 3.4827 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 2303/4000\n",
      "2/2 - 0s - loss: 7.6270e-05 - accuracy: 1.0000 - val_loss: 3.4832 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2304/4000\n",
      "2/2 - 0s - loss: 7.6168e-05 - accuracy: 1.0000 - val_loss: 3.4837 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2305/4000\n",
      "2/2 - 0s - loss: 7.6083e-05 - accuracy: 1.0000 - val_loss: 3.4843 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2306/4000\n",
      "2/2 - 0s - loss: 7.5964e-05 - accuracy: 1.0000 - val_loss: 3.4847 - val_accuracy: 0.7250 - 77ms/epoch - 39ms/step\n",
      "Epoch 2307/4000\n",
      "2/2 - 0s - loss: 7.5859e-05 - accuracy: 1.0000 - val_loss: 3.4852 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2308/4000\n",
      "2/2 - 0s - loss: 7.5744e-05 - accuracy: 1.0000 - val_loss: 3.4857 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2309/4000\n",
      "2/2 - 0s - loss: 7.5655e-05 - accuracy: 1.0000 - val_loss: 3.4863 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2310/4000\n",
      "2/2 - 0s - loss: 7.5523e-05 - accuracy: 1.0000 - val_loss: 3.4866 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2311/4000\n",
      "2/2 - 0s - loss: 7.5421e-05 - accuracy: 1.0000 - val_loss: 3.4871 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2312/4000\n",
      "2/2 - 0s - loss: 7.5319e-05 - accuracy: 1.0000 - val_loss: 3.4875 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2313/4000\n",
      "2/2 - 0s - loss: 7.5219e-05 - accuracy: 1.0000 - val_loss: 3.4880 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2314/4000\n",
      "2/2 - 0s - loss: 7.5104e-05 - accuracy: 1.0000 - val_loss: 3.4884 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2315/4000\n",
      "2/2 - 0s - loss: 7.4982e-05 - accuracy: 1.0000 - val_loss: 3.4889 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2316/4000\n",
      "2/2 - 0s - loss: 7.4895e-05 - accuracy: 1.0000 - val_loss: 3.4894 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2317/4000\n",
      "2/2 - 0s - loss: 7.4784e-05 - accuracy: 1.0000 - val_loss: 3.4898 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2318/4000\n",
      "2/2 - 0s - loss: 7.4684e-05 - accuracy: 1.0000 - val_loss: 3.4902 - val_accuracy: 0.7250 - 77ms/epoch - 39ms/step\n",
      "Epoch 2319/4000\n",
      "2/2 - 0s - loss: 7.4569e-05 - accuracy: 1.0000 - val_loss: 3.4907 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2320/4000\n",
      "2/2 - 0s - loss: 7.4461e-05 - accuracy: 1.0000 - val_loss: 3.4911 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2321/4000\n",
      "2/2 - 0s - loss: 7.4359e-05 - accuracy: 1.0000 - val_loss: 3.4915 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2322/4000\n",
      "2/2 - 0s - loss: 7.4252e-05 - accuracy: 1.0000 - val_loss: 3.4920 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2323/4000\n",
      "2/2 - 0s - loss: 7.4148e-05 - accuracy: 1.0000 - val_loss: 3.4925 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2324/4000\n",
      "2/2 - 0s - loss: 7.4042e-05 - accuracy: 1.0000 - val_loss: 3.4929 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2325/4000\n",
      "2/2 - 0s - loss: 7.3933e-05 - accuracy: 1.0000 - val_loss: 3.4933 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2326/4000\n",
      "2/2 - 0s - loss: 7.3844e-05 - accuracy: 1.0000 - val_loss: 3.4937 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2327/4000\n",
      "2/2 - 0s - loss: 7.3729e-05 - accuracy: 1.0000 - val_loss: 3.4942 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2328/4000\n",
      "2/2 - 0s - loss: 7.3616e-05 - accuracy: 1.0000 - val_loss: 3.4947 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2329/4000\n",
      "2/2 - 0s - loss: 7.3514e-05 - accuracy: 1.0000 - val_loss: 3.4951 - val_accuracy: 0.7250 - 84ms/epoch - 42ms/step\n",
      "Epoch 2330/4000\n",
      "2/2 - 0s - loss: 7.3405e-05 - accuracy: 1.0000 - val_loss: 3.4956 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2331/4000\n",
      "2/2 - 0s - loss: 7.3309e-05 - accuracy: 1.0000 - val_loss: 3.4960 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2332/4000\n",
      "2/2 - 0s - loss: 7.3226e-05 - accuracy: 1.0000 - val_loss: 3.4964 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2333/4000\n",
      "2/2 - 0s - loss: 7.3105e-05 - accuracy: 1.0000 - val_loss: 3.4969 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2334/4000\n",
      "2/2 - 0s - loss: 7.3001e-05 - accuracy: 1.0000 - val_loss: 3.4973 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2335/4000\n",
      "2/2 - 0s - loss: 7.2901e-05 - accuracy: 1.0000 - val_loss: 3.4977 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2336/4000\n",
      "2/2 - 0s - loss: 7.2794e-05 - accuracy: 1.0000 - val_loss: 3.4982 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2337/4000\n",
      "2/2 - 0s - loss: 7.2694e-05 - accuracy: 1.0000 - val_loss: 3.4986 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2338/4000\n",
      "2/2 - 0s - loss: 7.2584e-05 - accuracy: 1.0000 - val_loss: 3.4990 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2339/4000\n",
      "2/2 - 0s - loss: 7.2486e-05 - accuracy: 1.0000 - val_loss: 3.4995 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2340/4000\n",
      "2/2 - 0s - loss: 7.2386e-05 - accuracy: 1.0000 - val_loss: 3.4999 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2341/4000\n",
      "2/2 - 0s - loss: 7.2277e-05 - accuracy: 1.0000 - val_loss: 3.5004 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2342/4000\n",
      "2/2 - 0s - loss: 7.2175e-05 - accuracy: 1.0000 - val_loss: 3.5009 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2343/4000\n",
      "2/2 - 0s - loss: 7.2088e-05 - accuracy: 1.0000 - val_loss: 3.5013 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2344/4000\n",
      "2/2 - 0s - loss: 7.1996e-05 - accuracy: 1.0000 - val_loss: 3.5017 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2345/4000\n",
      "2/2 - 0s - loss: 7.1879e-05 - accuracy: 1.0000 - val_loss: 3.5021 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2346/4000\n",
      "2/2 - 0s - loss: 7.1779e-05 - accuracy: 1.0000 - val_loss: 3.5025 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2347/4000\n",
      "2/2 - 0s - loss: 7.1673e-05 - accuracy: 1.0000 - val_loss: 3.5030 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2348/4000\n",
      "2/2 - 0s - loss: 7.1555e-05 - accuracy: 1.0000 - val_loss: 3.5035 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2349/4000\n",
      "2/2 - 0s - loss: 7.1464e-05 - accuracy: 1.0000 - val_loss: 3.5040 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2350/4000\n",
      "2/2 - 0s - loss: 7.1379e-05 - accuracy: 1.0000 - val_loss: 3.5044 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2351/4000\n",
      "2/2 - 0s - loss: 7.1277e-05 - accuracy: 1.0000 - val_loss: 3.5049 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2352/4000\n",
      "2/2 - 0s - loss: 7.1179e-05 - accuracy: 1.0000 - val_loss: 3.5053 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2353/4000\n",
      "2/2 - 0s - loss: 7.1070e-05 - accuracy: 1.0000 - val_loss: 3.5058 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2354/4000\n",
      "2/2 - 0s - loss: 7.0966e-05 - accuracy: 1.0000 - val_loss: 3.5062 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2355/4000\n",
      "2/2 - 0s - loss: 7.0872e-05 - accuracy: 1.0000 - val_loss: 3.5067 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2356/4000\n",
      "2/2 - 0s - loss: 7.0757e-05 - accuracy: 1.0000 - val_loss: 3.5071 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2357/4000\n",
      "2/2 - 0s - loss: 7.0670e-05 - accuracy: 1.0000 - val_loss: 3.5076 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2358/4000\n",
      "2/2 - 0s - loss: 7.0568e-05 - accuracy: 1.0000 - val_loss: 3.5081 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2359/4000\n",
      "2/2 - 0s - loss: 7.0470e-05 - accuracy: 1.0000 - val_loss: 3.5085 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 2360/4000\n",
      "2/2 - 0s - loss: 7.0372e-05 - accuracy: 1.0000 - val_loss: 3.5089 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2361/4000\n",
      "2/2 - 0s - loss: 7.0268e-05 - accuracy: 1.0000 - val_loss: 3.5094 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2362/4000\n",
      "2/2 - 0s - loss: 7.0176e-05 - accuracy: 1.0000 - val_loss: 3.5097 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2363/4000\n",
      "2/2 - 0s - loss: 7.0076e-05 - accuracy: 1.0000 - val_loss: 3.5101 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 2364/4000\n",
      "2/2 - 0s - loss: 6.9985e-05 - accuracy: 1.0000 - val_loss: 3.5105 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2365/4000\n",
      "2/2 - 0s - loss: 6.9882e-05 - accuracy: 1.0000 - val_loss: 3.5110 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2366/4000\n",
      "2/2 - 0s - loss: 6.9785e-05 - accuracy: 1.0000 - val_loss: 3.5115 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2367/4000\n",
      "2/2 - 0s - loss: 6.9697e-05 - accuracy: 1.0000 - val_loss: 3.5119 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2368/4000\n",
      "2/2 - 0s - loss: 6.9599e-05 - accuracy: 1.0000 - val_loss: 3.5122 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2369/4000\n",
      "2/2 - 0s - loss: 6.9512e-05 - accuracy: 1.0000 - val_loss: 3.5126 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2370/4000\n",
      "2/2 - 0s - loss: 6.9412e-05 - accuracy: 1.0000 - val_loss: 3.5130 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2371/4000\n",
      "2/2 - 0s - loss: 6.9306e-05 - accuracy: 1.0000 - val_loss: 3.5134 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2372/4000\n",
      "2/2 - 0s - loss: 6.9208e-05 - accuracy: 1.0000 - val_loss: 3.5139 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2373/4000\n",
      "2/2 - 0s - loss: 6.9112e-05 - accuracy: 1.0000 - val_loss: 3.5144 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2374/4000\n",
      "2/2 - 0s - loss: 6.9006e-05 - accuracy: 1.0000 - val_loss: 3.5148 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2375/4000\n",
      "2/2 - 0s - loss: 6.8920e-05 - accuracy: 1.0000 - val_loss: 3.5152 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2376/4000\n",
      "2/2 - 0s - loss: 6.8829e-05 - accuracy: 1.0000 - val_loss: 3.5157 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2377/4000\n",
      "2/2 - 0s - loss: 6.8729e-05 - accuracy: 1.0000 - val_loss: 3.5161 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2378/4000\n",
      "2/2 - 0s - loss: 6.8633e-05 - accuracy: 1.0000 - val_loss: 3.5165 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2379/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 6.8531e-05 - accuracy: 1.0000 - val_loss: 3.5169 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2380/4000\n",
      "2/2 - 0s - loss: 6.8441e-05 - accuracy: 1.0000 - val_loss: 3.5173 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2381/4000\n",
      "2/2 - 0s - loss: 6.8361e-05 - accuracy: 1.0000 - val_loss: 3.5176 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2382/4000\n",
      "2/2 - 0s - loss: 6.8258e-05 - accuracy: 1.0000 - val_loss: 3.5180 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2383/4000\n",
      "2/2 - 0s - loss: 6.8169e-05 - accuracy: 1.0000 - val_loss: 3.5185 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2384/4000\n",
      "2/2 - 0s - loss: 6.8060e-05 - accuracy: 1.0000 - val_loss: 3.5189 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2385/4000\n",
      "2/2 - 0s - loss: 6.7975e-05 - accuracy: 1.0000 - val_loss: 3.5194 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2386/4000\n",
      "2/2 - 0s - loss: 6.7871e-05 - accuracy: 1.0000 - val_loss: 3.5198 - val_accuracy: 0.7250 - 79ms/epoch - 39ms/step\n",
      "Epoch 2387/4000\n",
      "2/2 - 0s - loss: 6.7784e-05 - accuracy: 1.0000 - val_loss: 3.5203 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2388/4000\n",
      "2/2 - 0s - loss: 6.7686e-05 - accuracy: 1.0000 - val_loss: 3.5208 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2389/4000\n",
      "2/2 - 0s - loss: 6.7599e-05 - accuracy: 1.0000 - val_loss: 3.5213 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2390/4000\n",
      "2/2 - 0s - loss: 6.7496e-05 - accuracy: 1.0000 - val_loss: 3.5217 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2391/4000\n",
      "2/2 - 0s - loss: 6.7405e-05 - accuracy: 1.0000 - val_loss: 3.5221 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2392/4000\n",
      "2/2 - 0s - loss: 6.7292e-05 - accuracy: 1.0000 - val_loss: 3.5224 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2393/4000\n",
      "2/2 - 0s - loss: 6.7205e-05 - accuracy: 1.0000 - val_loss: 3.5228 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2394/4000\n",
      "2/2 - 0s - loss: 6.7113e-05 - accuracy: 1.0000 - val_loss: 3.5233 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2395/4000\n",
      "2/2 - 0s - loss: 6.7039e-05 - accuracy: 1.0000 - val_loss: 3.5237 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2396/4000\n",
      "2/2 - 0s - loss: 6.6945e-05 - accuracy: 1.0000 - val_loss: 3.5242 - val_accuracy: 0.7250 - 81ms/epoch - 40ms/step\n",
      "Epoch 2397/4000\n",
      "2/2 - 0s - loss: 6.6841e-05 - accuracy: 1.0000 - val_loss: 3.5246 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2398/4000\n",
      "2/2 - 0s - loss: 6.6751e-05 - accuracy: 1.0000 - val_loss: 3.5249 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2399/4000\n",
      "2/2 - 0s - loss: 6.6658e-05 - accuracy: 1.0000 - val_loss: 3.5255 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2400/4000\n",
      "2/2 - 0s - loss: 6.6566e-05 - accuracy: 1.0000 - val_loss: 3.5260 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2401/4000\n",
      "2/2 - 0s - loss: 6.6470e-05 - accuracy: 1.0000 - val_loss: 3.5264 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2402/4000\n",
      "2/2 - 0s - loss: 6.6381e-05 - accuracy: 1.0000 - val_loss: 3.5268 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2403/4000\n",
      "2/2 - 0s - loss: 6.6285e-05 - accuracy: 1.0000 - val_loss: 3.5272 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2404/4000\n",
      "2/2 - 0s - loss: 6.6209e-05 - accuracy: 1.0000 - val_loss: 3.5276 - val_accuracy: 0.7250 - 80ms/epoch - 40ms/step\n",
      "Epoch 2405/4000\n",
      "2/2 - 0s - loss: 6.6102e-05 - accuracy: 1.0000 - val_loss: 3.5280 - val_accuracy: 0.7250 - 79ms/epoch - 39ms/step\n",
      "Epoch 2406/4000\n",
      "2/2 - 0s - loss: 6.6002e-05 - accuracy: 1.0000 - val_loss: 3.5285 - val_accuracy: 0.7250 - 80ms/epoch - 40ms/step\n",
      "Epoch 2407/4000\n",
      "2/2 - 0s - loss: 6.5928e-05 - accuracy: 1.0000 - val_loss: 3.5290 - val_accuracy: 0.7250 - 81ms/epoch - 41ms/step\n",
      "Epoch 2408/4000\n",
      "2/2 - 0s - loss: 6.5823e-05 - accuracy: 1.0000 - val_loss: 3.5296 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2409/4000\n",
      "2/2 - 0s - loss: 6.5738e-05 - accuracy: 1.0000 - val_loss: 3.5301 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 2410/4000\n",
      "2/2 - 0s - loss: 6.5647e-05 - accuracy: 1.0000 - val_loss: 3.5305 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2411/4000\n",
      "2/2 - 0s - loss: 6.5553e-05 - accuracy: 1.0000 - val_loss: 3.5309 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2412/4000\n",
      "2/2 - 0s - loss: 6.5476e-05 - accuracy: 1.0000 - val_loss: 3.5314 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2413/4000\n",
      "2/2 - 0s - loss: 6.5381e-05 - accuracy: 1.0000 - val_loss: 3.5318 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2414/4000\n",
      "2/2 - 0s - loss: 6.5283e-05 - accuracy: 1.0000 - val_loss: 3.5323 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2415/4000\n",
      "2/2 - 0s - loss: 6.5196e-05 - accuracy: 1.0000 - val_loss: 3.5326 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2416/4000\n",
      "2/2 - 0s - loss: 6.5106e-05 - accuracy: 1.0000 - val_loss: 3.5330 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2417/4000\n",
      "2/2 - 0s - loss: 6.5025e-05 - accuracy: 1.0000 - val_loss: 3.5334 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 2418/4000\n",
      "2/2 - 0s - loss: 6.4929e-05 - accuracy: 1.0000 - val_loss: 3.5338 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2419/4000\n",
      "2/2 - 0s - loss: 6.4846e-05 - accuracy: 1.0000 - val_loss: 3.5344 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2420/4000\n",
      "2/2 - 0s - loss: 6.4749e-05 - accuracy: 1.0000 - val_loss: 3.5348 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2421/4000\n",
      "2/2 - 0s - loss: 6.4657e-05 - accuracy: 1.0000 - val_loss: 3.5351 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2422/4000\n",
      "2/2 - 0s - loss: 6.4561e-05 - accuracy: 1.0000 - val_loss: 3.5355 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2423/4000\n",
      "2/2 - 0s - loss: 6.4465e-05 - accuracy: 1.0000 - val_loss: 3.5359 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2424/4000\n",
      "2/2 - 0s - loss: 6.4378e-05 - accuracy: 1.0000 - val_loss: 3.5363 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2425/4000\n",
      "2/2 - 0s - loss: 6.4293e-05 - accuracy: 1.0000 - val_loss: 3.5368 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2426/4000\n",
      "2/2 - 0s - loss: 6.4195e-05 - accuracy: 1.0000 - val_loss: 3.5373 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2427/4000\n",
      "2/2 - 0s - loss: 6.4112e-05 - accuracy: 1.0000 - val_loss: 3.5378 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2428/4000\n",
      "2/2 - 0s - loss: 6.4029e-05 - accuracy: 1.0000 - val_loss: 3.5383 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2429/4000\n",
      "2/2 - 0s - loss: 6.3938e-05 - accuracy: 1.0000 - val_loss: 3.5387 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2430/4000\n",
      "2/2 - 0s - loss: 6.3861e-05 - accuracy: 1.0000 - val_loss: 3.5391 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2431/4000\n",
      "2/2 - 0s - loss: 6.3763e-05 - accuracy: 1.0000 - val_loss: 3.5396 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2432/4000\n",
      "2/2 - 0s - loss: 6.3682e-05 - accuracy: 1.0000 - val_loss: 3.5400 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2433/4000\n",
      "2/2 - 0s - loss: 6.3599e-05 - accuracy: 1.0000 - val_loss: 3.5405 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2434/4000\n",
      "2/2 - 0s - loss: 6.3501e-05 - accuracy: 1.0000 - val_loss: 3.5409 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2435/4000\n",
      "2/2 - 0s - loss: 6.3403e-05 - accuracy: 1.0000 - val_loss: 3.5413 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2436/4000\n",
      "2/2 - 0s - loss: 6.3327e-05 - accuracy: 1.0000 - val_loss: 3.5417 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2437/4000\n",
      "2/2 - 0s - loss: 6.3225e-05 - accuracy: 1.0000 - val_loss: 3.5421 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2438/4000\n",
      "2/2 - 0s - loss: 6.3146e-05 - accuracy: 1.0000 - val_loss: 3.5426 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2439/4000\n",
      "2/2 - 0s - loss: 6.3069e-05 - accuracy: 1.0000 - val_loss: 3.5430 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2440/4000\n",
      "2/2 - 0s - loss: 6.2971e-05 - accuracy: 1.0000 - val_loss: 3.5434 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2441/4000\n",
      "2/2 - 0s - loss: 6.2899e-05 - accuracy: 1.0000 - val_loss: 3.5438 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2442/4000\n",
      "2/2 - 0s - loss: 6.2820e-05 - accuracy: 1.0000 - val_loss: 3.5442 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2443/4000\n",
      "2/2 - 0s - loss: 6.2731e-05 - accuracy: 1.0000 - val_loss: 3.5446 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2444/4000\n",
      "2/2 - 0s - loss: 6.2637e-05 - accuracy: 1.0000 - val_loss: 3.5451 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2445/4000\n",
      "2/2 - 0s - loss: 6.2539e-05 - accuracy: 1.0000 - val_loss: 3.5455 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2446/4000\n",
      "2/2 - 0s - loss: 6.2463e-05 - accuracy: 1.0000 - val_loss: 3.5458 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2447/4000\n",
      "2/2 - 0s - loss: 6.2367e-05 - accuracy: 1.0000 - val_loss: 3.5463 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2448/4000\n",
      "2/2 - 0s - loss: 6.2290e-05 - accuracy: 1.0000 - val_loss: 3.5467 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2449/4000\n",
      "2/2 - 0s - loss: 6.2188e-05 - accuracy: 1.0000 - val_loss: 3.5472 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2450/4000\n",
      "2/2 - 0s - loss: 6.2103e-05 - accuracy: 1.0000 - val_loss: 3.5477 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2451/4000\n",
      "2/2 - 0s - loss: 6.2024e-05 - accuracy: 1.0000 - val_loss: 3.5481 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 2452/4000\n",
      "2/2 - 0s - loss: 6.1941e-05 - accuracy: 1.0000 - val_loss: 3.5484 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2453/4000\n",
      "2/2 - 0s - loss: 6.1860e-05 - accuracy: 1.0000 - val_loss: 3.5488 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2454/4000\n",
      "2/2 - 0s - loss: 6.1769e-05 - accuracy: 1.0000 - val_loss: 3.5492 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2455/4000\n",
      "2/2 - 0s - loss: 6.1683e-05 - accuracy: 1.0000 - val_loss: 3.5496 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2456/4000\n",
      "2/2 - 0s - loss: 6.1607e-05 - accuracy: 1.0000 - val_loss: 3.5500 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2457/4000\n",
      "2/2 - 0s - loss: 6.1515e-05 - accuracy: 1.0000 - val_loss: 3.5503 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2458/4000\n",
      "2/2 - 0s - loss: 6.1428e-05 - accuracy: 1.0000 - val_loss: 3.5507 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 2459/4000\n",
      "2/2 - 0s - loss: 6.1358e-05 - accuracy: 1.0000 - val_loss: 3.5511 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2460/4000\n",
      "2/2 - 0s - loss: 6.1262e-05 - accuracy: 1.0000 - val_loss: 3.5515 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2461/4000\n",
      "2/2 - 0s - loss: 6.1181e-05 - accuracy: 1.0000 - val_loss: 3.5520 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2462/4000\n",
      "2/2 - 0s - loss: 6.1090e-05 - accuracy: 1.0000 - val_loss: 3.5524 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2463/4000\n",
      "2/2 - 0s - loss: 6.1019e-05 - accuracy: 1.0000 - val_loss: 3.5529 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2464/4000\n",
      "2/2 - 0s - loss: 6.0938e-05 - accuracy: 1.0000 - val_loss: 3.5533 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2465/4000\n",
      "2/2 - 0s - loss: 6.0843e-05 - accuracy: 1.0000 - val_loss: 3.5537 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2466/4000\n",
      "2/2 - 0s - loss: 6.0772e-05 - accuracy: 1.0000 - val_loss: 3.5541 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2467/4000\n",
      "2/2 - 0s - loss: 6.0675e-05 - accuracy: 1.0000 - val_loss: 3.5544 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2468/4000\n",
      "2/2 - 0s - loss: 6.0600e-05 - accuracy: 1.0000 - val_loss: 3.5549 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2469/4000\n",
      "2/2 - 0s - loss: 6.0513e-05 - accuracy: 1.0000 - val_loss: 3.5554 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2470/4000\n",
      "2/2 - 0s - loss: 6.0425e-05 - accuracy: 1.0000 - val_loss: 3.5558 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2471/4000\n",
      "2/2 - 0s - loss: 6.0342e-05 - accuracy: 1.0000 - val_loss: 3.5562 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2472/4000\n",
      "2/2 - 0s - loss: 6.0262e-05 - accuracy: 1.0000 - val_loss: 3.5566 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2473/4000\n",
      "2/2 - 0s - loss: 6.0185e-05 - accuracy: 1.0000 - val_loss: 3.5570 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2474/4000\n",
      "2/2 - 0s - loss: 6.0096e-05 - accuracy: 1.0000 - val_loss: 3.5574 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2475/4000\n",
      "2/2 - 0s - loss: 6.0025e-05 - accuracy: 1.0000 - val_loss: 3.5578 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2476/4000\n",
      "2/2 - 0s - loss: 5.9930e-05 - accuracy: 1.0000 - val_loss: 3.5583 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2477/4000\n",
      "2/2 - 0s - loss: 5.9830e-05 - accuracy: 1.0000 - val_loss: 3.5587 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2478/4000\n",
      "2/2 - 0s - loss: 5.9764e-05 - accuracy: 1.0000 - val_loss: 3.5592 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2479/4000\n",
      "2/2 - 0s - loss: 5.9676e-05 - accuracy: 1.0000 - val_loss: 3.5596 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2480/4000\n",
      "2/2 - 0s - loss: 5.9593e-05 - accuracy: 1.0000 - val_loss: 3.5600 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2481/4000\n",
      "2/2 - 0s - loss: 5.9517e-05 - accuracy: 1.0000 - val_loss: 3.5603 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2482/4000\n",
      "2/2 - 0s - loss: 5.9431e-05 - accuracy: 1.0000 - val_loss: 3.5607 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2483/4000\n",
      "2/2 - 0s - loss: 5.9359e-05 - accuracy: 1.0000 - val_loss: 3.5611 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2484/4000\n",
      "2/2 - 0s - loss: 5.9282e-05 - accuracy: 1.0000 - val_loss: 3.5615 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2485/4000\n",
      "2/2 - 0s - loss: 5.9191e-05 - accuracy: 1.0000 - val_loss: 3.5620 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2486/4000\n",
      "2/2 - 0s - loss: 5.9110e-05 - accuracy: 1.0000 - val_loss: 3.5625 - val_accuracy: 0.7250 - 77ms/epoch - 39ms/step\n",
      "Epoch 2487/4000\n",
      "2/2 - 0s - loss: 5.9031e-05 - accuracy: 1.0000 - val_loss: 3.5630 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2488/4000\n",
      "2/2 - 0s - loss: 5.8942e-05 - accuracy: 1.0000 - val_loss: 3.5633 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2489/4000\n",
      "2/2 - 0s - loss: 5.8872e-05 - accuracy: 1.0000 - val_loss: 3.5637 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2490/4000\n",
      "2/2 - 0s - loss: 5.8772e-05 - accuracy: 1.0000 - val_loss: 3.5640 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2491/4000\n",
      "2/2 - 0s - loss: 5.8714e-05 - accuracy: 1.0000 - val_loss: 3.5645 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2492/4000\n",
      "2/2 - 0s - loss: 5.8618e-05 - accuracy: 1.0000 - val_loss: 3.5649 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2493/4000\n",
      "2/2 - 0s - loss: 5.8546e-05 - accuracy: 1.0000 - val_loss: 3.5653 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2494/4000\n",
      "2/2 - 0s - loss: 5.8463e-05 - accuracy: 1.0000 - val_loss: 3.5656 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2495/4000\n",
      "2/2 - 0s - loss: 5.8401e-05 - accuracy: 1.0000 - val_loss: 3.5658 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 2496/4000\n",
      "2/2 - 0s - loss: 5.8305e-05 - accuracy: 1.0000 - val_loss: 3.5663 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2497/4000\n",
      "2/2 - 0s - loss: 5.8220e-05 - accuracy: 1.0000 - val_loss: 3.5667 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2498/4000\n",
      "2/2 - 0s - loss: 5.8156e-05 - accuracy: 1.0000 - val_loss: 3.5672 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2499/4000\n",
      "2/2 - 0s - loss: 5.8059e-05 - accuracy: 1.0000 - val_loss: 3.5675 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2500/4000\n",
      "2/2 - 0s - loss: 5.7976e-05 - accuracy: 1.0000 - val_loss: 3.5679 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2501/4000\n",
      "2/2 - 0s - loss: 5.7910e-05 - accuracy: 1.0000 - val_loss: 3.5683 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2502/4000\n",
      "2/2 - 0s - loss: 5.7822e-05 - accuracy: 1.0000 - val_loss: 3.5687 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2503/4000\n",
      "2/2 - 0s - loss: 5.7756e-05 - accuracy: 1.0000 - val_loss: 3.5692 - val_accuracy: 0.7250 - 79ms/epoch - 39ms/step\n",
      "Epoch 2504/4000\n",
      "2/2 - 0s - loss: 5.7661e-05 - accuracy: 1.0000 - val_loss: 3.5696 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2505/4000\n",
      "2/2 - 0s - loss: 5.7603e-05 - accuracy: 1.0000 - val_loss: 3.5700 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2506/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 5.7514e-05 - accuracy: 1.0000 - val_loss: 3.5704 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2507/4000\n",
      "2/2 - 0s - loss: 5.7443e-05 - accuracy: 1.0000 - val_loss: 3.5709 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 2508/4000\n",
      "2/2 - 0s - loss: 5.7350e-05 - accuracy: 1.0000 - val_loss: 3.5712 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2509/4000\n",
      "2/2 - 0s - loss: 5.7277e-05 - accuracy: 1.0000 - val_loss: 3.5715 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2510/4000\n",
      "2/2 - 0s - loss: 5.7188e-05 - accuracy: 1.0000 - val_loss: 3.5720 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2511/4000\n",
      "2/2 - 0s - loss: 5.7120e-05 - accuracy: 1.0000 - val_loss: 3.5724 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2512/4000\n",
      "2/2 - 0s - loss: 5.7035e-05 - accuracy: 1.0000 - val_loss: 3.5729 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2513/4000\n",
      "2/2 - 0s - loss: 5.6954e-05 - accuracy: 1.0000 - val_loss: 3.5734 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2514/4000\n",
      "2/2 - 0s - loss: 5.6871e-05 - accuracy: 1.0000 - val_loss: 3.5738 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2515/4000\n",
      "2/2 - 0s - loss: 5.6805e-05 - accuracy: 1.0000 - val_loss: 3.5743 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2516/4000\n",
      "2/2 - 0s - loss: 5.6724e-05 - accuracy: 1.0000 - val_loss: 3.5747 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2517/4000\n",
      "2/2 - 0s - loss: 5.6652e-05 - accuracy: 1.0000 - val_loss: 3.5751 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2518/4000\n",
      "2/2 - 0s - loss: 5.6577e-05 - accuracy: 1.0000 - val_loss: 3.5755 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2519/4000\n",
      "2/2 - 0s - loss: 5.6494e-05 - accuracy: 1.0000 - val_loss: 3.5760 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2520/4000\n",
      "2/2 - 0s - loss: 5.6424e-05 - accuracy: 1.0000 - val_loss: 3.5764 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2521/4000\n",
      "2/2 - 0s - loss: 5.6351e-05 - accuracy: 1.0000 - val_loss: 3.5768 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2522/4000\n",
      "2/2 - 0s - loss: 5.6264e-05 - accuracy: 1.0000 - val_loss: 3.5773 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 2523/4000\n",
      "2/2 - 0s - loss: 5.6183e-05 - accuracy: 1.0000 - val_loss: 3.5777 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2524/4000\n",
      "2/2 - 0s - loss: 5.6113e-05 - accuracy: 1.0000 - val_loss: 3.5782 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2525/4000\n",
      "2/2 - 0s - loss: 5.6024e-05 - accuracy: 1.0000 - val_loss: 3.5786 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2526/4000\n",
      "2/2 - 0s - loss: 5.5958e-05 - accuracy: 1.0000 - val_loss: 3.5790 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2527/4000\n",
      "2/2 - 0s - loss: 5.5879e-05 - accuracy: 1.0000 - val_loss: 3.5794 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2528/4000\n",
      "2/2 - 0s - loss: 5.5813e-05 - accuracy: 1.0000 - val_loss: 3.5799 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2529/4000\n",
      "2/2 - 0s - loss: 5.5721e-05 - accuracy: 1.0000 - val_loss: 3.5802 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2530/4000\n",
      "2/2 - 0s - loss: 5.5662e-05 - accuracy: 1.0000 - val_loss: 3.5806 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2531/4000\n",
      "2/2 - 0s - loss: 5.5572e-05 - accuracy: 1.0000 - val_loss: 3.5810 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2532/4000\n",
      "2/2 - 0s - loss: 5.5511e-05 - accuracy: 1.0000 - val_loss: 3.5815 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2533/4000\n",
      "2/2 - 0s - loss: 5.5426e-05 - accuracy: 1.0000 - val_loss: 3.5820 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2534/4000\n",
      "2/2 - 0s - loss: 5.5343e-05 - accuracy: 1.0000 - val_loss: 3.5824 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2535/4000\n",
      "2/2 - 0s - loss: 5.5281e-05 - accuracy: 1.0000 - val_loss: 3.5828 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2536/4000\n",
      "2/2 - 0s - loss: 5.5204e-05 - accuracy: 1.0000 - val_loss: 3.5832 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2537/4000\n",
      "2/2 - 0s - loss: 5.5121e-05 - accuracy: 1.0000 - val_loss: 3.5837 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2538/4000\n",
      "2/2 - 0s - loss: 5.5053e-05 - accuracy: 1.0000 - val_loss: 3.5841 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2539/4000\n",
      "2/2 - 0s - loss: 5.4981e-05 - accuracy: 1.0000 - val_loss: 3.5846 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2540/4000\n",
      "2/2 - 0s - loss: 5.4896e-05 - accuracy: 1.0000 - val_loss: 3.5850 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2541/4000\n",
      "2/2 - 0s - loss: 5.4821e-05 - accuracy: 1.0000 - val_loss: 3.5855 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2542/4000\n",
      "2/2 - 0s - loss: 5.4755e-05 - accuracy: 1.0000 - val_loss: 3.5860 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 2543/4000\n",
      "2/2 - 0s - loss: 5.4670e-05 - accuracy: 1.0000 - val_loss: 3.5863 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2544/4000\n",
      "2/2 - 0s - loss: 5.4585e-05 - accuracy: 1.0000 - val_loss: 3.5867 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2545/4000\n",
      "2/2 - 0s - loss: 5.4527e-05 - accuracy: 1.0000 - val_loss: 3.5872 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 2546/4000\n",
      "2/2 - 0s - loss: 5.4442e-05 - accuracy: 1.0000 - val_loss: 3.5877 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2547/4000\n",
      "2/2 - 0s - loss: 5.4374e-05 - accuracy: 1.0000 - val_loss: 3.5882 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2548/4000\n",
      "2/2 - 0s - loss: 5.4295e-05 - accuracy: 1.0000 - val_loss: 3.5887 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2549/4000\n",
      "2/2 - 0s - loss: 5.4227e-05 - accuracy: 1.0000 - val_loss: 3.5891 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2550/4000\n",
      "2/2 - 0s - loss: 5.4159e-05 - accuracy: 1.0000 - val_loss: 3.5894 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2551/4000\n",
      "2/2 - 0s - loss: 5.4091e-05 - accuracy: 1.0000 - val_loss: 3.5898 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2552/4000\n",
      "2/2 - 0s - loss: 5.4023e-05 - accuracy: 1.0000 - val_loss: 3.5903 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2553/4000\n",
      "2/2 - 0s - loss: 5.3953e-05 - accuracy: 1.0000 - val_loss: 3.5906 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2554/4000\n",
      "2/2 - 0s - loss: 5.3872e-05 - accuracy: 1.0000 - val_loss: 3.5910 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 2555/4000\n",
      "2/2 - 0s - loss: 5.3791e-05 - accuracy: 1.0000 - val_loss: 3.5914 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2556/4000\n",
      "2/2 - 0s - loss: 5.3710e-05 - accuracy: 1.0000 - val_loss: 3.5918 - val_accuracy: 0.7250 - 86ms/epoch - 43ms/step\n",
      "Epoch 2557/4000\n",
      "2/2 - 0s - loss: 5.3642e-05 - accuracy: 1.0000 - val_loss: 3.5923 - val_accuracy: 0.7250 - 89ms/epoch - 45ms/step\n",
      "Epoch 2558/4000\n",
      "2/2 - 0s - loss: 5.3569e-05 - accuracy: 1.0000 - val_loss: 3.5927 - val_accuracy: 0.7250 - 128ms/epoch - 64ms/step\n",
      "Epoch 2559/4000\n",
      "2/2 - 0s - loss: 5.3501e-05 - accuracy: 1.0000 - val_loss: 3.5930 - val_accuracy: 0.7250 - 87ms/epoch - 44ms/step\n",
      "Epoch 2560/4000\n",
      "2/2 - 0s - loss: 5.3418e-05 - accuracy: 1.0000 - val_loss: 3.5934 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2561/4000\n",
      "2/2 - 0s - loss: 5.3357e-05 - accuracy: 1.0000 - val_loss: 3.5938 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2562/4000\n",
      "2/2 - 0s - loss: 5.3280e-05 - accuracy: 1.0000 - val_loss: 3.5942 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2563/4000\n",
      "2/2 - 0s - loss: 5.3212e-05 - accuracy: 1.0000 - val_loss: 3.5947 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2564/4000\n",
      "2/2 - 0s - loss: 5.3150e-05 - accuracy: 1.0000 - val_loss: 3.5951 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2565/4000\n",
      "2/2 - 0s - loss: 5.3065e-05 - accuracy: 1.0000 - val_loss: 3.5954 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2566/4000\n",
      "2/2 - 0s - loss: 5.2997e-05 - accuracy: 1.0000 - val_loss: 3.5958 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2567/4000\n",
      "2/2 - 0s - loss: 5.2933e-05 - accuracy: 1.0000 - val_loss: 3.5962 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2568/4000\n",
      "2/2 - 0s - loss: 5.2852e-05 - accuracy: 1.0000 - val_loss: 3.5966 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2569/4000\n",
      "2/2 - 0s - loss: 5.2786e-05 - accuracy: 1.0000 - val_loss: 3.5971 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2570/4000\n",
      "2/2 - 0s - loss: 5.2701e-05 - accuracy: 1.0000 - val_loss: 3.5975 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2571/4000\n",
      "2/2 - 0s - loss: 5.2631e-05 - accuracy: 1.0000 - val_loss: 3.5978 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2572/4000\n",
      "2/2 - 0s - loss: 5.2569e-05 - accuracy: 1.0000 - val_loss: 3.5982 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 2573/4000\n",
      "2/2 - 0s - loss: 5.2497e-05 - accuracy: 1.0000 - val_loss: 3.5986 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2574/4000\n",
      "2/2 - 0s - loss: 5.2420e-05 - accuracy: 1.0000 - val_loss: 3.5990 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2575/4000\n",
      "2/2 - 0s - loss: 5.2352e-05 - accuracy: 1.0000 - val_loss: 3.5993 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2576/4000\n",
      "2/2 - 0s - loss: 5.2286e-05 - accuracy: 1.0000 - val_loss: 3.5997 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2577/4000\n",
      "2/2 - 0s - loss: 5.2199e-05 - accuracy: 1.0000 - val_loss: 3.6001 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2578/4000\n",
      "2/2 - 0s - loss: 5.2141e-05 - accuracy: 1.0000 - val_loss: 3.6005 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2579/4000\n",
      "2/2 - 0s - loss: 5.2073e-05 - accuracy: 1.0000 - val_loss: 3.6009 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2580/4000\n",
      "2/2 - 0s - loss: 5.2007e-05 - accuracy: 1.0000 - val_loss: 3.6014 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 2581/4000\n",
      "2/2 - 0s - loss: 5.1928e-05 - accuracy: 1.0000 - val_loss: 3.6018 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2582/4000\n",
      "2/2 - 0s - loss: 5.1862e-05 - accuracy: 1.0000 - val_loss: 3.6022 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2583/4000\n",
      "2/2 - 0s - loss: 5.1794e-05 - accuracy: 1.0000 - val_loss: 3.6026 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2584/4000\n",
      "2/2 - 0s - loss: 5.1711e-05 - accuracy: 1.0000 - val_loss: 3.6030 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2585/4000\n",
      "2/2 - 0s - loss: 5.1652e-05 - accuracy: 1.0000 - val_loss: 3.6034 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2586/4000\n",
      "2/2 - 0s - loss: 5.1575e-05 - accuracy: 1.0000 - val_loss: 3.6039 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2587/4000\n",
      "2/2 - 0s - loss: 5.1507e-05 - accuracy: 1.0000 - val_loss: 3.6043 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2588/4000\n",
      "2/2 - 0s - loss: 5.1435e-05 - accuracy: 1.0000 - val_loss: 3.6048 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2589/4000\n",
      "2/2 - 0s - loss: 5.1358e-05 - accuracy: 1.0000 - val_loss: 3.6052 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2590/4000\n",
      "2/2 - 0s - loss: 5.1283e-05 - accuracy: 1.0000 - val_loss: 3.6056 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2591/4000\n",
      "2/2 - 0s - loss: 5.1232e-05 - accuracy: 1.0000 - val_loss: 3.6060 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2592/4000\n",
      "2/2 - 0s - loss: 5.1173e-05 - accuracy: 1.0000 - val_loss: 3.6064 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2593/4000\n",
      "2/2 - 0s - loss: 5.1098e-05 - accuracy: 1.0000 - val_loss: 3.6069 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2594/4000\n",
      "2/2 - 0s - loss: 5.1019e-05 - accuracy: 1.0000 - val_loss: 3.6073 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2595/4000\n",
      "2/2 - 0s - loss: 5.0960e-05 - accuracy: 1.0000 - val_loss: 3.6077 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2596/4000\n",
      "2/2 - 0s - loss: 5.0887e-05 - accuracy: 1.0000 - val_loss: 3.6081 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2597/4000\n",
      "2/2 - 0s - loss: 5.0824e-05 - accuracy: 1.0000 - val_loss: 3.6085 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2598/4000\n",
      "2/2 - 0s - loss: 5.0751e-05 - accuracy: 1.0000 - val_loss: 3.6089 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2599/4000\n",
      "2/2 - 0s - loss: 5.0681e-05 - accuracy: 1.0000 - val_loss: 3.6093 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2600/4000\n",
      "2/2 - 0s - loss: 5.0617e-05 - accuracy: 1.0000 - val_loss: 3.6096 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2601/4000\n",
      "2/2 - 0s - loss: 5.0547e-05 - accuracy: 1.0000 - val_loss: 3.6099 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2602/4000\n",
      "2/2 - 0s - loss: 5.0483e-05 - accuracy: 1.0000 - val_loss: 3.6103 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2603/4000\n",
      "2/2 - 0s - loss: 5.0421e-05 - accuracy: 1.0000 - val_loss: 3.6107 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2604/4000\n",
      "2/2 - 0s - loss: 5.0353e-05 - accuracy: 1.0000 - val_loss: 3.6112 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2605/4000\n",
      "2/2 - 0s - loss: 5.0270e-05 - accuracy: 1.0000 - val_loss: 3.6117 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2606/4000\n",
      "2/2 - 0s - loss: 5.0206e-05 - accuracy: 1.0000 - val_loss: 3.6122 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2607/4000\n",
      "2/2 - 0s - loss: 5.0145e-05 - accuracy: 1.0000 - val_loss: 3.6127 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2608/4000\n",
      "2/2 - 0s - loss: 5.0083e-05 - accuracy: 1.0000 - val_loss: 3.6131 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2609/4000\n",
      "2/2 - 0s - loss: 5.0000e-05 - accuracy: 1.0000 - val_loss: 3.6136 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2610/4000\n",
      "2/2 - 0s - loss: 4.9945e-05 - accuracy: 1.0000 - val_loss: 3.6140 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2611/4000\n",
      "2/2 - 0s - loss: 4.9889e-05 - accuracy: 1.0000 - val_loss: 3.6145 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2612/4000\n",
      "2/2 - 0s - loss: 4.9821e-05 - accuracy: 1.0000 - val_loss: 3.6150 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2613/4000\n",
      "2/2 - 0s - loss: 4.9738e-05 - accuracy: 1.0000 - val_loss: 3.6154 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2614/4000\n",
      "2/2 - 0s - loss: 4.9668e-05 - accuracy: 1.0000 - val_loss: 3.6158 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2615/4000\n",
      "2/2 - 0s - loss: 4.9604e-05 - accuracy: 1.0000 - val_loss: 3.6163 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2616/4000\n",
      "2/2 - 0s - loss: 4.9549e-05 - accuracy: 1.0000 - val_loss: 3.6167 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2617/4000\n",
      "2/2 - 0s - loss: 4.9481e-05 - accuracy: 1.0000 - val_loss: 3.6171 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2618/4000\n",
      "2/2 - 0s - loss: 4.9417e-05 - accuracy: 1.0000 - val_loss: 3.6174 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2619/4000\n",
      "2/2 - 0s - loss: 4.9351e-05 - accuracy: 1.0000 - val_loss: 3.6179 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2620/4000\n",
      "2/2 - 0s - loss: 4.9283e-05 - accuracy: 1.0000 - val_loss: 3.6183 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2621/4000\n",
      "2/2 - 0s - loss: 4.9231e-05 - accuracy: 1.0000 - val_loss: 3.6187 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2622/4000\n",
      "2/2 - 0s - loss: 4.9144e-05 - accuracy: 1.0000 - val_loss: 3.6191 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2623/4000\n",
      "2/2 - 0s - loss: 4.9080e-05 - accuracy: 1.0000 - val_loss: 3.6195 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2624/4000\n",
      "2/2 - 0s - loss: 4.9006e-05 - accuracy: 1.0000 - val_loss: 3.6200 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2625/4000\n",
      "2/2 - 0s - loss: 4.8948e-05 - accuracy: 1.0000 - val_loss: 3.6203 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2626/4000\n",
      "2/2 - 0s - loss: 4.8878e-05 - accuracy: 1.0000 - val_loss: 3.6208 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2627/4000\n",
      "2/2 - 0s - loss: 4.8819e-05 - accuracy: 1.0000 - val_loss: 3.6211 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2628/4000\n",
      "2/2 - 0s - loss: 4.8748e-05 - accuracy: 1.0000 - val_loss: 3.6214 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2629/4000\n",
      "2/2 - 0s - loss: 4.8693e-05 - accuracy: 1.0000 - val_loss: 3.6218 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2630/4000\n",
      "2/2 - 0s - loss: 4.8627e-05 - accuracy: 1.0000 - val_loss: 3.6222 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2631/4000\n",
      "2/2 - 0s - loss: 4.8559e-05 - accuracy: 1.0000 - val_loss: 3.6226 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2632/4000\n",
      "2/2 - 0s - loss: 4.8495e-05 - accuracy: 1.0000 - val_loss: 3.6229 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2633/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 4.8435e-05 - accuracy: 1.0000 - val_loss: 3.6234 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2634/4000\n",
      "2/2 - 0s - loss: 4.8348e-05 - accuracy: 1.0000 - val_loss: 3.6237 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2635/4000\n",
      "2/2 - 0s - loss: 4.8291e-05 - accuracy: 1.0000 - val_loss: 3.6241 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2636/4000\n",
      "2/2 - 0s - loss: 4.8233e-05 - accuracy: 1.0000 - val_loss: 3.6244 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2637/4000\n",
      "2/2 - 0s - loss: 4.8165e-05 - accuracy: 1.0000 - val_loss: 3.6249 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2638/4000\n",
      "2/2 - 0s - loss: 4.8093e-05 - accuracy: 1.0000 - val_loss: 3.6253 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2639/4000\n",
      "2/2 - 0s - loss: 4.8039e-05 - accuracy: 1.0000 - val_loss: 3.6256 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2640/4000\n",
      "2/2 - 0s - loss: 4.7959e-05 - accuracy: 1.0000 - val_loss: 3.6260 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2641/4000\n",
      "2/2 - 0s - loss: 4.7912e-05 - accuracy: 1.0000 - val_loss: 3.6265 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2642/4000\n",
      "2/2 - 0s - loss: 4.7850e-05 - accuracy: 1.0000 - val_loss: 3.6269 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2643/4000\n",
      "2/2 - 0s - loss: 4.7782e-05 - accuracy: 1.0000 - val_loss: 3.6273 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2644/4000\n",
      "2/2 - 0s - loss: 4.7716e-05 - accuracy: 1.0000 - val_loss: 3.6279 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2645/4000\n",
      "2/2 - 0s - loss: 4.7661e-05 - accuracy: 1.0000 - val_loss: 3.6283 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2646/4000\n",
      "2/2 - 0s - loss: 4.7595e-05 - accuracy: 1.0000 - val_loss: 3.6287 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2647/4000\n",
      "2/2 - 0s - loss: 4.7518e-05 - accuracy: 1.0000 - val_loss: 3.6292 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2648/4000\n",
      "2/2 - 0s - loss: 4.7458e-05 - accuracy: 1.0000 - val_loss: 3.6297 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2649/4000\n",
      "2/2 - 0s - loss: 4.7390e-05 - accuracy: 1.0000 - val_loss: 3.6301 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2650/4000\n",
      "2/2 - 0s - loss: 4.7324e-05 - accuracy: 1.0000 - val_loss: 3.6305 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2651/4000\n",
      "2/2 - 0s - loss: 4.7256e-05 - accuracy: 1.0000 - val_loss: 3.6310 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2652/4000\n",
      "2/2 - 0s - loss: 4.7197e-05 - accuracy: 1.0000 - val_loss: 3.6314 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2653/4000\n",
      "2/2 - 0s - loss: 4.7131e-05 - accuracy: 1.0000 - val_loss: 3.6318 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2654/4000\n",
      "2/2 - 0s - loss: 4.7071e-05 - accuracy: 1.0000 - val_loss: 3.6322 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2655/4000\n",
      "2/2 - 0s - loss: 4.7014e-05 - accuracy: 1.0000 - val_loss: 3.6326 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2656/4000\n",
      "2/2 - 0s - loss: 4.6954e-05 - accuracy: 1.0000 - val_loss: 3.6330 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2657/4000\n",
      "2/2 - 0s - loss: 4.6890e-05 - accuracy: 1.0000 - val_loss: 3.6334 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2658/4000\n",
      "2/2 - 0s - loss: 4.6826e-05 - accuracy: 1.0000 - val_loss: 3.6338 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2659/4000\n",
      "2/2 - 0s - loss: 4.6764e-05 - accuracy: 1.0000 - val_loss: 3.6341 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2660/4000\n",
      "2/2 - 0s - loss: 4.6705e-05 - accuracy: 1.0000 - val_loss: 3.6346 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2661/4000\n",
      "2/2 - 0s - loss: 4.6643e-05 - accuracy: 1.0000 - val_loss: 3.6350 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2662/4000\n",
      "2/2 - 0s - loss: 4.6573e-05 - accuracy: 1.0000 - val_loss: 3.6355 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 2663/4000\n",
      "2/2 - 0s - loss: 4.6515e-05 - accuracy: 1.0000 - val_loss: 3.6359 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2664/4000\n",
      "2/2 - 0s - loss: 4.6452e-05 - accuracy: 1.0000 - val_loss: 3.6364 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2665/4000\n",
      "2/2 - 0s - loss: 4.6396e-05 - accuracy: 1.0000 - val_loss: 3.6368 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2666/4000\n",
      "2/2 - 0s - loss: 4.6337e-05 - accuracy: 1.0000 - val_loss: 3.6373 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2667/4000\n",
      "2/2 - 0s - loss: 4.6264e-05 - accuracy: 1.0000 - val_loss: 3.6377 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2668/4000\n",
      "2/2 - 0s - loss: 4.6194e-05 - accuracy: 1.0000 - val_loss: 3.6381 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2669/4000\n",
      "2/2 - 0s - loss: 4.6147e-05 - accuracy: 1.0000 - val_loss: 3.6384 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2670/4000\n",
      "2/2 - 0s - loss: 4.6088e-05 - accuracy: 1.0000 - val_loss: 3.6388 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2671/4000\n",
      "2/2 - 0s - loss: 4.6030e-05 - accuracy: 1.0000 - val_loss: 3.6393 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2672/4000\n",
      "2/2 - 0s - loss: 4.5956e-05 - accuracy: 1.0000 - val_loss: 3.6397 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2673/4000\n",
      "2/2 - 0s - loss: 4.5896e-05 - accuracy: 1.0000 - val_loss: 3.6401 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2674/4000\n",
      "2/2 - 0s - loss: 4.5845e-05 - accuracy: 1.0000 - val_loss: 3.6405 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 2675/4000\n",
      "2/2 - 0s - loss: 4.5787e-05 - accuracy: 1.0000 - val_loss: 3.6409 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2676/4000\n",
      "2/2 - 0s - loss: 4.5726e-05 - accuracy: 1.0000 - val_loss: 3.6413 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2677/4000\n",
      "2/2 - 0s - loss: 4.5666e-05 - accuracy: 1.0000 - val_loss: 3.6417 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2678/4000\n",
      "2/2 - 0s - loss: 4.5607e-05 - accuracy: 1.0000 - val_loss: 3.6421 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 2679/4000\n",
      "2/2 - 0s - loss: 4.5547e-05 - accuracy: 1.0000 - val_loss: 3.6424 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2680/4000\n",
      "2/2 - 0s - loss: 4.5489e-05 - accuracy: 1.0000 - val_loss: 3.6428 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2681/4000\n",
      "2/2 - 0s - loss: 4.5413e-05 - accuracy: 1.0000 - val_loss: 3.6433 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2682/4000\n",
      "2/2 - 0s - loss: 4.5362e-05 - accuracy: 1.0000 - val_loss: 3.6436 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2683/4000\n",
      "2/2 - 0s - loss: 4.5300e-05 - accuracy: 1.0000 - val_loss: 3.6441 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2684/4000\n",
      "2/2 - 0s - loss: 4.5240e-05 - accuracy: 1.0000 - val_loss: 3.6445 - val_accuracy: 0.7250 - 79ms/epoch - 39ms/step\n",
      "Epoch 2685/4000\n",
      "2/2 - 0s - loss: 4.5177e-05 - accuracy: 1.0000 - val_loss: 3.6450 - val_accuracy: 0.7250 - 77ms/epoch - 39ms/step\n",
      "Epoch 2686/4000\n",
      "2/2 - 0s - loss: 4.5128e-05 - accuracy: 1.0000 - val_loss: 3.6454 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2687/4000\n",
      "2/2 - 0s - loss: 4.5068e-05 - accuracy: 1.0000 - val_loss: 3.6457 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2688/4000\n",
      "2/2 - 0s - loss: 4.5002e-05 - accuracy: 1.0000 - val_loss: 3.6461 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2689/4000\n",
      "2/2 - 0s - loss: 4.4942e-05 - accuracy: 1.0000 - val_loss: 3.6465 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2690/4000\n",
      "2/2 - 0s - loss: 4.4885e-05 - accuracy: 1.0000 - val_loss: 3.6469 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2691/4000\n",
      "2/2 - 0s - loss: 4.4825e-05 - accuracy: 1.0000 - val_loss: 3.6473 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2692/4000\n",
      "2/2 - 0s - loss: 4.4761e-05 - accuracy: 1.0000 - val_loss: 3.6476 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2693/4000\n",
      "2/2 - 0s - loss: 4.4702e-05 - accuracy: 1.0000 - val_loss: 3.6480 - val_accuracy: 0.7250 - 86ms/epoch - 43ms/step\n",
      "Epoch 2694/4000\n",
      "2/2 - 0s - loss: 4.4644e-05 - accuracy: 1.0000 - val_loss: 3.6485 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 2695/4000\n",
      "2/2 - 0s - loss: 4.4593e-05 - accuracy: 1.0000 - val_loss: 3.6489 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2696/4000\n",
      "2/2 - 0s - loss: 4.4544e-05 - accuracy: 1.0000 - val_loss: 3.6494 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2697/4000\n",
      "2/2 - 0s - loss: 4.4478e-05 - accuracy: 1.0000 - val_loss: 3.6497 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2698/4000\n",
      "2/2 - 0s - loss: 4.4417e-05 - accuracy: 1.0000 - val_loss: 3.6502 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2699/4000\n",
      "2/2 - 0s - loss: 4.4340e-05 - accuracy: 1.0000 - val_loss: 3.6507 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2700/4000\n",
      "2/2 - 0s - loss: 4.4287e-05 - accuracy: 1.0000 - val_loss: 3.6511 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2701/4000\n",
      "2/2 - 0s - loss: 4.4240e-05 - accuracy: 1.0000 - val_loss: 3.6515 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 2702/4000\n",
      "2/2 - 0s - loss: 4.4168e-05 - accuracy: 1.0000 - val_loss: 3.6519 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 2703/4000\n",
      "2/2 - 0s - loss: 4.4121e-05 - accuracy: 1.0000 - val_loss: 3.6522 - val_accuracy: 0.7250 - 89ms/epoch - 45ms/step\n",
      "Epoch 2704/4000\n",
      "2/2 - 0s - loss: 4.4057e-05 - accuracy: 1.0000 - val_loss: 3.6527 - val_accuracy: 0.7250 - 107ms/epoch - 53ms/step\n",
      "Epoch 2705/4000\n",
      "2/2 - 0s - loss: 4.4008e-05 - accuracy: 1.0000 - val_loss: 3.6531 - val_accuracy: 0.7250 - 94ms/epoch - 47ms/step\n",
      "Epoch 2706/4000\n",
      "2/2 - 0s - loss: 4.3940e-05 - accuracy: 1.0000 - val_loss: 3.6535 - val_accuracy: 0.7250 - 95ms/epoch - 48ms/step\n",
      "Epoch 2707/4000\n",
      "2/2 - 0s - loss: 4.3884e-05 - accuracy: 1.0000 - val_loss: 3.6539 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2708/4000\n",
      "2/2 - 0s - loss: 4.3829e-05 - accuracy: 1.0000 - val_loss: 3.6543 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2709/4000\n",
      "2/2 - 0s - loss: 4.3776e-05 - accuracy: 1.0000 - val_loss: 3.6548 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2710/4000\n",
      "2/2 - 0s - loss: 4.3725e-05 - accuracy: 1.0000 - val_loss: 3.6552 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2711/4000\n",
      "2/2 - 0s - loss: 4.3661e-05 - accuracy: 1.0000 - val_loss: 3.6557 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2712/4000\n",
      "2/2 - 0s - loss: 4.3599e-05 - accuracy: 1.0000 - val_loss: 3.6560 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2713/4000\n",
      "2/2 - 0s - loss: 4.3548e-05 - accuracy: 1.0000 - val_loss: 3.6564 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2714/4000\n",
      "2/2 - 0s - loss: 4.3497e-05 - accuracy: 1.0000 - val_loss: 3.6568 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2715/4000\n",
      "2/2 - 0s - loss: 4.3433e-05 - accuracy: 1.0000 - val_loss: 3.6572 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2716/4000\n",
      "2/2 - 0s - loss: 4.3363e-05 - accuracy: 1.0000 - val_loss: 3.6577 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2717/4000\n",
      "2/2 - 0s - loss: 4.3318e-05 - accuracy: 1.0000 - val_loss: 3.6581 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2718/4000\n",
      "2/2 - 0s - loss: 4.3263e-05 - accuracy: 1.0000 - val_loss: 3.6585 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2719/4000\n",
      "2/2 - 0s - loss: 4.3203e-05 - accuracy: 1.0000 - val_loss: 3.6589 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2720/4000\n",
      "2/2 - 0s - loss: 4.3142e-05 - accuracy: 1.0000 - val_loss: 3.6593 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2721/4000\n",
      "2/2 - 0s - loss: 4.3086e-05 - accuracy: 1.0000 - val_loss: 3.6598 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2722/4000\n",
      "2/2 - 0s - loss: 4.3022e-05 - accuracy: 1.0000 - val_loss: 3.6602 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2723/4000\n",
      "2/2 - 0s - loss: 4.2973e-05 - accuracy: 1.0000 - val_loss: 3.6606 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2724/4000\n",
      "2/2 - 0s - loss: 4.2920e-05 - accuracy: 1.0000 - val_loss: 3.6610 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2725/4000\n",
      "2/2 - 0s - loss: 4.2867e-05 - accuracy: 1.0000 - val_loss: 3.6613 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2726/4000\n",
      "2/2 - 0s - loss: 4.2814e-05 - accuracy: 1.0000 - val_loss: 3.6618 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2727/4000\n",
      "2/2 - 0s - loss: 4.2744e-05 - accuracy: 1.0000 - val_loss: 3.6621 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2728/4000\n",
      "2/2 - 0s - loss: 4.2699e-05 - accuracy: 1.0000 - val_loss: 3.6626 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2729/4000\n",
      "2/2 - 0s - loss: 4.2641e-05 - accuracy: 1.0000 - val_loss: 3.6630 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2730/4000\n",
      "2/2 - 0s - loss: 4.2575e-05 - accuracy: 1.0000 - val_loss: 3.6634 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2731/4000\n",
      "2/2 - 0s - loss: 4.2520e-05 - accuracy: 1.0000 - val_loss: 3.6638 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2732/4000\n",
      "2/2 - 0s - loss: 4.2471e-05 - accuracy: 1.0000 - val_loss: 3.6643 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2733/4000\n",
      "2/2 - 0s - loss: 4.2416e-05 - accuracy: 1.0000 - val_loss: 3.6647 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2734/4000\n",
      "2/2 - 0s - loss: 4.2363e-05 - accuracy: 1.0000 - val_loss: 3.6652 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2735/4000\n",
      "2/2 - 0s - loss: 4.2297e-05 - accuracy: 1.0000 - val_loss: 3.6657 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2736/4000\n",
      "2/2 - 0s - loss: 4.2254e-05 - accuracy: 1.0000 - val_loss: 3.6661 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2737/4000\n",
      "2/2 - 0s - loss: 4.2194e-05 - accuracy: 1.0000 - val_loss: 3.6665 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2738/4000\n",
      "2/2 - 0s - loss: 4.2141e-05 - accuracy: 1.0000 - val_loss: 3.6669 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2739/4000\n",
      "2/2 - 0s - loss: 4.2071e-05 - accuracy: 1.0000 - val_loss: 3.6673 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2740/4000\n",
      "2/2 - 0s - loss: 4.2024e-05 - accuracy: 1.0000 - val_loss: 3.6677 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2741/4000\n",
      "2/2 - 0s - loss: 4.1967e-05 - accuracy: 1.0000 - val_loss: 3.6682 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2742/4000\n",
      "2/2 - 0s - loss: 4.1913e-05 - accuracy: 1.0000 - val_loss: 3.6686 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2743/4000\n",
      "2/2 - 0s - loss: 4.1852e-05 - accuracy: 1.0000 - val_loss: 3.6690 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2744/4000\n",
      "2/2 - 0s - loss: 4.1798e-05 - accuracy: 1.0000 - val_loss: 3.6694 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2745/4000\n",
      "2/2 - 0s - loss: 4.1745e-05 - accuracy: 1.0000 - val_loss: 3.6698 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2746/4000\n",
      "2/2 - 0s - loss: 4.1694e-05 - accuracy: 1.0000 - val_loss: 3.6702 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2747/4000\n",
      "2/2 - 0s - loss: 4.1645e-05 - accuracy: 1.0000 - val_loss: 3.6705 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2748/4000\n",
      "2/2 - 0s - loss: 4.1581e-05 - accuracy: 1.0000 - val_loss: 3.6709 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2749/4000\n",
      "2/2 - 0s - loss: 4.1509e-05 - accuracy: 1.0000 - val_loss: 3.6713 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2750/4000\n",
      "2/2 - 0s - loss: 4.1466e-05 - accuracy: 1.0000 - val_loss: 3.6717 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2751/4000\n",
      "2/2 - 0s - loss: 4.1413e-05 - accuracy: 1.0000 - val_loss: 3.6720 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2752/4000\n",
      "2/2 - 0s - loss: 4.1354e-05 - accuracy: 1.0000 - val_loss: 3.6724 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2753/4000\n",
      "2/2 - 0s - loss: 4.1307e-05 - accuracy: 1.0000 - val_loss: 3.6727 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2754/4000\n",
      "2/2 - 0s - loss: 4.1241e-05 - accuracy: 1.0000 - val_loss: 3.6731 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2755/4000\n",
      "2/2 - 0s - loss: 4.1202e-05 - accuracy: 1.0000 - val_loss: 3.6735 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2756/4000\n",
      "2/2 - 0s - loss: 4.1151e-05 - accuracy: 1.0000 - val_loss: 3.6739 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2757/4000\n",
      "2/2 - 0s - loss: 4.1094e-05 - accuracy: 1.0000 - val_loss: 3.6743 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2758/4000\n",
      "2/2 - 0s - loss: 4.1041e-05 - accuracy: 1.0000 - val_loss: 3.6747 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2759/4000\n",
      "2/2 - 0s - loss: 4.0983e-05 - accuracy: 1.0000 - val_loss: 3.6750 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2760/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 4.0926e-05 - accuracy: 1.0000 - val_loss: 3.6753 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2761/4000\n",
      "2/2 - 0s - loss: 4.0879e-05 - accuracy: 1.0000 - val_loss: 3.6758 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2762/4000\n",
      "2/2 - 0s - loss: 4.0828e-05 - accuracy: 1.0000 - val_loss: 3.6762 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2763/4000\n",
      "2/2 - 0s - loss: 4.0758e-05 - accuracy: 1.0000 - val_loss: 3.6766 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2764/4000\n",
      "2/2 - 0s - loss: 4.0724e-05 - accuracy: 1.0000 - val_loss: 3.6770 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2765/4000\n",
      "2/2 - 0s - loss: 4.0672e-05 - accuracy: 1.0000 - val_loss: 3.6774 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2766/4000\n",
      "2/2 - 0s - loss: 4.0615e-05 - accuracy: 1.0000 - val_loss: 3.6777 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2767/4000\n",
      "2/2 - 0s - loss: 4.0558e-05 - accuracy: 1.0000 - val_loss: 3.6781 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 2768/4000\n",
      "2/2 - 0s - loss: 4.0515e-05 - accuracy: 1.0000 - val_loss: 3.6784 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 2769/4000\n",
      "2/2 - 0s - loss: 4.0462e-05 - accuracy: 1.0000 - val_loss: 3.6788 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2770/4000\n",
      "2/2 - 0s - loss: 4.0402e-05 - accuracy: 1.0000 - val_loss: 3.6791 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2771/4000\n",
      "2/2 - 0s - loss: 4.0345e-05 - accuracy: 1.0000 - val_loss: 3.6796 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2772/4000\n",
      "2/2 - 0s - loss: 4.0291e-05 - accuracy: 1.0000 - val_loss: 3.6800 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2773/4000\n",
      "2/2 - 0s - loss: 4.0245e-05 - accuracy: 1.0000 - val_loss: 3.6804 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2774/4000\n",
      "2/2 - 0s - loss: 4.0189e-05 - accuracy: 1.0000 - val_loss: 3.6807 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2775/4000\n",
      "2/2 - 0s - loss: 4.0147e-05 - accuracy: 1.0000 - val_loss: 3.6811 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2776/4000\n",
      "2/2 - 0s - loss: 4.0076e-05 - accuracy: 1.0000 - val_loss: 3.6814 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2777/4000\n",
      "2/2 - 0s - loss: 4.0025e-05 - accuracy: 1.0000 - val_loss: 3.6819 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2778/4000\n",
      "2/2 - 0s - loss: 3.9964e-05 - accuracy: 1.0000 - val_loss: 3.6823 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2779/4000\n",
      "2/2 - 0s - loss: 3.9908e-05 - accuracy: 1.0000 - val_loss: 3.6827 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2780/4000\n",
      "2/2 - 0s - loss: 3.9853e-05 - accuracy: 1.0000 - val_loss: 3.6832 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2781/4000\n",
      "2/2 - 0s - loss: 3.9810e-05 - accuracy: 1.0000 - val_loss: 3.6836 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 2782/4000\n",
      "2/2 - 0s - loss: 3.9768e-05 - accuracy: 1.0000 - val_loss: 3.6841 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2783/4000\n",
      "2/2 - 0s - loss: 3.9710e-05 - accuracy: 1.0000 - val_loss: 3.6845 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2784/4000\n",
      "2/2 - 0s - loss: 3.9661e-05 - accuracy: 1.0000 - val_loss: 3.6849 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2785/4000\n",
      "2/2 - 0s - loss: 3.9612e-05 - accuracy: 1.0000 - val_loss: 3.6854 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 2786/4000\n",
      "2/2 - 0s - loss: 3.9555e-05 - accuracy: 1.0000 - val_loss: 3.6858 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2787/4000\n",
      "2/2 - 0s - loss: 3.9514e-05 - accuracy: 1.0000 - val_loss: 3.6862 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2788/4000\n",
      "2/2 - 0s - loss: 3.9444e-05 - accuracy: 1.0000 - val_loss: 3.6866 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 2789/4000\n",
      "2/2 - 0s - loss: 3.9400e-05 - accuracy: 1.0000 - val_loss: 3.6871 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2790/4000\n",
      "2/2 - 0s - loss: 3.9357e-05 - accuracy: 1.0000 - val_loss: 3.6875 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2791/4000\n",
      "2/2 - 0s - loss: 3.9312e-05 - accuracy: 1.0000 - val_loss: 3.6879 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2792/4000\n",
      "2/2 - 0s - loss: 3.9257e-05 - accuracy: 1.0000 - val_loss: 3.6882 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2793/4000\n",
      "2/2 - 0s - loss: 3.9214e-05 - accuracy: 1.0000 - val_loss: 3.6886 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2794/4000\n",
      "2/2 - 0s - loss: 3.9159e-05 - accuracy: 1.0000 - val_loss: 3.6890 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2795/4000\n",
      "2/2 - 0s - loss: 3.9097e-05 - accuracy: 1.0000 - val_loss: 3.6894 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2796/4000\n",
      "2/2 - 0s - loss: 3.9048e-05 - accuracy: 1.0000 - val_loss: 3.6898 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2797/4000\n",
      "2/2 - 0s - loss: 3.8999e-05 - accuracy: 1.0000 - val_loss: 3.6902 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2798/4000\n",
      "2/2 - 0s - loss: 3.8942e-05 - accuracy: 1.0000 - val_loss: 3.6907 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2799/4000\n",
      "2/2 - 0s - loss: 3.8899e-05 - accuracy: 1.0000 - val_loss: 3.6910 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2800/4000\n",
      "2/2 - 0s - loss: 3.8857e-05 - accuracy: 1.0000 - val_loss: 3.6915 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2801/4000\n",
      "2/2 - 0s - loss: 3.8795e-05 - accuracy: 1.0000 - val_loss: 3.6919 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 2802/4000\n",
      "2/2 - 0s - loss: 3.8744e-05 - accuracy: 1.0000 - val_loss: 3.6923 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2803/4000\n",
      "2/2 - 0s - loss: 3.8691e-05 - accuracy: 1.0000 - val_loss: 3.6926 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2804/4000\n",
      "2/2 - 0s - loss: 3.8646e-05 - accuracy: 1.0000 - val_loss: 3.6930 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2805/4000\n",
      "2/2 - 0s - loss: 3.8599e-05 - accuracy: 1.0000 - val_loss: 3.6934 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2806/4000\n",
      "2/2 - 0s - loss: 3.8537e-05 - accuracy: 1.0000 - val_loss: 3.6938 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2807/4000\n",
      "2/2 - 0s - loss: 3.8501e-05 - accuracy: 1.0000 - val_loss: 3.6941 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2808/4000\n",
      "2/2 - 0s - loss: 3.8437e-05 - accuracy: 1.0000 - val_loss: 3.6944 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2809/4000\n",
      "2/2 - 0s - loss: 3.8393e-05 - accuracy: 1.0000 - val_loss: 3.6948 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2810/4000\n",
      "2/2 - 0s - loss: 3.8335e-05 - accuracy: 1.0000 - val_loss: 3.6952 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2811/4000\n",
      "2/2 - 0s - loss: 3.8295e-05 - accuracy: 1.0000 - val_loss: 3.6956 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2812/4000\n",
      "2/2 - 0s - loss: 3.8242e-05 - accuracy: 1.0000 - val_loss: 3.6960 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2813/4000\n",
      "2/2 - 0s - loss: 3.8195e-05 - accuracy: 1.0000 - val_loss: 3.6964 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2814/4000\n",
      "2/2 - 0s - loss: 3.8146e-05 - accuracy: 1.0000 - val_loss: 3.6968 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2815/4000\n",
      "2/2 - 0s - loss: 3.8103e-05 - accuracy: 1.0000 - val_loss: 3.6972 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2816/4000\n",
      "2/2 - 0s - loss: 3.8037e-05 - accuracy: 1.0000 - val_loss: 3.6976 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2817/4000\n",
      "2/2 - 0s - loss: 3.7997e-05 - accuracy: 1.0000 - val_loss: 3.6979 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2818/4000\n",
      "2/2 - 0s - loss: 3.7954e-05 - accuracy: 1.0000 - val_loss: 3.6983 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2819/4000\n",
      "2/2 - 0s - loss: 3.7895e-05 - accuracy: 1.0000 - val_loss: 3.6987 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2820/4000\n",
      "2/2 - 0s - loss: 3.7852e-05 - accuracy: 1.0000 - val_loss: 3.6991 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2821/4000\n",
      "2/2 - 0s - loss: 3.7801e-05 - accuracy: 1.0000 - val_loss: 3.6995 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2822/4000\n",
      "2/2 - 0s - loss: 3.7752e-05 - accuracy: 1.0000 - val_loss: 3.6999 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2823/4000\n",
      "2/2 - 0s - loss: 3.7697e-05 - accuracy: 1.0000 - val_loss: 3.7003 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2824/4000\n",
      "2/2 - 0s - loss: 3.7652e-05 - accuracy: 1.0000 - val_loss: 3.7008 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2825/4000\n",
      "2/2 - 0s - loss: 3.7597e-05 - accuracy: 1.0000 - val_loss: 3.7012 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2826/4000\n",
      "2/2 - 0s - loss: 3.7554e-05 - accuracy: 1.0000 - val_loss: 3.7017 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 2827/4000\n",
      "2/2 - 0s - loss: 3.7503e-05 - accuracy: 1.0000 - val_loss: 3.7020 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2828/4000\n",
      "2/2 - 0s - loss: 3.7456e-05 - accuracy: 1.0000 - val_loss: 3.7025 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 2829/4000\n",
      "2/2 - 0s - loss: 3.7414e-05 - accuracy: 1.0000 - val_loss: 3.7028 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2830/4000\n",
      "2/2 - 0s - loss: 3.7360e-05 - accuracy: 1.0000 - val_loss: 3.7032 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2831/4000\n",
      "2/2 - 0s - loss: 3.7309e-05 - accuracy: 1.0000 - val_loss: 3.7036 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2832/4000\n",
      "2/2 - 0s - loss: 3.7256e-05 - accuracy: 1.0000 - val_loss: 3.7041 - val_accuracy: 0.7250 - 45ms/epoch - 23ms/step\n",
      "Epoch 2833/4000\n",
      "2/2 - 0s - loss: 3.7209e-05 - accuracy: 1.0000 - val_loss: 3.7045 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2834/4000\n",
      "2/2 - 0s - loss: 3.7167e-05 - accuracy: 1.0000 - val_loss: 3.7049 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2835/4000\n",
      "2/2 - 0s - loss: 3.7116e-05 - accuracy: 1.0000 - val_loss: 3.7053 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2836/4000\n",
      "2/2 - 0s - loss: 3.7064e-05 - accuracy: 1.0000 - val_loss: 3.7057 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2837/4000\n",
      "2/2 - 0s - loss: 3.7033e-05 - accuracy: 1.0000 - val_loss: 3.7061 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2838/4000\n",
      "2/2 - 0s - loss: 3.6979e-05 - accuracy: 1.0000 - val_loss: 3.7065 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2839/4000\n",
      "2/2 - 0s - loss: 3.6924e-05 - accuracy: 1.0000 - val_loss: 3.7070 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2840/4000\n",
      "2/2 - 0s - loss: 3.6877e-05 - accuracy: 1.0000 - val_loss: 3.7074 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2841/4000\n",
      "2/2 - 0s - loss: 3.6818e-05 - accuracy: 1.0000 - val_loss: 3.7078 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2842/4000\n",
      "2/2 - 0s - loss: 3.6771e-05 - accuracy: 1.0000 - val_loss: 3.7082 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2843/4000\n",
      "2/2 - 0s - loss: 3.6730e-05 - accuracy: 1.0000 - val_loss: 3.7086 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2844/4000\n",
      "2/2 - 0s - loss: 3.6694e-05 - accuracy: 1.0000 - val_loss: 3.7091 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2845/4000\n",
      "2/2 - 0s - loss: 3.6624e-05 - accuracy: 1.0000 - val_loss: 3.7095 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2846/4000\n",
      "2/2 - 0s - loss: 3.6588e-05 - accuracy: 1.0000 - val_loss: 3.7099 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2847/4000\n",
      "2/2 - 0s - loss: 3.6532e-05 - accuracy: 1.0000 - val_loss: 3.7103 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2848/4000\n",
      "2/2 - 0s - loss: 3.6475e-05 - accuracy: 1.0000 - val_loss: 3.7107 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2849/4000\n",
      "2/2 - 0s - loss: 3.6434e-05 - accuracy: 1.0000 - val_loss: 3.7111 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2850/4000\n",
      "2/2 - 0s - loss: 3.6390e-05 - accuracy: 1.0000 - val_loss: 3.7115 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2851/4000\n",
      "2/2 - 0s - loss: 3.6354e-05 - accuracy: 1.0000 - val_loss: 3.7118 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2852/4000\n",
      "2/2 - 0s - loss: 3.6309e-05 - accuracy: 1.0000 - val_loss: 3.7122 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2853/4000\n",
      "2/2 - 0s - loss: 3.6258e-05 - accuracy: 1.0000 - val_loss: 3.7126 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2854/4000\n",
      "2/2 - 0s - loss: 3.6207e-05 - accuracy: 1.0000 - val_loss: 3.7131 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 2855/4000\n",
      "2/2 - 0s - loss: 3.6162e-05 - accuracy: 1.0000 - val_loss: 3.7135 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 2856/4000\n",
      "2/2 - 0s - loss: 3.6111e-05 - accuracy: 1.0000 - val_loss: 3.7138 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2857/4000\n",
      "2/2 - 0s - loss: 3.6073e-05 - accuracy: 1.0000 - val_loss: 3.7143 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2858/4000\n",
      "2/2 - 0s - loss: 3.6019e-05 - accuracy: 1.0000 - val_loss: 3.7146 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2859/4000\n",
      "2/2 - 0s - loss: 3.5968e-05 - accuracy: 1.0000 - val_loss: 3.7149 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 2860/4000\n",
      "2/2 - 0s - loss: 3.5921e-05 - accuracy: 1.0000 - val_loss: 3.7152 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 2861/4000\n",
      "2/2 - 0s - loss: 3.5877e-05 - accuracy: 1.0000 - val_loss: 3.7156 - val_accuracy: 0.7250 - 84ms/epoch - 42ms/step\n",
      "Epoch 2862/4000\n",
      "2/2 - 0s - loss: 3.5836e-05 - accuracy: 1.0000 - val_loss: 3.7161 - val_accuracy: 0.7250 - 91ms/epoch - 45ms/step\n",
      "Epoch 2863/4000\n",
      "2/2 - 0s - loss: 3.5794e-05 - accuracy: 1.0000 - val_loss: 3.7165 - val_accuracy: 0.7250 - 113ms/epoch - 56ms/step\n",
      "Epoch 2864/4000\n",
      "2/2 - 0s - loss: 3.5732e-05 - accuracy: 1.0000 - val_loss: 3.7169 - val_accuracy: 0.7250 - 100ms/epoch - 50ms/step\n",
      "Epoch 2865/4000\n",
      "2/2 - 0s - loss: 3.5692e-05 - accuracy: 1.0000 - val_loss: 3.7172 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2866/4000\n",
      "2/2 - 0s - loss: 3.5651e-05 - accuracy: 1.0000 - val_loss: 3.7176 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2867/4000\n",
      "2/2 - 0s - loss: 3.5608e-05 - accuracy: 1.0000 - val_loss: 3.7180 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2868/4000\n",
      "2/2 - 0s - loss: 3.5551e-05 - accuracy: 1.0000 - val_loss: 3.7184 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2869/4000\n",
      "2/2 - 0s - loss: 3.5502e-05 - accuracy: 1.0000 - val_loss: 3.7187 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 2870/4000\n",
      "2/2 - 0s - loss: 3.5457e-05 - accuracy: 1.0000 - val_loss: 3.7192 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2871/4000\n",
      "2/2 - 0s - loss: 3.5413e-05 - accuracy: 1.0000 - val_loss: 3.7196 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2872/4000\n",
      "2/2 - 0s - loss: 3.5357e-05 - accuracy: 1.0000 - val_loss: 3.7200 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2873/4000\n",
      "2/2 - 0s - loss: 3.5319e-05 - accuracy: 1.0000 - val_loss: 3.7204 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2874/4000\n",
      "2/2 - 0s - loss: 3.5270e-05 - accuracy: 1.0000 - val_loss: 3.7206 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2875/4000\n",
      "2/2 - 0s - loss: 3.5225e-05 - accuracy: 1.0000 - val_loss: 3.7210 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2876/4000\n",
      "2/2 - 0s - loss: 3.5181e-05 - accuracy: 1.0000 - val_loss: 3.7213 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2877/4000\n",
      "2/2 - 0s - loss: 3.5132e-05 - accuracy: 1.0000 - val_loss: 3.7218 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2878/4000\n",
      "2/2 - 0s - loss: 3.5089e-05 - accuracy: 1.0000 - val_loss: 3.7222 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2879/4000\n",
      "2/2 - 0s - loss: 3.5047e-05 - accuracy: 1.0000 - val_loss: 3.7227 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2880/4000\n",
      "2/2 - 0s - loss: 3.5002e-05 - accuracy: 1.0000 - val_loss: 3.7231 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2881/4000\n",
      "2/2 - 0s - loss: 3.4966e-05 - accuracy: 1.0000 - val_loss: 3.7234 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2882/4000\n",
      "2/2 - 0s - loss: 3.4910e-05 - accuracy: 1.0000 - val_loss: 3.7238 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2883/4000\n",
      "2/2 - 0s - loss: 3.4863e-05 - accuracy: 1.0000 - val_loss: 3.7242 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2884/4000\n",
      "2/2 - 0s - loss: 3.4829e-05 - accuracy: 1.0000 - val_loss: 3.7247 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2885/4000\n",
      "2/2 - 0s - loss: 3.4780e-05 - accuracy: 1.0000 - val_loss: 3.7251 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2886/4000\n",
      "2/2 - 0s - loss: 3.4725e-05 - accuracy: 1.0000 - val_loss: 3.7256 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2887/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 3.4687e-05 - accuracy: 1.0000 - val_loss: 3.7260 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2888/4000\n",
      "2/2 - 0s - loss: 3.4646e-05 - accuracy: 1.0000 - val_loss: 3.7263 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2889/4000\n",
      "2/2 - 0s - loss: 3.4589e-05 - accuracy: 1.0000 - val_loss: 3.7267 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 2890/4000\n",
      "2/2 - 0s - loss: 3.4555e-05 - accuracy: 1.0000 - val_loss: 3.7270 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2891/4000\n",
      "2/2 - 0s - loss: 3.4510e-05 - accuracy: 1.0000 - val_loss: 3.7274 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2892/4000\n",
      "2/2 - 0s - loss: 3.4470e-05 - accuracy: 1.0000 - val_loss: 3.7278 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 2893/4000\n",
      "2/2 - 0s - loss: 3.4419e-05 - accuracy: 1.0000 - val_loss: 3.7282 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2894/4000\n",
      "2/2 - 0s - loss: 3.4380e-05 - accuracy: 1.0000 - val_loss: 3.7285 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2895/4000\n",
      "2/2 - 0s - loss: 3.4336e-05 - accuracy: 1.0000 - val_loss: 3.7289 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2896/4000\n",
      "2/2 - 0s - loss: 3.4287e-05 - accuracy: 1.0000 - val_loss: 3.7294 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2897/4000\n",
      "2/2 - 0s - loss: 3.4248e-05 - accuracy: 1.0000 - val_loss: 3.7298 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2898/4000\n",
      "2/2 - 0s - loss: 3.4193e-05 - accuracy: 1.0000 - val_loss: 3.7302 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2899/4000\n",
      "2/2 - 0s - loss: 3.4172e-05 - accuracy: 1.0000 - val_loss: 3.7305 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2900/4000\n",
      "2/2 - 0s - loss: 3.4121e-05 - accuracy: 1.0000 - val_loss: 3.7309 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2901/4000\n",
      "2/2 - 0s - loss: 3.4074e-05 - accuracy: 1.0000 - val_loss: 3.7313 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2902/4000\n",
      "2/2 - 0s - loss: 3.4029e-05 - accuracy: 1.0000 - val_loss: 3.7318 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2903/4000\n",
      "2/2 - 0s - loss: 3.3984e-05 - accuracy: 1.0000 - val_loss: 3.7322 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 2904/4000\n",
      "2/2 - 0s - loss: 3.3933e-05 - accuracy: 1.0000 - val_loss: 3.7326 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2905/4000\n",
      "2/2 - 0s - loss: 3.3882e-05 - accuracy: 1.0000 - val_loss: 3.7330 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2906/4000\n",
      "2/2 - 0s - loss: 3.3837e-05 - accuracy: 1.0000 - val_loss: 3.7334 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2907/4000\n",
      "2/2 - 0s - loss: 3.3801e-05 - accuracy: 1.0000 - val_loss: 3.7338 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2908/4000\n",
      "2/2 - 0s - loss: 3.3757e-05 - accuracy: 1.0000 - val_loss: 3.7342 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2909/4000\n",
      "2/2 - 0s - loss: 3.3723e-05 - accuracy: 1.0000 - val_loss: 3.7346 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2910/4000\n",
      "2/2 - 0s - loss: 3.3667e-05 - accuracy: 1.0000 - val_loss: 3.7349 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2911/4000\n",
      "2/2 - 0s - loss: 3.3616e-05 - accuracy: 1.0000 - val_loss: 3.7353 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2912/4000\n",
      "2/2 - 0s - loss: 3.3569e-05 - accuracy: 1.0000 - val_loss: 3.7357 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2913/4000\n",
      "2/2 - 0s - loss: 3.3535e-05 - accuracy: 1.0000 - val_loss: 3.7361 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2914/4000\n",
      "2/2 - 0s - loss: 3.3491e-05 - accuracy: 1.0000 - val_loss: 3.7365 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2915/4000\n",
      "2/2 - 0s - loss: 3.3446e-05 - accuracy: 1.0000 - val_loss: 3.7369 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2916/4000\n",
      "2/2 - 0s - loss: 3.3405e-05 - accuracy: 1.0000 - val_loss: 3.7373 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2917/4000\n",
      "2/2 - 0s - loss: 3.3367e-05 - accuracy: 1.0000 - val_loss: 3.7377 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2918/4000\n",
      "2/2 - 0s - loss: 3.3329e-05 - accuracy: 1.0000 - val_loss: 3.7381 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2919/4000\n",
      "2/2 - 0s - loss: 3.3293e-05 - accuracy: 1.0000 - val_loss: 3.7386 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2920/4000\n",
      "2/2 - 0s - loss: 3.3246e-05 - accuracy: 1.0000 - val_loss: 3.7390 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2921/4000\n",
      "2/2 - 0s - loss: 3.3201e-05 - accuracy: 1.0000 - val_loss: 3.7394 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2922/4000\n",
      "2/2 - 0s - loss: 3.3154e-05 - accuracy: 1.0000 - val_loss: 3.7398 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2923/4000\n",
      "2/2 - 0s - loss: 3.3116e-05 - accuracy: 1.0000 - val_loss: 3.7402 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2924/4000\n",
      "2/2 - 0s - loss: 3.3067e-05 - accuracy: 1.0000 - val_loss: 3.7407 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2925/4000\n",
      "2/2 - 0s - loss: 3.3022e-05 - accuracy: 1.0000 - val_loss: 3.7410 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 2926/4000\n",
      "2/2 - 0s - loss: 3.2973e-05 - accuracy: 1.0000 - val_loss: 3.7414 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 2927/4000\n",
      "2/2 - 0s - loss: 3.2937e-05 - accuracy: 1.0000 - val_loss: 3.7418 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2928/4000\n",
      "2/2 - 0s - loss: 3.2899e-05 - accuracy: 1.0000 - val_loss: 3.7421 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 2929/4000\n",
      "2/2 - 0s - loss: 3.2854e-05 - accuracy: 1.0000 - val_loss: 3.7426 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2930/4000\n",
      "2/2 - 0s - loss: 3.2820e-05 - accuracy: 1.0000 - val_loss: 3.7429 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2931/4000\n",
      "2/2 - 0s - loss: 3.2769e-05 - accuracy: 1.0000 - val_loss: 3.7433 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 2932/4000\n",
      "2/2 - 0s - loss: 3.2728e-05 - accuracy: 1.0000 - val_loss: 3.7438 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2933/4000\n",
      "2/2 - 0s - loss: 3.2694e-05 - accuracy: 1.0000 - val_loss: 3.7442 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2934/4000\n",
      "2/2 - 0s - loss: 3.2645e-05 - accuracy: 1.0000 - val_loss: 3.7446 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2935/4000\n",
      "2/2 - 0s - loss: 3.2622e-05 - accuracy: 1.0000 - val_loss: 3.7450 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2936/4000\n",
      "2/2 - 0s - loss: 3.2571e-05 - accuracy: 1.0000 - val_loss: 3.7455 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 2937/4000\n",
      "2/2 - 0s - loss: 3.2526e-05 - accuracy: 1.0000 - val_loss: 3.7459 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2938/4000\n",
      "2/2 - 0s - loss: 3.2482e-05 - accuracy: 1.0000 - val_loss: 3.7463 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 2939/4000\n",
      "2/2 - 0s - loss: 3.2437e-05 - accuracy: 1.0000 - val_loss: 3.7467 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2940/4000\n",
      "2/2 - 0s - loss: 3.2411e-05 - accuracy: 1.0000 - val_loss: 3.7472 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 2941/4000\n",
      "2/2 - 0s - loss: 3.2364e-05 - accuracy: 1.0000 - val_loss: 3.7475 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2942/4000\n",
      "2/2 - 0s - loss: 3.2311e-05 - accuracy: 1.0000 - val_loss: 3.7478 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 2943/4000\n",
      "2/2 - 0s - loss: 3.2275e-05 - accuracy: 1.0000 - val_loss: 3.7481 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2944/4000\n",
      "2/2 - 0s - loss: 3.2230e-05 - accuracy: 1.0000 - val_loss: 3.7486 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 2945/4000\n",
      "2/2 - 0s - loss: 3.2194e-05 - accuracy: 1.0000 - val_loss: 3.7489 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2946/4000\n",
      "2/2 - 0s - loss: 3.2149e-05 - accuracy: 1.0000 - val_loss: 3.7493 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2947/4000\n",
      "2/2 - 0s - loss: 3.2107e-05 - accuracy: 1.0000 - val_loss: 3.7497 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2948/4000\n",
      "2/2 - 0s - loss: 3.2075e-05 - accuracy: 1.0000 - val_loss: 3.7501 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2949/4000\n",
      "2/2 - 0s - loss: 3.2030e-05 - accuracy: 1.0000 - val_loss: 3.7505 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2950/4000\n",
      "2/2 - 0s - loss: 3.1990e-05 - accuracy: 1.0000 - val_loss: 3.7509 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2951/4000\n",
      "2/2 - 0s - loss: 3.1937e-05 - accuracy: 1.0000 - val_loss: 3.7513 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 2952/4000\n",
      "2/2 - 0s - loss: 3.1894e-05 - accuracy: 1.0000 - val_loss: 3.7516 - val_accuracy: 0.7250 - 85ms/epoch - 42ms/step\n",
      "Epoch 2953/4000\n",
      "2/2 - 0s - loss: 3.1856e-05 - accuracy: 1.0000 - val_loss: 3.7521 - val_accuracy: 0.7250 - 85ms/epoch - 42ms/step\n",
      "Epoch 2954/4000\n",
      "2/2 - 0s - loss: 3.1822e-05 - accuracy: 1.0000 - val_loss: 3.7525 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2955/4000\n",
      "2/2 - 0s - loss: 3.1781e-05 - accuracy: 1.0000 - val_loss: 3.7529 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2956/4000\n",
      "2/2 - 0s - loss: 3.1730e-05 - accuracy: 1.0000 - val_loss: 3.7534 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 2957/4000\n",
      "2/2 - 0s - loss: 3.1692e-05 - accuracy: 1.0000 - val_loss: 3.7537 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2958/4000\n",
      "2/2 - 0s - loss: 3.1671e-05 - accuracy: 1.0000 - val_loss: 3.7541 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2959/4000\n",
      "2/2 - 0s - loss: 3.1619e-05 - accuracy: 1.0000 - val_loss: 3.7545 - val_accuracy: 0.7250 - 80ms/epoch - 40ms/step\n",
      "Epoch 2960/4000\n",
      "2/2 - 0s - loss: 3.1568e-05 - accuracy: 1.0000 - val_loss: 3.7549 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 2961/4000\n",
      "2/2 - 0s - loss: 3.1536e-05 - accuracy: 1.0000 - val_loss: 3.7553 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 2962/4000\n",
      "2/2 - 0s - loss: 3.1507e-05 - accuracy: 1.0000 - val_loss: 3.7558 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 2963/4000\n",
      "2/2 - 0s - loss: 3.1451e-05 - accuracy: 1.0000 - val_loss: 3.7561 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2964/4000\n",
      "2/2 - 0s - loss: 3.1413e-05 - accuracy: 1.0000 - val_loss: 3.7565 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2965/4000\n",
      "2/2 - 0s - loss: 3.1368e-05 - accuracy: 1.0000 - val_loss: 3.7570 - val_accuracy: 0.7250 - 87ms/epoch - 43ms/step\n",
      "Epoch 2966/4000\n",
      "2/2 - 0s - loss: 3.1332e-05 - accuracy: 1.0000 - val_loss: 3.7574 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 2967/4000\n",
      "2/2 - 0s - loss: 3.1285e-05 - accuracy: 1.0000 - val_loss: 3.7578 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 2968/4000\n",
      "2/2 - 0s - loss: 3.1247e-05 - accuracy: 1.0000 - val_loss: 3.7582 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2969/4000\n",
      "2/2 - 0s - loss: 3.1209e-05 - accuracy: 1.0000 - val_loss: 3.7586 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2970/4000\n",
      "2/2 - 0s - loss: 3.1168e-05 - accuracy: 1.0000 - val_loss: 3.7589 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 2971/4000\n",
      "2/2 - 0s - loss: 3.1128e-05 - accuracy: 1.0000 - val_loss: 3.7593 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2972/4000\n",
      "2/2 - 0s - loss: 3.1094e-05 - accuracy: 1.0000 - val_loss: 3.7596 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2973/4000\n",
      "2/2 - 0s - loss: 3.1051e-05 - accuracy: 1.0000 - val_loss: 3.7599 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 2974/4000\n",
      "2/2 - 0s - loss: 3.1011e-05 - accuracy: 1.0000 - val_loss: 3.7603 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 2975/4000\n",
      "2/2 - 0s - loss: 3.0972e-05 - accuracy: 1.0000 - val_loss: 3.7607 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 2976/4000\n",
      "2/2 - 0s - loss: 3.0945e-05 - accuracy: 1.0000 - val_loss: 3.7611 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 2977/4000\n",
      "2/2 - 0s - loss: 3.0906e-05 - accuracy: 1.0000 - val_loss: 3.7614 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 2978/4000\n",
      "2/2 - 0s - loss: 3.0864e-05 - accuracy: 1.0000 - val_loss: 3.7617 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2979/4000\n",
      "2/2 - 0s - loss: 3.0821e-05 - accuracy: 1.0000 - val_loss: 3.7620 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 2980/4000\n",
      "2/2 - 0s - loss: 3.0779e-05 - accuracy: 1.0000 - val_loss: 3.7624 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 2981/4000\n",
      "2/2 - 0s - loss: 3.0736e-05 - accuracy: 1.0000 - val_loss: 3.7628 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 2982/4000\n",
      "2/2 - 0s - loss: 3.0704e-05 - accuracy: 1.0000 - val_loss: 3.7631 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 2983/4000\n",
      "2/2 - 0s - loss: 3.0662e-05 - accuracy: 1.0000 - val_loss: 3.7635 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2984/4000\n",
      "2/2 - 0s - loss: 3.0615e-05 - accuracy: 1.0000 - val_loss: 3.7638 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 2985/4000\n",
      "2/2 - 0s - loss: 3.0591e-05 - accuracy: 1.0000 - val_loss: 3.7642 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2986/4000\n",
      "2/2 - 0s - loss: 3.0545e-05 - accuracy: 1.0000 - val_loss: 3.7646 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 2987/4000\n",
      "2/2 - 0s - loss: 3.0502e-05 - accuracy: 1.0000 - val_loss: 3.7649 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2988/4000\n",
      "2/2 - 0s - loss: 3.0468e-05 - accuracy: 1.0000 - val_loss: 3.7653 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 2989/4000\n",
      "2/2 - 0s - loss: 3.0425e-05 - accuracy: 1.0000 - val_loss: 3.7657 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 2990/4000\n",
      "2/2 - 0s - loss: 3.0391e-05 - accuracy: 1.0000 - val_loss: 3.7661 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 2991/4000\n",
      "2/2 - 0s - loss: 3.0351e-05 - accuracy: 1.0000 - val_loss: 3.7664 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 2992/4000\n",
      "2/2 - 0s - loss: 3.0308e-05 - accuracy: 1.0000 - val_loss: 3.7668 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2993/4000\n",
      "2/2 - 0s - loss: 3.0274e-05 - accuracy: 1.0000 - val_loss: 3.7673 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2994/4000\n",
      "2/2 - 0s - loss: 3.0232e-05 - accuracy: 1.0000 - val_loss: 3.7676 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 2995/4000\n",
      "2/2 - 0s - loss: 3.0200e-05 - accuracy: 1.0000 - val_loss: 3.7679 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 2996/4000\n",
      "2/2 - 0s - loss: 3.0155e-05 - accuracy: 1.0000 - val_loss: 3.7682 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 2997/4000\n",
      "2/2 - 0s - loss: 3.0112e-05 - accuracy: 1.0000 - val_loss: 3.7687 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 2998/4000\n",
      "2/2 - 0s - loss: 3.0074e-05 - accuracy: 1.0000 - val_loss: 3.7691 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 2999/4000\n",
      "2/2 - 0s - loss: 3.0038e-05 - accuracy: 1.0000 - val_loss: 3.7696 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 3000/4000\n",
      "2/2 - 0s - loss: 3.0004e-05 - accuracy: 1.0000 - val_loss: 3.7700 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3001/4000\n",
      "2/2 - 0s - loss: 2.9953e-05 - accuracy: 1.0000 - val_loss: 3.7704 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3002/4000\n",
      "2/2 - 0s - loss: 2.9921e-05 - accuracy: 1.0000 - val_loss: 3.7708 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3003/4000\n",
      "2/2 - 0s - loss: 2.9882e-05 - accuracy: 1.0000 - val_loss: 3.7712 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3004/4000\n",
      "2/2 - 0s - loss: 2.9851e-05 - accuracy: 1.0000 - val_loss: 3.7716 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3005/4000\n",
      "2/2 - 0s - loss: 2.9814e-05 - accuracy: 1.0000 - val_loss: 3.7721 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3006/4000\n",
      "2/2 - 0s - loss: 2.9774e-05 - accuracy: 1.0000 - val_loss: 3.7725 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3007/4000\n",
      "2/2 - 0s - loss: 2.9729e-05 - accuracy: 1.0000 - val_loss: 3.7728 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3008/4000\n",
      "2/2 - 0s - loss: 2.9680e-05 - accuracy: 1.0000 - val_loss: 3.7732 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3009/4000\n",
      "2/2 - 0s - loss: 2.9642e-05 - accuracy: 1.0000 - val_loss: 3.7735 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3010/4000\n",
      "2/2 - 0s - loss: 2.9610e-05 - accuracy: 1.0000 - val_loss: 3.7740 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3011/4000\n",
      "2/2 - 0s - loss: 2.9582e-05 - accuracy: 1.0000 - val_loss: 3.7743 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3012/4000\n",
      "2/2 - 0s - loss: 2.9548e-05 - accuracy: 1.0000 - val_loss: 3.7747 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3013/4000\n",
      "2/2 - 0s - loss: 2.9501e-05 - accuracy: 1.0000 - val_loss: 3.7751 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3014/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.9463e-05 - accuracy: 1.0000 - val_loss: 3.7755 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3015/4000\n",
      "2/2 - 0s - loss: 2.9435e-05 - accuracy: 1.0000 - val_loss: 3.7759 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3016/4000\n",
      "2/2 - 0s - loss: 2.9395e-05 - accuracy: 1.0000 - val_loss: 3.7763 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3017/4000\n",
      "2/2 - 0s - loss: 2.9355e-05 - accuracy: 1.0000 - val_loss: 3.7767 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3018/4000\n",
      "2/2 - 0s - loss: 2.9329e-05 - accuracy: 1.0000 - val_loss: 3.7771 - val_accuracy: 0.7250 - 84ms/epoch - 42ms/step\n",
      "Epoch 3019/4000\n",
      "2/2 - 0s - loss: 2.9291e-05 - accuracy: 1.0000 - val_loss: 3.7775 - val_accuracy: 0.7250 - 83ms/epoch - 42ms/step\n",
      "Epoch 3020/4000\n",
      "2/2 - 0s - loss: 2.9252e-05 - accuracy: 1.0000 - val_loss: 3.7778 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3021/4000\n",
      "2/2 - 0s - loss: 2.9206e-05 - accuracy: 1.0000 - val_loss: 3.7782 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3022/4000\n",
      "2/2 - 0s - loss: 2.9167e-05 - accuracy: 1.0000 - val_loss: 3.7786 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3023/4000\n",
      "2/2 - 0s - loss: 2.9133e-05 - accuracy: 1.0000 - val_loss: 3.7789 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3024/4000\n",
      "2/2 - 0s - loss: 2.9097e-05 - accuracy: 1.0000 - val_loss: 3.7793 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3025/4000\n",
      "2/2 - 0s - loss: 2.9059e-05 - accuracy: 1.0000 - val_loss: 3.7797 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3026/4000\n",
      "2/2 - 0s - loss: 2.9027e-05 - accuracy: 1.0000 - val_loss: 3.7801 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3027/4000\n",
      "2/2 - 0s - loss: 2.8980e-05 - accuracy: 1.0000 - val_loss: 3.7805 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3028/4000\n",
      "2/2 - 0s - loss: 2.8950e-05 - accuracy: 1.0000 - val_loss: 3.7809 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3029/4000\n",
      "2/2 - 0s - loss: 2.8908e-05 - accuracy: 1.0000 - val_loss: 3.7813 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3030/4000\n",
      "2/2 - 0s - loss: 2.8874e-05 - accuracy: 1.0000 - val_loss: 3.7817 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3031/4000\n",
      "2/2 - 0s - loss: 2.8835e-05 - accuracy: 1.0000 - val_loss: 3.7821 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3032/4000\n",
      "2/2 - 0s - loss: 2.8797e-05 - accuracy: 1.0000 - val_loss: 3.7825 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3033/4000\n",
      "2/2 - 0s - loss: 2.8767e-05 - accuracy: 1.0000 - val_loss: 3.7829 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3034/4000\n",
      "2/2 - 0s - loss: 2.8731e-05 - accuracy: 1.0000 - val_loss: 3.7833 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3035/4000\n",
      "2/2 - 0s - loss: 2.8686e-05 - accuracy: 1.0000 - val_loss: 3.7837 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3036/4000\n",
      "2/2 - 0s - loss: 2.8648e-05 - accuracy: 1.0000 - val_loss: 3.7840 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3037/4000\n",
      "2/2 - 0s - loss: 2.8618e-05 - accuracy: 1.0000 - val_loss: 3.7844 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3038/4000\n",
      "2/2 - 0s - loss: 2.8578e-05 - accuracy: 1.0000 - val_loss: 3.7849 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3039/4000\n",
      "2/2 - 0s - loss: 2.8554e-05 - accuracy: 1.0000 - val_loss: 3.7853 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3040/4000\n",
      "2/2 - 0s - loss: 2.8505e-05 - accuracy: 1.0000 - val_loss: 3.7857 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 3041/4000\n",
      "2/2 - 0s - loss: 2.8465e-05 - accuracy: 1.0000 - val_loss: 3.7861 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3042/4000\n",
      "2/2 - 0s - loss: 2.8429e-05 - accuracy: 1.0000 - val_loss: 3.7865 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3043/4000\n",
      "2/2 - 0s - loss: 2.8390e-05 - accuracy: 1.0000 - val_loss: 3.7869 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3044/4000\n",
      "2/2 - 0s - loss: 2.8371e-05 - accuracy: 1.0000 - val_loss: 3.7874 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3045/4000\n",
      "2/2 - 0s - loss: 2.8329e-05 - accuracy: 1.0000 - val_loss: 3.7878 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 3046/4000\n",
      "2/2 - 0s - loss: 2.8288e-05 - accuracy: 1.0000 - val_loss: 3.7883 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 3047/4000\n",
      "2/2 - 0s - loss: 2.8252e-05 - accuracy: 1.0000 - val_loss: 3.7887 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3048/4000\n",
      "2/2 - 0s - loss: 2.8207e-05 - accuracy: 1.0000 - val_loss: 3.7891 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3049/4000\n",
      "2/2 - 0s - loss: 2.8177e-05 - accuracy: 1.0000 - val_loss: 3.7894 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3050/4000\n",
      "2/2 - 0s - loss: 2.8146e-05 - accuracy: 1.0000 - val_loss: 3.7899 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3051/4000\n",
      "2/2 - 0s - loss: 2.8111e-05 - accuracy: 1.0000 - val_loss: 3.7903 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3052/4000\n",
      "2/2 - 0s - loss: 2.8084e-05 - accuracy: 1.0000 - val_loss: 3.7907 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3053/4000\n",
      "2/2 - 0s - loss: 2.8039e-05 - accuracy: 1.0000 - val_loss: 3.7911 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3054/4000\n",
      "2/2 - 0s - loss: 2.8003e-05 - accuracy: 1.0000 - val_loss: 3.7916 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3055/4000\n",
      "2/2 - 0s - loss: 2.7971e-05 - accuracy: 1.0000 - val_loss: 3.7919 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3056/4000\n",
      "2/2 - 0s - loss: 2.7937e-05 - accuracy: 1.0000 - val_loss: 3.7922 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3057/4000\n",
      "2/2 - 0s - loss: 2.7907e-05 - accuracy: 1.0000 - val_loss: 3.7926 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3058/4000\n",
      "2/2 - 0s - loss: 2.7854e-05 - accuracy: 1.0000 - val_loss: 3.7930 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3059/4000\n",
      "2/2 - 0s - loss: 2.7822e-05 - accuracy: 1.0000 - val_loss: 3.7933 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3060/4000\n",
      "2/2 - 0s - loss: 2.7794e-05 - accuracy: 1.0000 - val_loss: 3.7937 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3061/4000\n",
      "2/2 - 0s - loss: 2.7758e-05 - accuracy: 1.0000 - val_loss: 3.7942 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3062/4000\n",
      "2/2 - 0s - loss: 2.7720e-05 - accuracy: 1.0000 - val_loss: 3.7946 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3063/4000\n",
      "2/2 - 0s - loss: 2.7686e-05 - accuracy: 1.0000 - val_loss: 3.7949 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3064/4000\n",
      "2/2 - 0s - loss: 2.7641e-05 - accuracy: 1.0000 - val_loss: 3.7953 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3065/4000\n",
      "2/2 - 0s - loss: 2.7609e-05 - accuracy: 1.0000 - val_loss: 3.7957 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3066/4000\n",
      "2/2 - 0s - loss: 2.7579e-05 - accuracy: 1.0000 - val_loss: 3.7962 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3067/4000\n",
      "2/2 - 0s - loss: 2.7545e-05 - accuracy: 1.0000 - val_loss: 3.7966 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3068/4000\n",
      "2/2 - 0s - loss: 2.7509e-05 - accuracy: 1.0000 - val_loss: 3.7970 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3069/4000\n",
      "2/2 - 0s - loss: 2.7481e-05 - accuracy: 1.0000 - val_loss: 3.7974 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3070/4000\n",
      "2/2 - 0s - loss: 2.7447e-05 - accuracy: 1.0000 - val_loss: 3.7978 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3071/4000\n",
      "2/2 - 0s - loss: 2.7413e-05 - accuracy: 1.0000 - val_loss: 3.7981 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3072/4000\n",
      "2/2 - 0s - loss: 2.7377e-05 - accuracy: 1.0000 - val_loss: 3.7985 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3073/4000\n",
      "2/2 - 0s - loss: 2.7328e-05 - accuracy: 1.0000 - val_loss: 3.7990 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3074/4000\n",
      "2/2 - 0s - loss: 2.7305e-05 - accuracy: 1.0000 - val_loss: 3.7994 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3075/4000\n",
      "2/2 - 0s - loss: 2.7266e-05 - accuracy: 1.0000 - val_loss: 3.7998 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3076/4000\n",
      "2/2 - 0s - loss: 2.7228e-05 - accuracy: 1.0000 - val_loss: 3.8003 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3077/4000\n",
      "2/2 - 0s - loss: 2.7196e-05 - accuracy: 1.0000 - val_loss: 3.8008 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3078/4000\n",
      "2/2 - 0s - loss: 2.7156e-05 - accuracy: 1.0000 - val_loss: 3.8012 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3079/4000\n",
      "2/2 - 0s - loss: 2.7128e-05 - accuracy: 1.0000 - val_loss: 3.8016 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3080/4000\n",
      "2/2 - 0s - loss: 2.7098e-05 - accuracy: 1.0000 - val_loss: 3.8020 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3081/4000\n",
      "2/2 - 0s - loss: 2.7058e-05 - accuracy: 1.0000 - val_loss: 3.8024 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3082/4000\n",
      "2/2 - 0s - loss: 2.7024e-05 - accuracy: 1.0000 - val_loss: 3.8028 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3083/4000\n",
      "2/2 - 0s - loss: 2.6992e-05 - accuracy: 1.0000 - val_loss: 3.8032 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3084/4000\n",
      "2/2 - 0s - loss: 2.6958e-05 - accuracy: 1.0000 - val_loss: 3.8036 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3085/4000\n",
      "2/2 - 0s - loss: 2.6924e-05 - accuracy: 1.0000 - val_loss: 3.8040 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3086/4000\n",
      "2/2 - 0s - loss: 2.6896e-05 - accuracy: 1.0000 - val_loss: 3.8044 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3087/4000\n",
      "2/2 - 0s - loss: 2.6847e-05 - accuracy: 1.0000 - val_loss: 3.8047 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3088/4000\n",
      "2/2 - 0s - loss: 2.6811e-05 - accuracy: 1.0000 - val_loss: 3.8051 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3089/4000\n",
      "2/2 - 0s - loss: 2.6783e-05 - accuracy: 1.0000 - val_loss: 3.8056 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3090/4000\n",
      "2/2 - 0s - loss: 2.6743e-05 - accuracy: 1.0000 - val_loss: 3.8060 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3091/4000\n",
      "2/2 - 0s - loss: 2.6719e-05 - accuracy: 1.0000 - val_loss: 3.8064 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3092/4000\n",
      "2/2 - 0s - loss: 2.6679e-05 - accuracy: 1.0000 - val_loss: 3.8068 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3093/4000\n",
      "2/2 - 0s - loss: 2.6653e-05 - accuracy: 1.0000 - val_loss: 3.8071 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3094/4000\n",
      "2/2 - 0s - loss: 2.6617e-05 - accuracy: 1.0000 - val_loss: 3.8076 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3095/4000\n",
      "2/2 - 0s - loss: 2.6579e-05 - accuracy: 1.0000 - val_loss: 3.8080 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3096/4000\n",
      "2/2 - 0s - loss: 2.6547e-05 - accuracy: 1.0000 - val_loss: 3.8083 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3097/4000\n",
      "2/2 - 0s - loss: 2.6513e-05 - accuracy: 1.0000 - val_loss: 3.8086 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3098/4000\n",
      "2/2 - 0s - loss: 2.6477e-05 - accuracy: 1.0000 - val_loss: 3.8090 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3099/4000\n",
      "2/2 - 0s - loss: 2.6445e-05 - accuracy: 1.0000 - val_loss: 3.8094 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3100/4000\n",
      "2/2 - 0s - loss: 2.6409e-05 - accuracy: 1.0000 - val_loss: 3.8098 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3101/4000\n",
      "2/2 - 0s - loss: 2.6372e-05 - accuracy: 1.0000 - val_loss: 3.8102 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3102/4000\n",
      "2/2 - 0s - loss: 2.6351e-05 - accuracy: 1.0000 - val_loss: 3.8105 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3103/4000\n",
      "2/2 - 0s - loss: 2.6311e-05 - accuracy: 1.0000 - val_loss: 3.8108 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3104/4000\n",
      "2/2 - 0s - loss: 2.6277e-05 - accuracy: 1.0000 - val_loss: 3.8111 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3105/4000\n",
      "2/2 - 0s - loss: 2.6245e-05 - accuracy: 1.0000 - val_loss: 3.8115 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3106/4000\n",
      "2/2 - 0s - loss: 2.6206e-05 - accuracy: 1.0000 - val_loss: 3.8119 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3107/4000\n",
      "2/2 - 0s - loss: 2.6179e-05 - accuracy: 1.0000 - val_loss: 3.8123 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3108/4000\n",
      "2/2 - 0s - loss: 2.6151e-05 - accuracy: 1.0000 - val_loss: 3.8126 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 3109/4000\n",
      "2/2 - 0s - loss: 2.6108e-05 - accuracy: 1.0000 - val_loss: 3.8129 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3110/4000\n",
      "2/2 - 0s - loss: 2.6081e-05 - accuracy: 1.0000 - val_loss: 3.8133 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3111/4000\n",
      "2/2 - 0s - loss: 2.6059e-05 - accuracy: 1.0000 - val_loss: 3.8137 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3112/4000\n",
      "2/2 - 0s - loss: 2.6010e-05 - accuracy: 1.0000 - val_loss: 3.8141 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3113/4000\n",
      "2/2 - 0s - loss: 2.5979e-05 - accuracy: 1.0000 - val_loss: 3.8146 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3114/4000\n",
      "2/2 - 0s - loss: 2.5942e-05 - accuracy: 1.0000 - val_loss: 3.8150 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3115/4000\n",
      "2/2 - 0s - loss: 2.5915e-05 - accuracy: 1.0000 - val_loss: 3.8154 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3116/4000\n",
      "2/2 - 0s - loss: 2.5885e-05 - accuracy: 1.0000 - val_loss: 3.8158 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3117/4000\n",
      "2/2 - 0s - loss: 2.5851e-05 - accuracy: 1.0000 - val_loss: 3.8162 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3118/4000\n",
      "2/2 - 0s - loss: 2.5813e-05 - accuracy: 1.0000 - val_loss: 3.8165 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3119/4000\n",
      "2/2 - 0s - loss: 2.5778e-05 - accuracy: 1.0000 - val_loss: 3.8169 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3120/4000\n",
      "2/2 - 0s - loss: 2.5747e-05 - accuracy: 1.0000 - val_loss: 3.8172 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3121/4000\n",
      "2/2 - 0s - loss: 2.5706e-05 - accuracy: 1.0000 - val_loss: 3.8176 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3122/4000\n",
      "2/2 - 0s - loss: 2.5685e-05 - accuracy: 1.0000 - val_loss: 3.8180 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3123/4000\n",
      "2/2 - 0s - loss: 2.5655e-05 - accuracy: 1.0000 - val_loss: 3.8184 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3124/4000\n",
      "2/2 - 0s - loss: 2.5627e-05 - accuracy: 1.0000 - val_loss: 3.8187 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3125/4000\n",
      "2/2 - 0s - loss: 2.5600e-05 - accuracy: 1.0000 - val_loss: 3.8190 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3126/4000\n",
      "2/2 - 0s - loss: 2.5555e-05 - accuracy: 1.0000 - val_loss: 3.8194 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3127/4000\n",
      "2/2 - 0s - loss: 2.5525e-05 - accuracy: 1.0000 - val_loss: 3.8198 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3128/4000\n",
      "2/2 - 0s - loss: 2.5493e-05 - accuracy: 1.0000 - val_loss: 3.8203 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3129/4000\n",
      "2/2 - 0s - loss: 2.5461e-05 - accuracy: 1.0000 - val_loss: 3.8207 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3130/4000\n",
      "2/2 - 0s - loss: 2.5425e-05 - accuracy: 1.0000 - val_loss: 3.8211 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3131/4000\n",
      "2/2 - 0s - loss: 2.5404e-05 - accuracy: 1.0000 - val_loss: 3.8215 - val_accuracy: 0.7250 - 85ms/epoch - 43ms/step\n",
      "Epoch 3132/4000\n",
      "2/2 - 0s - loss: 2.5372e-05 - accuracy: 1.0000 - val_loss: 3.8219 - val_accuracy: 0.7250 - 98ms/epoch - 49ms/step\n",
      "Epoch 3133/4000\n",
      "2/2 - 0s - loss: 2.5334e-05 - accuracy: 1.0000 - val_loss: 3.8223 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 3134/4000\n",
      "2/2 - 0s - loss: 2.5300e-05 - accuracy: 1.0000 - val_loss: 3.8227 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3135/4000\n",
      "2/2 - 0s - loss: 2.5270e-05 - accuracy: 1.0000 - val_loss: 3.8231 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3136/4000\n",
      "2/2 - 0s - loss: 2.5238e-05 - accuracy: 1.0000 - val_loss: 3.8235 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3137/4000\n",
      "2/2 - 0s - loss: 2.5210e-05 - accuracy: 1.0000 - val_loss: 3.8239 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3138/4000\n",
      "2/2 - 0s - loss: 2.5170e-05 - accuracy: 1.0000 - val_loss: 3.8243 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3139/4000\n",
      "2/2 - 0s - loss: 2.5151e-05 - accuracy: 1.0000 - val_loss: 3.8247 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3140/4000\n",
      "2/2 - 0s - loss: 2.5119e-05 - accuracy: 1.0000 - val_loss: 3.8251 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3141/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.5085e-05 - accuracy: 1.0000 - val_loss: 3.8255 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3142/4000\n",
      "2/2 - 0s - loss: 2.5053e-05 - accuracy: 1.0000 - val_loss: 3.8258 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3143/4000\n",
      "2/2 - 0s - loss: 2.5019e-05 - accuracy: 1.0000 - val_loss: 3.8261 - val_accuracy: 0.7250 - 81ms/epoch - 41ms/step\n",
      "Epoch 3144/4000\n",
      "2/2 - 0s - loss: 2.4987e-05 - accuracy: 1.0000 - val_loss: 3.8265 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3145/4000\n",
      "2/2 - 0s - loss: 2.4961e-05 - accuracy: 1.0000 - val_loss: 3.8270 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3146/4000\n",
      "2/2 - 0s - loss: 2.4936e-05 - accuracy: 1.0000 - val_loss: 3.8274 - val_accuracy: 0.7250 - 81ms/epoch - 40ms/step\n",
      "Epoch 3147/4000\n",
      "2/2 - 0s - loss: 2.4906e-05 - accuracy: 1.0000 - val_loss: 3.8277 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3148/4000\n",
      "2/2 - 0s - loss: 2.4870e-05 - accuracy: 1.0000 - val_loss: 3.8282 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3149/4000\n",
      "2/2 - 0s - loss: 2.4850e-05 - accuracy: 1.0000 - val_loss: 3.8286 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 3150/4000\n",
      "2/2 - 0s - loss: 2.4814e-05 - accuracy: 1.0000 - val_loss: 3.8290 - val_accuracy: 0.7250 - 102ms/epoch - 51ms/step\n",
      "Epoch 3151/4000\n",
      "2/2 - 0s - loss: 2.4774e-05 - accuracy: 1.0000 - val_loss: 3.8294 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 3152/4000\n",
      "2/2 - 0s - loss: 2.4740e-05 - accuracy: 1.0000 - val_loss: 3.8299 - val_accuracy: 0.7250 - 104ms/epoch - 52ms/step\n",
      "Epoch 3153/4000\n",
      "2/2 - 0s - loss: 2.4710e-05 - accuracy: 1.0000 - val_loss: 3.8303 - val_accuracy: 0.7250 - 89ms/epoch - 45ms/step\n",
      "Epoch 3154/4000\n",
      "2/2 - 0s - loss: 2.4678e-05 - accuracy: 1.0000 - val_loss: 3.8307 - val_accuracy: 0.7250 - 87ms/epoch - 43ms/step\n",
      "Epoch 3155/4000\n",
      "2/2 - 0s - loss: 2.4640e-05 - accuracy: 1.0000 - val_loss: 3.8310 - val_accuracy: 0.7250 - 105ms/epoch - 52ms/step\n",
      "Epoch 3156/4000\n",
      "2/2 - 0s - loss: 2.4603e-05 - accuracy: 1.0000 - val_loss: 3.8313 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3157/4000\n",
      "2/2 - 0s - loss: 2.4576e-05 - accuracy: 1.0000 - val_loss: 3.8316 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3158/4000\n",
      "2/2 - 0s - loss: 2.4544e-05 - accuracy: 1.0000 - val_loss: 3.8320 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3159/4000\n",
      "2/2 - 0s - loss: 2.4518e-05 - accuracy: 1.0000 - val_loss: 3.8324 - val_accuracy: 0.7250 - 44ms/epoch - 22ms/step\n",
      "Epoch 3160/4000\n",
      "2/2 - 0s - loss: 2.4486e-05 - accuracy: 1.0000 - val_loss: 3.8328 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3161/4000\n",
      "2/2 - 0s - loss: 2.4459e-05 - accuracy: 1.0000 - val_loss: 3.8332 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3162/4000\n",
      "2/2 - 0s - loss: 2.4433e-05 - accuracy: 1.0000 - val_loss: 3.8336 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3163/4000\n",
      "2/2 - 0s - loss: 2.4405e-05 - accuracy: 1.0000 - val_loss: 3.8340 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3164/4000\n",
      "2/2 - 0s - loss: 2.4376e-05 - accuracy: 1.0000 - val_loss: 3.8343 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3165/4000\n",
      "2/2 - 0s - loss: 2.4348e-05 - accuracy: 1.0000 - val_loss: 3.8347 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3166/4000\n",
      "2/2 - 0s - loss: 2.4308e-05 - accuracy: 1.0000 - val_loss: 3.8351 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3167/4000\n",
      "2/2 - 0s - loss: 2.4286e-05 - accuracy: 1.0000 - val_loss: 3.8354 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3168/4000\n",
      "2/2 - 0s - loss: 2.4242e-05 - accuracy: 1.0000 - val_loss: 3.8358 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3169/4000\n",
      "2/2 - 0s - loss: 2.4220e-05 - accuracy: 1.0000 - val_loss: 3.8362 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3170/4000\n",
      "2/2 - 0s - loss: 2.4186e-05 - accuracy: 1.0000 - val_loss: 3.8365 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3171/4000\n",
      "2/2 - 0s - loss: 2.4146e-05 - accuracy: 1.0000 - val_loss: 3.8370 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3172/4000\n",
      "2/2 - 0s - loss: 2.4110e-05 - accuracy: 1.0000 - val_loss: 3.8374 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3173/4000\n",
      "2/2 - 0s - loss: 2.4086e-05 - accuracy: 1.0000 - val_loss: 3.8378 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3174/4000\n",
      "2/2 - 0s - loss: 2.4050e-05 - accuracy: 1.0000 - val_loss: 3.8382 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3175/4000\n",
      "2/2 - 0s - loss: 2.4024e-05 - accuracy: 1.0000 - val_loss: 3.8386 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3176/4000\n",
      "2/2 - 0s - loss: 2.3995e-05 - accuracy: 1.0000 - val_loss: 3.8390 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3177/4000\n",
      "2/2 - 0s - loss: 2.3965e-05 - accuracy: 1.0000 - val_loss: 3.8395 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3178/4000\n",
      "2/2 - 0s - loss: 2.3939e-05 - accuracy: 1.0000 - val_loss: 3.8398 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 3179/4000\n",
      "2/2 - 0s - loss: 2.3912e-05 - accuracy: 1.0000 - val_loss: 3.8403 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3180/4000\n",
      "2/2 - 0s - loss: 2.3878e-05 - accuracy: 1.0000 - val_loss: 3.8407 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3181/4000\n",
      "2/2 - 0s - loss: 2.3844e-05 - accuracy: 1.0000 - val_loss: 3.8411 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3182/4000\n",
      "2/2 - 0s - loss: 2.3807e-05 - accuracy: 1.0000 - val_loss: 3.8415 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3183/4000\n",
      "2/2 - 0s - loss: 2.3778e-05 - accuracy: 1.0000 - val_loss: 3.8419 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3184/4000\n",
      "2/2 - 0s - loss: 2.3756e-05 - accuracy: 1.0000 - val_loss: 3.8422 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3185/4000\n",
      "2/2 - 0s - loss: 2.3731e-05 - accuracy: 1.0000 - val_loss: 3.8426 - val_accuracy: 0.7250 - 79ms/epoch - 39ms/step\n",
      "Epoch 3186/4000\n",
      "2/2 - 0s - loss: 2.3705e-05 - accuracy: 1.0000 - val_loss: 3.8430 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 3187/4000\n",
      "2/2 - 0s - loss: 2.3677e-05 - accuracy: 1.0000 - val_loss: 3.8434 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3188/4000\n",
      "2/2 - 0s - loss: 2.3646e-05 - accuracy: 1.0000 - val_loss: 3.8438 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3189/4000\n",
      "2/2 - 0s - loss: 2.3597e-05 - accuracy: 1.0000 - val_loss: 3.8442 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3190/4000\n",
      "2/2 - 0s - loss: 2.3571e-05 - accuracy: 1.0000 - val_loss: 3.8445 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3191/4000\n",
      "2/2 - 0s - loss: 2.3543e-05 - accuracy: 1.0000 - val_loss: 3.8449 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3192/4000\n",
      "2/2 - 0s - loss: 2.3507e-05 - accuracy: 1.0000 - val_loss: 3.8452 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3193/4000\n",
      "2/2 - 0s - loss: 2.3490e-05 - accuracy: 1.0000 - val_loss: 3.8456 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 3194/4000\n",
      "2/2 - 0s - loss: 2.3463e-05 - accuracy: 1.0000 - val_loss: 3.8460 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3195/4000\n",
      "2/2 - 0s - loss: 2.3439e-05 - accuracy: 1.0000 - val_loss: 3.8465 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3196/4000\n",
      "2/2 - 0s - loss: 2.3409e-05 - accuracy: 1.0000 - val_loss: 3.8469 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3197/4000\n",
      "2/2 - 0s - loss: 2.3362e-05 - accuracy: 1.0000 - val_loss: 3.8472 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3198/4000\n",
      "2/2 - 0s - loss: 2.3337e-05 - accuracy: 1.0000 - val_loss: 3.8476 - val_accuracy: 0.7250 - 43ms/epoch - 22ms/step\n",
      "Epoch 3199/4000\n",
      "2/2 - 0s - loss: 2.3313e-05 - accuracy: 1.0000 - val_loss: 3.8480 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3200/4000\n",
      "2/2 - 0s - loss: 2.3284e-05 - accuracy: 1.0000 - val_loss: 3.8483 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3201/4000\n",
      "2/2 - 0s - loss: 2.3265e-05 - accuracy: 1.0000 - val_loss: 3.8487 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3202/4000\n",
      "2/2 - 0s - loss: 2.3230e-05 - accuracy: 1.0000 - val_loss: 3.8491 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3203/4000\n",
      "2/2 - 0s - loss: 2.3209e-05 - accuracy: 1.0000 - val_loss: 3.8495 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3204/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.3186e-05 - accuracy: 1.0000 - val_loss: 3.8500 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3205/4000\n",
      "2/2 - 0s - loss: 2.3143e-05 - accuracy: 1.0000 - val_loss: 3.8503 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3206/4000\n",
      "2/2 - 0s - loss: 2.3111e-05 - accuracy: 1.0000 - val_loss: 3.8507 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3207/4000\n",
      "2/2 - 0s - loss: 2.3075e-05 - accuracy: 1.0000 - val_loss: 3.8512 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3208/4000\n",
      "2/2 - 0s - loss: 2.3052e-05 - accuracy: 1.0000 - val_loss: 3.8516 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3209/4000\n",
      "2/2 - 0s - loss: 2.3018e-05 - accuracy: 1.0000 - val_loss: 3.8519 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3210/4000\n",
      "2/2 - 0s - loss: 2.2984e-05 - accuracy: 1.0000 - val_loss: 3.8523 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3211/4000\n",
      "2/2 - 0s - loss: 2.2964e-05 - accuracy: 1.0000 - val_loss: 3.8526 - val_accuracy: 0.7250 - 44ms/epoch - 22ms/step\n",
      "Epoch 3212/4000\n",
      "2/2 - 0s - loss: 2.2937e-05 - accuracy: 1.0000 - val_loss: 3.8530 - val_accuracy: 0.7250 - 43ms/epoch - 21ms/step\n",
      "Epoch 3213/4000\n",
      "2/2 - 0s - loss: 2.2909e-05 - accuracy: 1.0000 - val_loss: 3.8533 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3214/4000\n",
      "2/2 - 0s - loss: 2.2886e-05 - accuracy: 1.0000 - val_loss: 3.8536 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3215/4000\n",
      "2/2 - 0s - loss: 2.2854e-05 - accuracy: 1.0000 - val_loss: 3.8540 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3216/4000\n",
      "2/2 - 0s - loss: 2.2820e-05 - accuracy: 1.0000 - val_loss: 3.8543 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3217/4000\n",
      "2/2 - 0s - loss: 2.2794e-05 - accuracy: 1.0000 - val_loss: 3.8547 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3218/4000\n",
      "2/2 - 0s - loss: 2.2773e-05 - accuracy: 1.0000 - val_loss: 3.8551 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3219/4000\n",
      "2/2 - 0s - loss: 2.2728e-05 - accuracy: 1.0000 - val_loss: 3.8555 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3220/4000\n",
      "2/2 - 0s - loss: 2.2709e-05 - accuracy: 1.0000 - val_loss: 3.8559 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3221/4000\n",
      "2/2 - 0s - loss: 2.2677e-05 - accuracy: 1.0000 - val_loss: 3.8563 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3222/4000\n",
      "2/2 - 0s - loss: 2.2649e-05 - accuracy: 1.0000 - val_loss: 3.8567 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3223/4000\n",
      "2/2 - 0s - loss: 2.2615e-05 - accuracy: 1.0000 - val_loss: 3.8570 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3224/4000\n",
      "2/2 - 0s - loss: 2.2590e-05 - accuracy: 1.0000 - val_loss: 3.8574 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3225/4000\n",
      "2/2 - 0s - loss: 2.2562e-05 - accuracy: 1.0000 - val_loss: 3.8578 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3226/4000\n",
      "2/2 - 0s - loss: 2.2532e-05 - accuracy: 1.0000 - val_loss: 3.8582 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3227/4000\n",
      "2/2 - 0s - loss: 2.2502e-05 - accuracy: 1.0000 - val_loss: 3.8585 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3228/4000\n",
      "2/2 - 0s - loss: 2.2477e-05 - accuracy: 1.0000 - val_loss: 3.8588 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3229/4000\n",
      "2/2 - 0s - loss: 2.2443e-05 - accuracy: 1.0000 - val_loss: 3.8592 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3230/4000\n",
      "2/2 - 0s - loss: 2.2407e-05 - accuracy: 1.0000 - val_loss: 3.8597 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3231/4000\n",
      "2/2 - 0s - loss: 2.2394e-05 - accuracy: 1.0000 - val_loss: 3.8600 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3232/4000\n",
      "2/2 - 0s - loss: 2.2368e-05 - accuracy: 1.0000 - val_loss: 3.8604 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3233/4000\n",
      "2/2 - 0s - loss: 2.2341e-05 - accuracy: 1.0000 - val_loss: 3.8607 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3234/4000\n",
      "2/2 - 0s - loss: 2.2319e-05 - accuracy: 1.0000 - val_loss: 3.8611 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3235/4000\n",
      "2/2 - 0s - loss: 2.2287e-05 - accuracy: 1.0000 - val_loss: 3.8616 - val_accuracy: 0.7250 - 120ms/epoch - 60ms/step\n",
      "Epoch 3236/4000\n",
      "2/2 - 0s - loss: 2.2256e-05 - accuracy: 1.0000 - val_loss: 3.8620 - val_accuracy: 0.7250 - 81ms/epoch - 41ms/step\n",
      "Epoch 3237/4000\n",
      "2/2 - 0s - loss: 2.2221e-05 - accuracy: 1.0000 - val_loss: 3.8624 - val_accuracy: 0.7250 - 111ms/epoch - 56ms/step\n",
      "Epoch 3238/4000\n",
      "2/2 - 0s - loss: 2.2192e-05 - accuracy: 1.0000 - val_loss: 3.8628 - val_accuracy: 0.7250 - 97ms/epoch - 49ms/step\n",
      "Epoch 3239/4000\n",
      "2/2 - 0s - loss: 2.2160e-05 - accuracy: 1.0000 - val_loss: 3.8632 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3240/4000\n",
      "2/2 - 0s - loss: 2.2136e-05 - accuracy: 1.0000 - val_loss: 3.8635 - val_accuracy: 0.7250 - 83ms/epoch - 41ms/step\n",
      "Epoch 3241/4000\n",
      "2/2 - 0s - loss: 2.2113e-05 - accuracy: 1.0000 - val_loss: 3.8639 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 3242/4000\n",
      "2/2 - 0s - loss: 2.2081e-05 - accuracy: 1.0000 - val_loss: 3.8643 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3243/4000\n",
      "2/2 - 0s - loss: 2.2058e-05 - accuracy: 1.0000 - val_loss: 3.8647 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3244/4000\n",
      "2/2 - 0s - loss: 2.2026e-05 - accuracy: 1.0000 - val_loss: 3.8651 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3245/4000\n",
      "2/2 - 0s - loss: 2.2004e-05 - accuracy: 1.0000 - val_loss: 3.8654 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3246/4000\n",
      "2/2 - 0s - loss: 2.1960e-05 - accuracy: 1.0000 - val_loss: 3.8658 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3247/4000\n",
      "2/2 - 0s - loss: 2.1938e-05 - accuracy: 1.0000 - val_loss: 3.8662 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3248/4000\n",
      "2/2 - 0s - loss: 2.1915e-05 - accuracy: 1.0000 - val_loss: 3.8665 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3249/4000\n",
      "2/2 - 0s - loss: 2.1887e-05 - accuracy: 1.0000 - val_loss: 3.8669 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 3250/4000\n",
      "2/2 - 0s - loss: 2.1853e-05 - accuracy: 1.0000 - val_loss: 3.8673 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3251/4000\n",
      "2/2 - 0s - loss: 2.1834e-05 - accuracy: 1.0000 - val_loss: 3.8676 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 3252/4000\n",
      "2/2 - 0s - loss: 2.1802e-05 - accuracy: 1.0000 - val_loss: 3.8681 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3253/4000\n",
      "2/2 - 0s - loss: 2.1781e-05 - accuracy: 1.0000 - val_loss: 3.8685 - val_accuracy: 0.7250 - 79ms/epoch - 39ms/step\n",
      "Epoch 3254/4000\n",
      "2/2 - 0s - loss: 2.1755e-05 - accuracy: 1.0000 - val_loss: 3.8689 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3255/4000\n",
      "2/2 - 0s - loss: 2.1723e-05 - accuracy: 1.0000 - val_loss: 3.8693 - val_accuracy: 0.7250 - 98ms/epoch - 49ms/step\n",
      "Epoch 3256/4000\n",
      "2/2 - 0s - loss: 2.1683e-05 - accuracy: 1.0000 - val_loss: 3.8697 - val_accuracy: 0.7250 - 97ms/epoch - 49ms/step\n",
      "Epoch 3257/4000\n",
      "2/2 - 0s - loss: 2.1666e-05 - accuracy: 1.0000 - val_loss: 3.8701 - val_accuracy: 0.7250 - 85ms/epoch - 42ms/step\n",
      "Epoch 3258/4000\n",
      "2/2 - 0s - loss: 2.1640e-05 - accuracy: 1.0000 - val_loss: 3.8706 - val_accuracy: 0.7250 - 90ms/epoch - 45ms/step\n",
      "Epoch 3259/4000\n",
      "2/2 - 0s - loss: 2.1602e-05 - accuracy: 1.0000 - val_loss: 3.8710 - val_accuracy: 0.7250 - 105ms/epoch - 52ms/step\n",
      "Epoch 3260/4000\n",
      "2/2 - 0s - loss: 2.1583e-05 - accuracy: 1.0000 - val_loss: 3.8714 - val_accuracy: 0.7250 - 80ms/epoch - 40ms/step\n",
      "Epoch 3261/4000\n",
      "2/2 - 0s - loss: 2.1570e-05 - accuracy: 1.0000 - val_loss: 3.8718 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3262/4000\n",
      "2/2 - 0s - loss: 2.1540e-05 - accuracy: 1.0000 - val_loss: 3.8721 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 3263/4000\n",
      "2/2 - 0s - loss: 2.1511e-05 - accuracy: 1.0000 - val_loss: 3.8725 - val_accuracy: 0.7250 - 99ms/epoch - 49ms/step\n",
      "Epoch 3264/4000\n",
      "2/2 - 0s - loss: 2.1493e-05 - accuracy: 1.0000 - val_loss: 3.8729 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 3265/4000\n",
      "2/2 - 0s - loss: 2.1447e-05 - accuracy: 1.0000 - val_loss: 3.8733 - val_accuracy: 0.7250 - 95ms/epoch - 48ms/step\n",
      "Epoch 3266/4000\n",
      "2/2 - 0s - loss: 2.1419e-05 - accuracy: 1.0000 - val_loss: 3.8737 - val_accuracy: 0.7250 - 100ms/epoch - 50ms/step\n",
      "Epoch 3267/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 2.1404e-05 - accuracy: 1.0000 - val_loss: 3.8740 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 3268/4000\n",
      "2/2 - 0s - loss: 2.1372e-05 - accuracy: 1.0000 - val_loss: 3.8744 - val_accuracy: 0.7250 - 85ms/epoch - 42ms/step\n",
      "Epoch 3269/4000\n",
      "2/2 - 0s - loss: 2.1334e-05 - accuracy: 1.0000 - val_loss: 3.8748 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 3270/4000\n",
      "2/2 - 0s - loss: 2.1306e-05 - accuracy: 1.0000 - val_loss: 3.8753 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3271/4000\n",
      "2/2 - 0s - loss: 2.1285e-05 - accuracy: 1.0000 - val_loss: 3.8757 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 3272/4000\n",
      "2/2 - 0s - loss: 2.1253e-05 - accuracy: 1.0000 - val_loss: 3.8761 - val_accuracy: 0.7250 - 82ms/epoch - 41ms/step\n",
      "Epoch 3273/4000\n",
      "2/2 - 0s - loss: 2.1227e-05 - accuracy: 1.0000 - val_loss: 3.8765 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3274/4000\n",
      "2/2 - 0s - loss: 2.1204e-05 - accuracy: 1.0000 - val_loss: 3.8770 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3275/4000\n",
      "2/2 - 0s - loss: 2.1174e-05 - accuracy: 1.0000 - val_loss: 3.8774 - val_accuracy: 0.7250 - 108ms/epoch - 54ms/step\n",
      "Epoch 3276/4000\n",
      "2/2 - 0s - loss: 2.1140e-05 - accuracy: 1.0000 - val_loss: 3.8779 - val_accuracy: 0.7250 - 79ms/epoch - 40ms/step\n",
      "Epoch 3277/4000\n",
      "2/2 - 0s - loss: 2.1123e-05 - accuracy: 1.0000 - val_loss: 3.8783 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3278/4000\n",
      "2/2 - 0s - loss: 2.1102e-05 - accuracy: 1.0000 - val_loss: 3.8787 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3279/4000\n",
      "2/2 - 0s - loss: 2.1068e-05 - accuracy: 1.0000 - val_loss: 3.8791 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3280/4000\n",
      "2/2 - 0s - loss: 2.1040e-05 - accuracy: 1.0000 - val_loss: 3.8795 - val_accuracy: 0.7250 - 88ms/epoch - 44ms/step\n",
      "Epoch 3281/4000\n",
      "2/2 - 0s - loss: 2.1029e-05 - accuracy: 1.0000 - val_loss: 3.8799 - val_accuracy: 0.7250 - 96ms/epoch - 48ms/step\n",
      "Epoch 3282/4000\n",
      "2/2 - 0s - loss: 2.1015e-05 - accuracy: 1.0000 - val_loss: 3.8802 - val_accuracy: 0.7250 - 103ms/epoch - 51ms/step\n",
      "Epoch 3283/4000\n",
      "2/2 - 0s - loss: 2.0972e-05 - accuracy: 1.0000 - val_loss: 3.8805 - val_accuracy: 0.7250 - 109ms/epoch - 54ms/step\n",
      "Epoch 3284/4000\n",
      "2/2 - 0s - loss: 2.0940e-05 - accuracy: 1.0000 - val_loss: 3.8808 - val_accuracy: 0.7250 - 85ms/epoch - 43ms/step\n",
      "Epoch 3285/4000\n",
      "2/2 - 0s - loss: 2.0906e-05 - accuracy: 1.0000 - val_loss: 3.8812 - val_accuracy: 0.7250 - 93ms/epoch - 46ms/step\n",
      "Epoch 3286/4000\n",
      "2/2 - 0s - loss: 2.0887e-05 - accuracy: 1.0000 - val_loss: 3.8816 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 3287/4000\n",
      "2/2 - 0s - loss: 2.0866e-05 - accuracy: 1.0000 - val_loss: 3.8821 - val_accuracy: 0.7250 - 90ms/epoch - 45ms/step\n",
      "Epoch 3288/4000\n",
      "2/2 - 0s - loss: 2.0838e-05 - accuracy: 1.0000 - val_loss: 3.8824 - val_accuracy: 0.7250 - 103ms/epoch - 51ms/step\n",
      "Epoch 3289/4000\n",
      "2/2 - 0s - loss: 2.0814e-05 - accuracy: 1.0000 - val_loss: 3.8827 - val_accuracy: 0.7250 - 87ms/epoch - 44ms/step\n",
      "Epoch 3290/4000\n",
      "2/2 - 0s - loss: 2.0793e-05 - accuracy: 1.0000 - val_loss: 3.8831 - val_accuracy: 0.7250 - 101ms/epoch - 51ms/step\n",
      "Epoch 3291/4000\n",
      "2/2 - 0s - loss: 2.0761e-05 - accuracy: 1.0000 - val_loss: 3.8834 - val_accuracy: 0.7250 - 98ms/epoch - 49ms/step\n",
      "Epoch 3292/4000\n",
      "2/2 - 0s - loss: 2.0729e-05 - accuracy: 1.0000 - val_loss: 3.8838 - val_accuracy: 0.7250 - 95ms/epoch - 48ms/step\n",
      "Epoch 3293/4000\n",
      "2/2 - 0s - loss: 2.0704e-05 - accuracy: 1.0000 - val_loss: 3.8842 - val_accuracy: 0.7250 - 111ms/epoch - 55ms/step\n",
      "Epoch 3294/4000\n",
      "2/2 - 0s - loss: 2.0685e-05 - accuracy: 1.0000 - val_loss: 3.8846 - val_accuracy: 0.7250 - 105ms/epoch - 53ms/step\n",
      "Epoch 3295/4000\n",
      "2/2 - 0s - loss: 2.0653e-05 - accuracy: 1.0000 - val_loss: 3.8850 - val_accuracy: 0.7250 - 90ms/epoch - 45ms/step\n",
      "Epoch 3296/4000\n",
      "2/2 - 0s - loss: 2.0629e-05 - accuracy: 1.0000 - val_loss: 3.8853 - val_accuracy: 0.7250 - 111ms/epoch - 56ms/step\n",
      "Epoch 3297/4000\n",
      "2/2 - 0s - loss: 2.0608e-05 - accuracy: 1.0000 - val_loss: 3.8858 - val_accuracy: 0.7250 - 94ms/epoch - 47ms/step\n",
      "Epoch 3298/4000\n",
      "2/2 - 0s - loss: 2.0582e-05 - accuracy: 1.0000 - val_loss: 3.8863 - val_accuracy: 0.7250 - 85ms/epoch - 42ms/step\n",
      "Epoch 3299/4000\n",
      "2/2 - 0s - loss: 2.0548e-05 - accuracy: 1.0000 - val_loss: 3.8866 - val_accuracy: 0.7250 - 83ms/epoch - 42ms/step\n",
      "Epoch 3300/4000\n",
      "2/2 - 0s - loss: 2.0521e-05 - accuracy: 1.0000 - val_loss: 3.8870 - val_accuracy: 0.7250 - 106ms/epoch - 53ms/step\n",
      "Epoch 3301/4000\n",
      "2/2 - 0s - loss: 2.0504e-05 - accuracy: 1.0000 - val_loss: 3.8874 - val_accuracy: 0.7250 - 97ms/epoch - 48ms/step\n",
      "Epoch 3302/4000\n",
      "2/2 - 0s - loss: 2.0472e-05 - accuracy: 1.0000 - val_loss: 3.8878 - val_accuracy: 0.7250 - 93ms/epoch - 47ms/step\n",
      "Epoch 3303/4000\n",
      "2/2 - 0s - loss: 2.0446e-05 - accuracy: 1.0000 - val_loss: 3.8882 - val_accuracy: 0.7250 - 112ms/epoch - 56ms/step\n",
      "Epoch 3304/4000\n",
      "2/2 - 0s - loss: 2.0425e-05 - accuracy: 1.0000 - val_loss: 3.8885 - val_accuracy: 0.7250 - 94ms/epoch - 47ms/step\n",
      "Epoch 3305/4000\n",
      "2/2 - 0s - loss: 2.0395e-05 - accuracy: 1.0000 - val_loss: 3.8890 - val_accuracy: 0.7250 - 96ms/epoch - 48ms/step\n",
      "Epoch 3306/4000\n",
      "2/2 - 0s - loss: 2.0367e-05 - accuracy: 1.0000 - val_loss: 3.8894 - val_accuracy: 0.7250 - 124ms/epoch - 62ms/step\n",
      "Epoch 3307/4000\n",
      "2/2 - 0s - loss: 2.0335e-05 - accuracy: 1.0000 - val_loss: 3.8897 - val_accuracy: 0.7250 - 94ms/epoch - 47ms/step\n",
      "Epoch 3308/4000\n",
      "2/2 - 0s - loss: 2.0308e-05 - accuracy: 1.0000 - val_loss: 3.8901 - val_accuracy: 0.7250 - 94ms/epoch - 47ms/step\n",
      "Epoch 3309/4000\n",
      "2/2 - 0s - loss: 2.0289e-05 - accuracy: 1.0000 - val_loss: 3.8905 - val_accuracy: 0.7250 - 114ms/epoch - 57ms/step\n",
      "Epoch 3310/4000\n",
      "2/2 - 0s - loss: 2.0274e-05 - accuracy: 1.0000 - val_loss: 3.8909 - val_accuracy: 0.7250 - 318ms/epoch - 159ms/step\n",
      "Epoch 3311/4000\n",
      "2/2 - 0s - loss: 2.0238e-05 - accuracy: 1.0000 - val_loss: 3.8913 - val_accuracy: 0.7250 - 113ms/epoch - 56ms/step\n",
      "Epoch 3312/4000\n",
      "2/2 - 0s - loss: 2.0216e-05 - accuracy: 1.0000 - val_loss: 3.8916 - val_accuracy: 0.7250 - 85ms/epoch - 43ms/step\n",
      "Epoch 3313/4000\n",
      "2/2 - 0s - loss: 2.0186e-05 - accuracy: 1.0000 - val_loss: 3.8920 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 3314/4000\n",
      "2/2 - 0s - loss: 2.0174e-05 - accuracy: 1.0000 - val_loss: 3.8923 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 3315/4000\n",
      "2/2 - 0s - loss: 2.0146e-05 - accuracy: 1.0000 - val_loss: 3.8927 - val_accuracy: 0.7250 - 107ms/epoch - 53ms/step\n",
      "Epoch 3316/4000\n",
      "2/2 - 0s - loss: 2.0114e-05 - accuracy: 1.0000 - val_loss: 3.8931 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 3317/4000\n",
      "2/2 - 0s - loss: 2.0086e-05 - accuracy: 1.0000 - val_loss: 3.8935 - val_accuracy: 0.7250 - 94ms/epoch - 47ms/step\n",
      "Epoch 3318/4000\n",
      "2/2 - 0s - loss: 2.0063e-05 - accuracy: 1.0000 - val_loss: 3.8938 - val_accuracy: 0.7250 - 108ms/epoch - 54ms/step\n",
      "Epoch 3319/4000\n",
      "2/2 - 0s - loss: 2.0046e-05 - accuracy: 1.0000 - val_loss: 3.8942 - val_accuracy: 0.7250 - 88ms/epoch - 44ms/step\n",
      "Epoch 3320/4000\n",
      "2/2 - 0s - loss: 2.0016e-05 - accuracy: 1.0000 - val_loss: 3.8945 - val_accuracy: 0.7250 - 96ms/epoch - 48ms/step\n",
      "Epoch 3321/4000\n",
      "2/2 - 0s - loss: 2.0001e-05 - accuracy: 1.0000 - val_loss: 3.8948 - val_accuracy: 0.7250 - 98ms/epoch - 49ms/step\n",
      "Epoch 3322/4000\n",
      "2/2 - 0s - loss: 1.9974e-05 - accuracy: 1.0000 - val_loss: 3.8952 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3323/4000\n",
      "2/2 - 0s - loss: 1.9944e-05 - accuracy: 1.0000 - val_loss: 3.8956 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3324/4000\n",
      "2/2 - 0s - loss: 1.9920e-05 - accuracy: 1.0000 - val_loss: 3.8960 - val_accuracy: 0.7250 - 75ms/epoch - 38ms/step\n",
      "Epoch 3325/4000\n",
      "2/2 - 0s - loss: 1.9891e-05 - accuracy: 1.0000 - val_loss: 3.8963 - val_accuracy: 0.7250 - 77ms/epoch - 39ms/step\n",
      "Epoch 3326/4000\n",
      "2/2 - 0s - loss: 1.9876e-05 - accuracy: 1.0000 - val_loss: 3.8967 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3327/4000\n",
      "2/2 - 0s - loss: 1.9852e-05 - accuracy: 1.0000 - val_loss: 3.8970 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3328/4000\n",
      "2/2 - 0s - loss: 1.9829e-05 - accuracy: 1.0000 - val_loss: 3.8973 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3329/4000\n",
      "2/2 - 0s - loss: 1.9786e-05 - accuracy: 1.0000 - val_loss: 3.8977 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 3330/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.9765e-05 - accuracy: 1.0000 - val_loss: 3.8981 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3331/4000\n",
      "2/2 - 0s - loss: 1.9746e-05 - accuracy: 1.0000 - val_loss: 3.8984 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3332/4000\n",
      "2/2 - 0s - loss: 1.9725e-05 - accuracy: 1.0000 - val_loss: 3.8988 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3333/4000\n",
      "2/2 - 0s - loss: 1.9697e-05 - accuracy: 1.0000 - val_loss: 3.8992 - val_accuracy: 0.7250 - 87ms/epoch - 43ms/step\n",
      "Epoch 3334/4000\n",
      "2/2 - 0s - loss: 1.9673e-05 - accuracy: 1.0000 - val_loss: 3.8997 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3335/4000\n",
      "2/2 - 0s - loss: 1.9648e-05 - accuracy: 1.0000 - val_loss: 3.9001 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3336/4000\n",
      "2/2 - 0s - loss: 1.9629e-05 - accuracy: 1.0000 - val_loss: 3.9004 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3337/4000\n",
      "2/2 - 0s - loss: 1.9599e-05 - accuracy: 1.0000 - val_loss: 3.9008 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3338/4000\n",
      "2/2 - 0s - loss: 1.9576e-05 - accuracy: 1.0000 - val_loss: 3.9012 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3339/4000\n",
      "2/2 - 0s - loss: 1.9546e-05 - accuracy: 1.0000 - val_loss: 3.9015 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3340/4000\n",
      "2/2 - 0s - loss: 1.9527e-05 - accuracy: 1.0000 - val_loss: 3.9020 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3341/4000\n",
      "2/2 - 0s - loss: 1.9501e-05 - accuracy: 1.0000 - val_loss: 3.9023 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3342/4000\n",
      "2/2 - 0s - loss: 1.9473e-05 - accuracy: 1.0000 - val_loss: 3.9027 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3343/4000\n",
      "2/2 - 0s - loss: 1.9452e-05 - accuracy: 1.0000 - val_loss: 3.9031 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3344/4000\n",
      "2/2 - 0s - loss: 1.9424e-05 - accuracy: 1.0000 - val_loss: 3.9034 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3345/4000\n",
      "2/2 - 0s - loss: 1.9395e-05 - accuracy: 1.0000 - val_loss: 3.9038 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3346/4000\n",
      "2/2 - 0s - loss: 1.9382e-05 - accuracy: 1.0000 - val_loss: 3.9042 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3347/4000\n",
      "2/2 - 0s - loss: 1.9352e-05 - accuracy: 1.0000 - val_loss: 3.9045 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3348/4000\n",
      "2/2 - 0s - loss: 1.9329e-05 - accuracy: 1.0000 - val_loss: 3.9049 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3349/4000\n",
      "2/2 - 0s - loss: 1.9303e-05 - accuracy: 1.0000 - val_loss: 3.9052 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3350/4000\n",
      "2/2 - 0s - loss: 1.9286e-05 - accuracy: 1.0000 - val_loss: 3.9056 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3351/4000\n",
      "2/2 - 0s - loss: 1.9250e-05 - accuracy: 1.0000 - val_loss: 3.9059 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3352/4000\n",
      "2/2 - 0s - loss: 1.9237e-05 - accuracy: 1.0000 - val_loss: 3.9062 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3353/4000\n",
      "2/2 - 0s - loss: 1.9214e-05 - accuracy: 1.0000 - val_loss: 3.9064 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3354/4000\n",
      "2/2 - 0s - loss: 1.9186e-05 - accuracy: 1.0000 - val_loss: 3.9069 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3355/4000\n",
      "2/2 - 0s - loss: 1.9163e-05 - accuracy: 1.0000 - val_loss: 3.9073 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3356/4000\n",
      "2/2 - 0s - loss: 1.9143e-05 - accuracy: 1.0000 - val_loss: 3.9076 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3357/4000\n",
      "2/2 - 0s - loss: 1.9105e-05 - accuracy: 1.0000 - val_loss: 3.9080 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3358/4000\n",
      "2/2 - 0s - loss: 1.9082e-05 - accuracy: 1.0000 - val_loss: 3.9083 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3359/4000\n",
      "2/2 - 0s - loss: 1.9060e-05 - accuracy: 1.0000 - val_loss: 3.9087 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3360/4000\n",
      "2/2 - 0s - loss: 1.9033e-05 - accuracy: 1.0000 - val_loss: 3.9091 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3361/4000\n",
      "2/2 - 0s - loss: 1.9005e-05 - accuracy: 1.0000 - val_loss: 3.9095 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3362/4000\n",
      "2/2 - 0s - loss: 1.8990e-05 - accuracy: 1.0000 - val_loss: 3.9099 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3363/4000\n",
      "2/2 - 0s - loss: 1.8973e-05 - accuracy: 1.0000 - val_loss: 3.9103 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3364/4000\n",
      "2/2 - 0s - loss: 1.8960e-05 - accuracy: 1.0000 - val_loss: 3.9107 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3365/4000\n",
      "2/2 - 0s - loss: 1.8926e-05 - accuracy: 1.0000 - val_loss: 3.9111 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3366/4000\n",
      "2/2 - 0s - loss: 1.8905e-05 - accuracy: 1.0000 - val_loss: 3.9116 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3367/4000\n",
      "2/2 - 0s - loss: 1.8886e-05 - accuracy: 1.0000 - val_loss: 3.9120 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3368/4000\n",
      "2/2 - 0s - loss: 1.8862e-05 - accuracy: 1.0000 - val_loss: 3.9124 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3369/4000\n",
      "2/2 - 0s - loss: 1.8845e-05 - accuracy: 1.0000 - val_loss: 3.9128 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3370/4000\n",
      "2/2 - 0s - loss: 1.8818e-05 - accuracy: 1.0000 - val_loss: 3.9131 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3371/4000\n",
      "2/2 - 0s - loss: 1.8792e-05 - accuracy: 1.0000 - val_loss: 3.9136 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3372/4000\n",
      "2/2 - 0s - loss: 1.8769e-05 - accuracy: 1.0000 - val_loss: 3.9140 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3373/4000\n",
      "2/2 - 0s - loss: 1.8748e-05 - accuracy: 1.0000 - val_loss: 3.9144 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3374/4000\n",
      "2/2 - 0s - loss: 1.8728e-05 - accuracy: 1.0000 - val_loss: 3.9147 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3375/4000\n",
      "2/2 - 0s - loss: 1.8705e-05 - accuracy: 1.0000 - val_loss: 3.9151 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3376/4000\n",
      "2/2 - 0s - loss: 1.8679e-05 - accuracy: 1.0000 - val_loss: 3.9155 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3377/4000\n",
      "2/2 - 0s - loss: 1.8645e-05 - accuracy: 1.0000 - val_loss: 3.9160 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3378/4000\n",
      "2/2 - 0s - loss: 1.8622e-05 - accuracy: 1.0000 - val_loss: 3.9163 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3379/4000\n",
      "2/2 - 0s - loss: 1.8599e-05 - accuracy: 1.0000 - val_loss: 3.9166 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3380/4000\n",
      "2/2 - 0s - loss: 1.8586e-05 - accuracy: 1.0000 - val_loss: 3.9169 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3381/4000\n",
      "2/2 - 0s - loss: 1.8550e-05 - accuracy: 1.0000 - val_loss: 3.9173 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3382/4000\n",
      "2/2 - 0s - loss: 1.8535e-05 - accuracy: 1.0000 - val_loss: 3.9177 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3383/4000\n",
      "2/2 - 0s - loss: 1.8513e-05 - accuracy: 1.0000 - val_loss: 3.9180 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3384/4000\n",
      "2/2 - 0s - loss: 1.8486e-05 - accuracy: 1.0000 - val_loss: 3.9183 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3385/4000\n",
      "2/2 - 0s - loss: 1.8454e-05 - accuracy: 1.0000 - val_loss: 3.9188 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3386/4000\n",
      "2/2 - 0s - loss: 1.8441e-05 - accuracy: 1.0000 - val_loss: 3.9192 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3387/4000\n",
      "2/2 - 0s - loss: 1.8415e-05 - accuracy: 1.0000 - val_loss: 3.9196 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3388/4000\n",
      "2/2 - 0s - loss: 1.8390e-05 - accuracy: 1.0000 - val_loss: 3.9200 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3389/4000\n",
      "2/2 - 0s - loss: 1.8371e-05 - accuracy: 1.0000 - val_loss: 3.9203 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3390/4000\n",
      "2/2 - 0s - loss: 1.8362e-05 - accuracy: 1.0000 - val_loss: 3.9206 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3391/4000\n",
      "2/2 - 0s - loss: 1.8330e-05 - accuracy: 1.0000 - val_loss: 3.9210 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3392/4000\n",
      "2/2 - 0s - loss: 1.8318e-05 - accuracy: 1.0000 - val_loss: 3.9214 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3393/4000\n",
      "2/2 - 0s - loss: 1.8288e-05 - accuracy: 1.0000 - val_loss: 3.9218 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3394/4000\n",
      "2/2 - 0s - loss: 1.8264e-05 - accuracy: 1.0000 - val_loss: 3.9222 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3395/4000\n",
      "2/2 - 0s - loss: 1.8241e-05 - accuracy: 1.0000 - val_loss: 3.9225 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3396/4000\n",
      "2/2 - 0s - loss: 1.8213e-05 - accuracy: 1.0000 - val_loss: 3.9229 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3397/4000\n",
      "2/2 - 0s - loss: 1.8192e-05 - accuracy: 1.0000 - val_loss: 3.9232 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3398/4000\n",
      "2/2 - 0s - loss: 1.8171e-05 - accuracy: 1.0000 - val_loss: 3.9235 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3399/4000\n",
      "2/2 - 0s - loss: 1.8147e-05 - accuracy: 1.0000 - val_loss: 3.9238 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3400/4000\n",
      "2/2 - 0s - loss: 1.8124e-05 - accuracy: 1.0000 - val_loss: 3.9242 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3401/4000\n",
      "2/2 - 0s - loss: 1.8107e-05 - accuracy: 1.0000 - val_loss: 3.9246 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3402/4000\n",
      "2/2 - 0s - loss: 1.8090e-05 - accuracy: 1.0000 - val_loss: 3.9249 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3403/4000\n",
      "2/2 - 0s - loss: 1.8064e-05 - accuracy: 1.0000 - val_loss: 3.9252 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3404/4000\n",
      "2/2 - 0s - loss: 1.8037e-05 - accuracy: 1.0000 - val_loss: 3.9256 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3405/4000\n",
      "2/2 - 0s - loss: 1.8015e-05 - accuracy: 1.0000 - val_loss: 3.9260 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3406/4000\n",
      "2/2 - 0s - loss: 1.7996e-05 - accuracy: 1.0000 - val_loss: 3.9263 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3407/4000\n",
      "2/2 - 0s - loss: 1.7964e-05 - accuracy: 1.0000 - val_loss: 3.9267 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3408/4000\n",
      "2/2 - 0s - loss: 1.7941e-05 - accuracy: 1.0000 - val_loss: 3.9271 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3409/4000\n",
      "2/2 - 0s - loss: 1.7922e-05 - accuracy: 1.0000 - val_loss: 3.9275 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3410/4000\n",
      "2/2 - 0s - loss: 1.7907e-05 - accuracy: 1.0000 - val_loss: 3.9279 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3411/4000\n",
      "2/2 - 0s - loss: 1.7881e-05 - accuracy: 1.0000 - val_loss: 3.9283 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3412/4000\n",
      "2/2 - 0s - loss: 1.7866e-05 - accuracy: 1.0000 - val_loss: 3.9286 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3413/4000\n",
      "2/2 - 0s - loss: 1.7843e-05 - accuracy: 1.0000 - val_loss: 3.9290 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3414/4000\n",
      "2/2 - 0s - loss: 1.7824e-05 - accuracy: 1.0000 - val_loss: 3.9294 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3415/4000\n",
      "2/2 - 0s - loss: 1.7796e-05 - accuracy: 1.0000 - val_loss: 3.9298 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3416/4000\n",
      "2/2 - 0s - loss: 1.7777e-05 - accuracy: 1.0000 - val_loss: 3.9302 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3417/4000\n",
      "2/2 - 0s - loss: 1.7749e-05 - accuracy: 1.0000 - val_loss: 3.9305 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3418/4000\n",
      "2/2 - 0s - loss: 1.7728e-05 - accuracy: 1.0000 - val_loss: 3.9308 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3419/4000\n",
      "2/2 - 0s - loss: 1.7700e-05 - accuracy: 1.0000 - val_loss: 3.9311 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3420/4000\n",
      "2/2 - 0s - loss: 1.7679e-05 - accuracy: 1.0000 - val_loss: 3.9315 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3421/4000\n",
      "2/2 - 0s - loss: 1.7656e-05 - accuracy: 1.0000 - val_loss: 3.9318 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3422/4000\n",
      "2/2 - 0s - loss: 1.7638e-05 - accuracy: 1.0000 - val_loss: 3.9321 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3423/4000\n",
      "2/2 - 0s - loss: 1.7617e-05 - accuracy: 1.0000 - val_loss: 3.9325 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3424/4000\n",
      "2/2 - 0s - loss: 1.7594e-05 - accuracy: 1.0000 - val_loss: 3.9328 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3425/4000\n",
      "2/2 - 0s - loss: 1.7577e-05 - accuracy: 1.0000 - val_loss: 3.9332 - val_accuracy: 0.7250 - 45ms/epoch - 23ms/step\n",
      "Epoch 3426/4000\n",
      "2/2 - 0s - loss: 1.7555e-05 - accuracy: 1.0000 - val_loss: 3.9335 - val_accuracy: 0.7250 - 91ms/epoch - 46ms/step\n",
      "Epoch 3427/4000\n",
      "2/2 - 0s - loss: 1.7534e-05 - accuracy: 1.0000 - val_loss: 3.9340 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3428/4000\n",
      "2/2 - 0s - loss: 1.7515e-05 - accuracy: 1.0000 - val_loss: 3.9343 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3429/4000\n",
      "2/2 - 0s - loss: 1.7492e-05 - accuracy: 1.0000 - val_loss: 3.9347 - val_accuracy: 0.7250 - 104ms/epoch - 52ms/step\n",
      "Epoch 3430/4000\n",
      "2/2 - 0s - loss: 1.7475e-05 - accuracy: 1.0000 - val_loss: 3.9351 - val_accuracy: 0.7250 - 110ms/epoch - 55ms/step\n",
      "Epoch 3431/4000\n",
      "2/2 - 0s - loss: 1.7451e-05 - accuracy: 1.0000 - val_loss: 3.9355 - val_accuracy: 0.7250 - 87ms/epoch - 43ms/step\n",
      "Epoch 3432/4000\n",
      "2/2 - 0s - loss: 1.7415e-05 - accuracy: 1.0000 - val_loss: 3.9359 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 3433/4000\n",
      "2/2 - 0s - loss: 1.7392e-05 - accuracy: 1.0000 - val_loss: 3.9363 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3434/4000\n",
      "2/2 - 0s - loss: 1.7377e-05 - accuracy: 1.0000 - val_loss: 3.9367 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 3435/4000\n",
      "2/2 - 0s - loss: 1.7349e-05 - accuracy: 1.0000 - val_loss: 3.9371 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3436/4000\n",
      "2/2 - 0s - loss: 1.7326e-05 - accuracy: 1.0000 - val_loss: 3.9376 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 3437/4000\n",
      "2/2 - 0s - loss: 1.7306e-05 - accuracy: 1.0000 - val_loss: 3.9379 - val_accuracy: 0.7250 - 82ms/epoch - 41ms/step\n",
      "Epoch 3438/4000\n",
      "2/2 - 0s - loss: 1.7285e-05 - accuracy: 1.0000 - val_loss: 3.9383 - val_accuracy: 0.7250 - 82ms/epoch - 41ms/step\n",
      "Epoch 3439/4000\n",
      "2/2 - 0s - loss: 1.7266e-05 - accuracy: 1.0000 - val_loss: 3.9388 - val_accuracy: 0.7250 - 86ms/epoch - 43ms/step\n",
      "Epoch 3440/4000\n",
      "2/2 - 0s - loss: 1.7251e-05 - accuracy: 1.0000 - val_loss: 3.9392 - val_accuracy: 0.7250 - 106ms/epoch - 53ms/step\n",
      "Epoch 3441/4000\n",
      "2/2 - 0s - loss: 1.7228e-05 - accuracy: 1.0000 - val_loss: 3.9395 - val_accuracy: 0.7250 - 121ms/epoch - 61ms/step\n",
      "Epoch 3442/4000\n",
      "2/2 - 0s - loss: 1.7202e-05 - accuracy: 1.0000 - val_loss: 3.9399 - val_accuracy: 0.7250 - 116ms/epoch - 58ms/step\n",
      "Epoch 3443/4000\n",
      "2/2 - 0s - loss: 1.7183e-05 - accuracy: 1.0000 - val_loss: 3.9403 - val_accuracy: 0.7250 - 87ms/epoch - 43ms/step\n",
      "Epoch 3444/4000\n",
      "2/2 - 0s - loss: 1.7164e-05 - accuracy: 1.0000 - val_loss: 3.9407 - val_accuracy: 0.7250 - 85ms/epoch - 42ms/step\n",
      "Epoch 3445/4000\n",
      "2/2 - 0s - loss: 1.7136e-05 - accuracy: 1.0000 - val_loss: 3.9411 - val_accuracy: 0.7250 - 82ms/epoch - 41ms/step\n",
      "Epoch 3446/4000\n",
      "2/2 - 0s - loss: 1.7125e-05 - accuracy: 1.0000 - val_loss: 3.9414 - val_accuracy: 0.7250 - 82ms/epoch - 41ms/step\n",
      "Epoch 3447/4000\n",
      "2/2 - 0s - loss: 1.7096e-05 - accuracy: 1.0000 - val_loss: 3.9417 - val_accuracy: 0.7250 - 107ms/epoch - 54ms/step\n",
      "Epoch 3448/4000\n",
      "2/2 - 0s - loss: 1.7083e-05 - accuracy: 1.0000 - val_loss: 3.9421 - val_accuracy: 0.7250 - 98ms/epoch - 49ms/step\n",
      "Epoch 3449/4000\n",
      "2/2 - 0s - loss: 1.7055e-05 - accuracy: 1.0000 - val_loss: 3.9425 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 3450/4000\n",
      "2/2 - 0s - loss: 1.7036e-05 - accuracy: 1.0000 - val_loss: 3.9429 - val_accuracy: 0.7250 - 97ms/epoch - 48ms/step\n",
      "Epoch 3451/4000\n",
      "2/2 - 0s - loss: 1.7013e-05 - accuracy: 1.0000 - val_loss: 3.9433 - val_accuracy: 0.7250 - 84ms/epoch - 42ms/step\n",
      "Epoch 3452/4000\n",
      "2/2 - 0s - loss: 1.6993e-05 - accuracy: 1.0000 - val_loss: 3.9437 - val_accuracy: 0.7250 - 108ms/epoch - 54ms/step\n",
      "Epoch 3453/4000\n",
      "2/2 - 0s - loss: 1.6981e-05 - accuracy: 1.0000 - val_loss: 3.9441 - val_accuracy: 0.7250 - 87ms/epoch - 43ms/step\n",
      "Epoch 3454/4000\n",
      "2/2 - 0s - loss: 1.6957e-05 - accuracy: 1.0000 - val_loss: 3.9445 - val_accuracy: 0.7250 - 99ms/epoch - 49ms/step\n",
      "Epoch 3455/4000\n",
      "2/2 - 0s - loss: 1.6936e-05 - accuracy: 1.0000 - val_loss: 3.9448 - val_accuracy: 0.7250 - 93ms/epoch - 46ms/step\n",
      "Epoch 3456/4000\n",
      "2/2 - 0s - loss: 1.6908e-05 - accuracy: 1.0000 - val_loss: 3.9453 - val_accuracy: 0.7250 - 82ms/epoch - 41ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3457/4000\n",
      "2/2 - 0s - loss: 1.6891e-05 - accuracy: 1.0000 - val_loss: 3.9457 - val_accuracy: 0.7250 - 88ms/epoch - 44ms/step\n",
      "Epoch 3458/4000\n",
      "2/2 - 0s - loss: 1.6885e-05 - accuracy: 1.0000 - val_loss: 3.9461 - val_accuracy: 0.7250 - 114ms/epoch - 57ms/step\n",
      "Epoch 3459/4000\n",
      "2/2 - 0s - loss: 1.6859e-05 - accuracy: 1.0000 - val_loss: 3.9465 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 3460/4000\n",
      "2/2 - 0s - loss: 1.6838e-05 - accuracy: 1.0000 - val_loss: 3.9468 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 3461/4000\n",
      "2/2 - 0s - loss: 1.6817e-05 - accuracy: 1.0000 - val_loss: 3.9471 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3462/4000\n",
      "2/2 - 0s - loss: 1.6789e-05 - accuracy: 1.0000 - val_loss: 3.9475 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3463/4000\n",
      "2/2 - 0s - loss: 1.6772e-05 - accuracy: 1.0000 - val_loss: 3.9479 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3464/4000\n",
      "2/2 - 0s - loss: 1.6749e-05 - accuracy: 1.0000 - val_loss: 3.9483 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 3465/4000\n",
      "2/2 - 0s - loss: 1.6727e-05 - accuracy: 1.0000 - val_loss: 3.9486 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3466/4000\n",
      "2/2 - 0s - loss: 1.6710e-05 - accuracy: 1.0000 - val_loss: 3.9490 - val_accuracy: 0.7250 - 82ms/epoch - 41ms/step\n",
      "Epoch 3467/4000\n",
      "2/2 - 0s - loss: 1.6691e-05 - accuracy: 1.0000 - val_loss: 3.9493 - val_accuracy: 0.7250 - 97ms/epoch - 49ms/step\n",
      "Epoch 3468/4000\n",
      "2/2 - 0s - loss: 1.6670e-05 - accuracy: 1.0000 - val_loss: 3.9497 - val_accuracy: 0.7250 - 104ms/epoch - 52ms/step\n",
      "Epoch 3469/4000\n",
      "2/2 - 0s - loss: 1.6649e-05 - accuracy: 1.0000 - val_loss: 3.9501 - val_accuracy: 0.7250 - 90ms/epoch - 45ms/step\n",
      "Epoch 3470/4000\n",
      "2/2 - 0s - loss: 1.6627e-05 - accuracy: 1.0000 - val_loss: 3.9505 - val_accuracy: 0.7250 - 93ms/epoch - 47ms/step\n",
      "Epoch 3471/4000\n",
      "2/2 - 0s - loss: 1.6608e-05 - accuracy: 1.0000 - val_loss: 3.9508 - val_accuracy: 0.7250 - 99ms/epoch - 50ms/step\n",
      "Epoch 3472/4000\n",
      "2/2 - 0s - loss: 1.6585e-05 - accuracy: 1.0000 - val_loss: 3.9513 - val_accuracy: 0.7250 - 108ms/epoch - 54ms/step\n",
      "Epoch 3473/4000\n",
      "2/2 - 0s - loss: 1.6572e-05 - accuracy: 1.0000 - val_loss: 3.9517 - val_accuracy: 0.7250 - 78ms/epoch - 39ms/step\n",
      "Epoch 3474/4000\n",
      "2/2 - 0s - loss: 1.6551e-05 - accuracy: 1.0000 - val_loss: 3.9521 - val_accuracy: 0.7250 - 98ms/epoch - 49ms/step\n",
      "Epoch 3475/4000\n",
      "2/2 - 0s - loss: 1.6525e-05 - accuracy: 1.0000 - val_loss: 3.9525 - val_accuracy: 0.7250 - 110ms/epoch - 55ms/step\n",
      "Epoch 3476/4000\n",
      "2/2 - 0s - loss: 1.6504e-05 - accuracy: 1.0000 - val_loss: 3.9528 - val_accuracy: 0.7250 - 122ms/epoch - 61ms/step\n",
      "Epoch 3477/4000\n",
      "2/2 - 0s - loss: 1.6474e-05 - accuracy: 1.0000 - val_loss: 3.9532 - val_accuracy: 0.7250 - 94ms/epoch - 47ms/step\n",
      "Epoch 3478/4000\n",
      "2/2 - 0s - loss: 1.6461e-05 - accuracy: 1.0000 - val_loss: 3.9536 - val_accuracy: 0.7250 - 101ms/epoch - 50ms/step\n",
      "Epoch 3479/4000\n",
      "2/2 - 0s - loss: 1.6446e-05 - accuracy: 1.0000 - val_loss: 3.9540 - val_accuracy: 0.7250 - 116ms/epoch - 58ms/step\n",
      "Epoch 3480/4000\n",
      "2/2 - 0s - loss: 1.6421e-05 - accuracy: 1.0000 - val_loss: 3.9545 - val_accuracy: 0.7250 - 98ms/epoch - 49ms/step\n",
      "Epoch 3481/4000\n",
      "2/2 - 0s - loss: 1.6393e-05 - accuracy: 1.0000 - val_loss: 3.9548 - val_accuracy: 0.7250 - 100ms/epoch - 50ms/step\n",
      "Epoch 3482/4000\n",
      "2/2 - 0s - loss: 1.6378e-05 - accuracy: 1.0000 - val_loss: 3.9552 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3483/4000\n",
      "2/2 - 0s - loss: 1.6359e-05 - accuracy: 1.0000 - val_loss: 3.9555 - val_accuracy: 0.7250 - 86ms/epoch - 43ms/step\n",
      "Epoch 3484/4000\n",
      "2/2 - 0s - loss: 1.6338e-05 - accuracy: 1.0000 - val_loss: 3.9560 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3485/4000\n",
      "2/2 - 0s - loss: 1.6310e-05 - accuracy: 1.0000 - val_loss: 3.9563 - val_accuracy: 0.7250 - 92ms/epoch - 46ms/step\n",
      "Epoch 3486/4000\n",
      "2/2 - 0s - loss: 1.6297e-05 - accuracy: 1.0000 - val_loss: 3.9568 - val_accuracy: 0.7250 - 86ms/epoch - 43ms/step\n",
      "Epoch 3487/4000\n",
      "2/2 - 0s - loss: 1.6280e-05 - accuracy: 1.0000 - val_loss: 3.9571 - val_accuracy: 0.7250 - 80ms/epoch - 40ms/step\n",
      "Epoch 3488/4000\n",
      "2/2 - 0s - loss: 1.6263e-05 - accuracy: 1.0000 - val_loss: 3.9575 - val_accuracy: 0.7250 - 75ms/epoch - 37ms/step\n",
      "Epoch 3489/4000\n",
      "2/2 - 0s - loss: 1.6251e-05 - accuracy: 1.0000 - val_loss: 3.9579 - val_accuracy: 0.7250 - 88ms/epoch - 44ms/step\n",
      "Epoch 3490/4000\n",
      "2/2 - 0s - loss: 1.6234e-05 - accuracy: 1.0000 - val_loss: 3.9583 - val_accuracy: 0.7250 - 90ms/epoch - 45ms/step\n",
      "Epoch 3491/4000\n",
      "2/2 - 0s - loss: 1.6199e-05 - accuracy: 1.0000 - val_loss: 3.9588 - val_accuracy: 0.7250 - 108ms/epoch - 54ms/step\n",
      "Epoch 3492/4000\n",
      "2/2 - 0s - loss: 1.6176e-05 - accuracy: 1.0000 - val_loss: 3.9592 - val_accuracy: 0.7250 - 115ms/epoch - 57ms/step\n",
      "Epoch 3493/4000\n",
      "2/2 - 0s - loss: 1.6153e-05 - accuracy: 1.0000 - val_loss: 3.9595 - val_accuracy: 0.7250 - 88ms/epoch - 44ms/step\n",
      "Epoch 3494/4000\n",
      "2/2 - 0s - loss: 1.6136e-05 - accuracy: 1.0000 - val_loss: 3.9599 - val_accuracy: 0.7250 - 76ms/epoch - 38ms/step\n",
      "Epoch 3495/4000\n",
      "2/2 - 0s - loss: 1.6114e-05 - accuracy: 1.0000 - val_loss: 3.9602 - val_accuracy: 0.7250 - 82ms/epoch - 41ms/step\n",
      "Epoch 3496/4000\n",
      "2/2 - 0s - loss: 1.6093e-05 - accuracy: 1.0000 - val_loss: 3.9606 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3497/4000\n",
      "2/2 - 0s - loss: 1.6076e-05 - accuracy: 1.0000 - val_loss: 3.9610 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3498/4000\n",
      "2/2 - 0s - loss: 1.6061e-05 - accuracy: 1.0000 - val_loss: 3.9613 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3499/4000\n",
      "2/2 - 0s - loss: 1.6042e-05 - accuracy: 1.0000 - val_loss: 3.9617 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3500/4000\n",
      "2/2 - 0s - loss: 1.6031e-05 - accuracy: 1.0000 - val_loss: 3.9620 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3501/4000\n",
      "2/2 - 0s - loss: 1.6010e-05 - accuracy: 1.0000 - val_loss: 3.9624 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3502/4000\n",
      "2/2 - 0s - loss: 1.5991e-05 - accuracy: 1.0000 - val_loss: 3.9628 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3503/4000\n",
      "2/2 - 0s - loss: 1.5978e-05 - accuracy: 1.0000 - val_loss: 3.9633 - val_accuracy: 0.7250 - 73ms/epoch - 37ms/step\n",
      "Epoch 3504/4000\n",
      "2/2 - 0s - loss: 1.5953e-05 - accuracy: 1.0000 - val_loss: 3.9636 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3505/4000\n",
      "2/2 - 0s - loss: 1.5923e-05 - accuracy: 1.0000 - val_loss: 3.9640 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3506/4000\n",
      "2/2 - 0s - loss: 1.5901e-05 - accuracy: 1.0000 - val_loss: 3.9644 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3507/4000\n",
      "2/2 - 0s - loss: 1.5882e-05 - accuracy: 1.0000 - val_loss: 3.9648 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3508/4000\n",
      "2/2 - 0s - loss: 1.5872e-05 - accuracy: 1.0000 - val_loss: 3.9652 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3509/4000\n",
      "2/2 - 0s - loss: 1.5848e-05 - accuracy: 1.0000 - val_loss: 3.9656 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3510/4000\n",
      "2/2 - 0s - loss: 1.5827e-05 - accuracy: 1.0000 - val_loss: 3.9659 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3511/4000\n",
      "2/2 - 0s - loss: 1.5804e-05 - accuracy: 1.0000 - val_loss: 3.9663 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3512/4000\n",
      "2/2 - 0s - loss: 1.5784e-05 - accuracy: 1.0000 - val_loss: 3.9667 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3513/4000\n",
      "2/2 - 0s - loss: 1.5774e-05 - accuracy: 1.0000 - val_loss: 3.9671 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3514/4000\n",
      "2/2 - 0s - loss: 1.5744e-05 - accuracy: 1.0000 - val_loss: 3.9675 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3515/4000\n",
      "2/2 - 0s - loss: 1.5727e-05 - accuracy: 1.0000 - val_loss: 3.9679 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3516/4000\n",
      "2/2 - 0s - loss: 1.5716e-05 - accuracy: 1.0000 - val_loss: 3.9682 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3517/4000\n",
      "2/2 - 0s - loss: 1.5697e-05 - accuracy: 1.0000 - val_loss: 3.9686 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3518/4000\n",
      "2/2 - 0s - loss: 1.5682e-05 - accuracy: 1.0000 - val_loss: 3.9690 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3519/4000\n",
      "2/2 - 0s - loss: 1.5663e-05 - accuracy: 1.0000 - val_loss: 3.9694 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3520/4000\n",
      "2/2 - 0s - loss: 1.5633e-05 - accuracy: 1.0000 - val_loss: 3.9698 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3521/4000\n",
      "2/2 - 0s - loss: 1.5608e-05 - accuracy: 1.0000 - val_loss: 3.9701 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3522/4000\n",
      "2/2 - 0s - loss: 1.5601e-05 - accuracy: 1.0000 - val_loss: 3.9705 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3523/4000\n",
      "2/2 - 0s - loss: 1.5572e-05 - accuracy: 1.0000 - val_loss: 3.9708 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3524/4000\n",
      "2/2 - 0s - loss: 1.5550e-05 - accuracy: 1.0000 - val_loss: 3.9711 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3525/4000\n",
      "2/2 - 0s - loss: 1.5537e-05 - accuracy: 1.0000 - val_loss: 3.9715 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3526/4000\n",
      "2/2 - 0s - loss: 1.5518e-05 - accuracy: 1.0000 - val_loss: 3.9719 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3527/4000\n",
      "2/2 - 0s - loss: 1.5501e-05 - accuracy: 1.0000 - val_loss: 3.9723 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 3528/4000\n",
      "2/2 - 0s - loss: 1.5482e-05 - accuracy: 1.0000 - val_loss: 3.9726 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3529/4000\n",
      "2/2 - 0s - loss: 1.5471e-05 - accuracy: 1.0000 - val_loss: 3.9729 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3530/4000\n",
      "2/2 - 0s - loss: 1.5448e-05 - accuracy: 1.0000 - val_loss: 3.9732 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3531/4000\n",
      "2/2 - 0s - loss: 1.5425e-05 - accuracy: 1.0000 - val_loss: 3.9736 - val_accuracy: 0.7250 - 83ms/epoch - 41ms/step\n",
      "Epoch 3532/4000\n",
      "2/2 - 0s - loss: 1.5408e-05 - accuracy: 1.0000 - val_loss: 3.9739 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3533/4000\n",
      "2/2 - 0s - loss: 1.5391e-05 - accuracy: 1.0000 - val_loss: 3.9744 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3534/4000\n",
      "2/2 - 0s - loss: 1.5374e-05 - accuracy: 1.0000 - val_loss: 3.9747 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3535/4000\n",
      "2/2 - 0s - loss: 1.5354e-05 - accuracy: 1.0000 - val_loss: 3.9751 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3536/4000\n",
      "2/2 - 0s - loss: 1.5331e-05 - accuracy: 1.0000 - val_loss: 3.9755 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3537/4000\n",
      "2/2 - 0s - loss: 1.5322e-05 - accuracy: 1.0000 - val_loss: 3.9759 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3538/4000\n",
      "2/2 - 0s - loss: 1.5301e-05 - accuracy: 1.0000 - val_loss: 3.9764 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3539/4000\n",
      "2/2 - 0s - loss: 1.5276e-05 - accuracy: 1.0000 - val_loss: 3.9769 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3540/4000\n",
      "2/2 - 0s - loss: 1.5259e-05 - accuracy: 1.0000 - val_loss: 3.9773 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3541/4000\n",
      "2/2 - 0s - loss: 1.5242e-05 - accuracy: 1.0000 - val_loss: 3.9777 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3542/4000\n",
      "2/2 - 0s - loss: 1.5220e-05 - accuracy: 1.0000 - val_loss: 3.9780 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3543/4000\n",
      "2/2 - 0s - loss: 1.5199e-05 - accuracy: 1.0000 - val_loss: 3.9783 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3544/4000\n",
      "2/2 - 0s - loss: 1.5190e-05 - accuracy: 1.0000 - val_loss: 3.9787 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3545/4000\n",
      "2/2 - 0s - loss: 1.5165e-05 - accuracy: 1.0000 - val_loss: 3.9791 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3546/4000\n",
      "2/2 - 0s - loss: 1.5152e-05 - accuracy: 1.0000 - val_loss: 3.9796 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3547/4000\n",
      "2/2 - 0s - loss: 1.5135e-05 - accuracy: 1.0000 - val_loss: 3.9800 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3548/4000\n",
      "2/2 - 0s - loss: 1.5107e-05 - accuracy: 1.0000 - val_loss: 3.9804 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 3549/4000\n",
      "2/2 - 0s - loss: 1.5084e-05 - accuracy: 1.0000 - val_loss: 3.9807 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3550/4000\n",
      "2/2 - 0s - loss: 1.5076e-05 - accuracy: 1.0000 - val_loss: 3.9811 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3551/4000\n",
      "2/2 - 0s - loss: 1.5061e-05 - accuracy: 1.0000 - val_loss: 3.9814 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3552/4000\n",
      "2/2 - 0s - loss: 1.5031e-05 - accuracy: 1.0000 - val_loss: 3.9817 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3553/4000\n",
      "2/2 - 0s - loss: 1.5014e-05 - accuracy: 1.0000 - val_loss: 3.9820 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3554/4000\n",
      "2/2 - 0s - loss: 1.4997e-05 - accuracy: 1.0000 - val_loss: 3.9824 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3555/4000\n",
      "2/2 - 0s - loss: 1.4982e-05 - accuracy: 1.0000 - val_loss: 3.9827 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3556/4000\n",
      "2/2 - 0s - loss: 1.4965e-05 - accuracy: 1.0000 - val_loss: 3.9831 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3557/4000\n",
      "2/2 - 0s - loss: 1.4950e-05 - accuracy: 1.0000 - val_loss: 3.9834 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3558/4000\n",
      "2/2 - 0s - loss: 1.4935e-05 - accuracy: 1.0000 - val_loss: 3.9837 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3559/4000\n",
      "2/2 - 0s - loss: 1.4912e-05 - accuracy: 1.0000 - val_loss: 3.9841 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3560/4000\n",
      "2/2 - 0s - loss: 1.4888e-05 - accuracy: 1.0000 - val_loss: 3.9844 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3561/4000\n",
      "2/2 - 0s - loss: 1.4869e-05 - accuracy: 1.0000 - val_loss: 3.9848 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3562/4000\n",
      "2/2 - 0s - loss: 1.4854e-05 - accuracy: 1.0000 - val_loss: 3.9852 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3563/4000\n",
      "2/2 - 0s - loss: 1.4835e-05 - accuracy: 1.0000 - val_loss: 3.9855 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3564/4000\n",
      "2/2 - 0s - loss: 1.4824e-05 - accuracy: 1.0000 - val_loss: 3.9858 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3565/4000\n",
      "2/2 - 0s - loss: 1.4809e-05 - accuracy: 1.0000 - val_loss: 3.9861 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3566/4000\n",
      "2/2 - 0s - loss: 1.4792e-05 - accuracy: 1.0000 - val_loss: 3.9865 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3567/4000\n",
      "2/2 - 0s - loss: 1.4778e-05 - accuracy: 1.0000 - val_loss: 3.9869 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3568/4000\n",
      "2/2 - 0s - loss: 1.4750e-05 - accuracy: 1.0000 - val_loss: 3.9873 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3569/4000\n",
      "2/2 - 0s - loss: 1.4733e-05 - accuracy: 1.0000 - val_loss: 3.9876 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3570/4000\n",
      "2/2 - 0s - loss: 1.4716e-05 - accuracy: 1.0000 - val_loss: 3.9881 - val_accuracy: 0.7250 - 45ms/epoch - 23ms/step\n",
      "Epoch 3571/4000\n",
      "2/2 - 0s - loss: 1.4697e-05 - accuracy: 1.0000 - val_loss: 3.9884 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3572/4000\n",
      "2/2 - 0s - loss: 1.4677e-05 - accuracy: 1.0000 - val_loss: 3.9887 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3573/4000\n",
      "2/2 - 0s - loss: 1.4650e-05 - accuracy: 1.0000 - val_loss: 3.9891 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3574/4000\n",
      "2/2 - 0s - loss: 1.4633e-05 - accuracy: 1.0000 - val_loss: 3.9895 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3575/4000\n",
      "2/2 - 0s - loss: 1.4618e-05 - accuracy: 1.0000 - val_loss: 3.9900 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3576/4000\n",
      "2/2 - 0s - loss: 1.4603e-05 - accuracy: 1.0000 - val_loss: 3.9903 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3577/4000\n",
      "2/2 - 0s - loss: 1.4590e-05 - accuracy: 1.0000 - val_loss: 3.9908 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 3578/4000\n",
      "2/2 - 0s - loss: 1.4565e-05 - accuracy: 1.0000 - val_loss: 3.9912 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3579/4000\n",
      "2/2 - 0s - loss: 1.4528e-05 - accuracy: 1.0000 - val_loss: 3.9916 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3580/4000\n",
      "2/2 - 0s - loss: 1.4511e-05 - accuracy: 1.0000 - val_loss: 3.9919 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3581/4000\n",
      "2/2 - 0s - loss: 1.4503e-05 - accuracy: 1.0000 - val_loss: 3.9923 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3582/4000\n",
      "2/2 - 0s - loss: 1.4475e-05 - accuracy: 1.0000 - val_loss: 3.9927 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3583/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.4458e-05 - accuracy: 1.0000 - val_loss: 3.9930 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 3584/4000\n",
      "2/2 - 0s - loss: 1.4426e-05 - accuracy: 1.0000 - val_loss: 3.9934 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3585/4000\n",
      "2/2 - 0s - loss: 1.4409e-05 - accuracy: 1.0000 - val_loss: 3.9937 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3586/4000\n",
      "2/2 - 0s - loss: 1.4396e-05 - accuracy: 1.0000 - val_loss: 3.9942 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3587/4000\n",
      "2/2 - 0s - loss: 1.4388e-05 - accuracy: 1.0000 - val_loss: 3.9946 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3588/4000\n",
      "2/2 - 0s - loss: 1.4367e-05 - accuracy: 1.0000 - val_loss: 3.9949 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3589/4000\n",
      "2/2 - 0s - loss: 1.4345e-05 - accuracy: 1.0000 - val_loss: 3.9953 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 3590/4000\n",
      "2/2 - 0s - loss: 1.4322e-05 - accuracy: 1.0000 - val_loss: 3.9957 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3591/4000\n",
      "2/2 - 0s - loss: 1.4303e-05 - accuracy: 1.0000 - val_loss: 3.9961 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3592/4000\n",
      "2/2 - 0s - loss: 1.4294e-05 - accuracy: 1.0000 - val_loss: 3.9965 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3593/4000\n",
      "2/2 - 0s - loss: 1.4277e-05 - accuracy: 1.0000 - val_loss: 3.9970 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3594/4000\n",
      "2/2 - 0s - loss: 1.4258e-05 - accuracy: 1.0000 - val_loss: 3.9975 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3595/4000\n",
      "2/2 - 0s - loss: 1.4239e-05 - accuracy: 1.0000 - val_loss: 3.9979 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3596/4000\n",
      "2/2 - 0s - loss: 1.4209e-05 - accuracy: 1.0000 - val_loss: 3.9983 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3597/4000\n",
      "2/2 - 0s - loss: 1.4199e-05 - accuracy: 1.0000 - val_loss: 3.9987 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3598/4000\n",
      "2/2 - 0s - loss: 1.4181e-05 - accuracy: 1.0000 - val_loss: 3.9991 - val_accuracy: 0.7250 - 77ms/epoch - 38ms/step\n",
      "Epoch 3599/4000\n",
      "2/2 - 0s - loss: 1.4173e-05 - accuracy: 1.0000 - val_loss: 3.9995 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3600/4000\n",
      "2/2 - 0s - loss: 1.4147e-05 - accuracy: 1.0000 - val_loss: 3.9999 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3601/4000\n",
      "2/2 - 0s - loss: 1.4124e-05 - accuracy: 1.0000 - val_loss: 4.0003 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3602/4000\n",
      "2/2 - 0s - loss: 1.4105e-05 - accuracy: 1.0000 - val_loss: 4.0007 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3603/4000\n",
      "2/2 - 0s - loss: 1.4094e-05 - accuracy: 1.0000 - val_loss: 4.0010 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3604/4000\n",
      "2/2 - 0s - loss: 1.4084e-05 - accuracy: 1.0000 - val_loss: 4.0015 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3605/4000\n",
      "2/2 - 0s - loss: 1.4058e-05 - accuracy: 1.0000 - val_loss: 4.0019 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3606/4000\n",
      "2/2 - 0s - loss: 1.4043e-05 - accuracy: 1.0000 - val_loss: 4.0024 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3607/4000\n",
      "2/2 - 0s - loss: 1.4022e-05 - accuracy: 1.0000 - val_loss: 4.0028 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 3608/4000\n",
      "2/2 - 0s - loss: 1.4005e-05 - accuracy: 1.0000 - val_loss: 4.0032 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3609/4000\n",
      "2/2 - 0s - loss: 1.3984e-05 - accuracy: 1.0000 - val_loss: 4.0036 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3610/4000\n",
      "2/2 - 0s - loss: 1.3966e-05 - accuracy: 1.0000 - val_loss: 4.0040 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3611/4000\n",
      "2/2 - 0s - loss: 1.3952e-05 - accuracy: 1.0000 - val_loss: 4.0045 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3612/4000\n",
      "2/2 - 0s - loss: 1.3928e-05 - accuracy: 1.0000 - val_loss: 4.0048 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3613/4000\n",
      "2/2 - 0s - loss: 1.3907e-05 - accuracy: 1.0000 - val_loss: 4.0052 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3614/4000\n",
      "2/2 - 0s - loss: 1.3892e-05 - accuracy: 1.0000 - val_loss: 4.0056 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3615/4000\n",
      "2/2 - 0s - loss: 1.3881e-05 - accuracy: 1.0000 - val_loss: 4.0060 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3616/4000\n",
      "2/2 - 0s - loss: 1.3866e-05 - accuracy: 1.0000 - val_loss: 4.0063 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3617/4000\n",
      "2/2 - 0s - loss: 1.3845e-05 - accuracy: 1.0000 - val_loss: 4.0068 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3618/4000\n",
      "2/2 - 0s - loss: 1.3826e-05 - accuracy: 1.0000 - val_loss: 4.0071 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3619/4000\n",
      "2/2 - 0s - loss: 1.3813e-05 - accuracy: 1.0000 - val_loss: 4.0075 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3620/4000\n",
      "2/2 - 0s - loss: 1.3792e-05 - accuracy: 1.0000 - val_loss: 4.0079 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3621/4000\n",
      "2/2 - 0s - loss: 1.3771e-05 - accuracy: 1.0000 - val_loss: 4.0083 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3622/4000\n",
      "2/2 - 0s - loss: 1.3745e-05 - accuracy: 1.0000 - val_loss: 4.0087 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3623/4000\n",
      "2/2 - 0s - loss: 1.3728e-05 - accuracy: 1.0000 - val_loss: 4.0091 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3624/4000\n",
      "2/2 - 0s - loss: 1.3717e-05 - accuracy: 1.0000 - val_loss: 4.0094 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3625/4000\n",
      "2/2 - 0s - loss: 1.3696e-05 - accuracy: 1.0000 - val_loss: 4.0099 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3626/4000\n",
      "2/2 - 0s - loss: 1.3686e-05 - accuracy: 1.0000 - val_loss: 4.0103 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3627/4000\n",
      "2/2 - 0s - loss: 1.3668e-05 - accuracy: 1.0000 - val_loss: 4.0106 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3628/4000\n",
      "2/2 - 0s - loss: 1.3643e-05 - accuracy: 1.0000 - val_loss: 4.0109 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3629/4000\n",
      "2/2 - 0s - loss: 1.3628e-05 - accuracy: 1.0000 - val_loss: 4.0113 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3630/4000\n",
      "2/2 - 0s - loss: 1.3609e-05 - accuracy: 1.0000 - val_loss: 4.0117 - val_accuracy: 0.7250 - 73ms/epoch - 36ms/step\n",
      "Epoch 3631/4000\n",
      "2/2 - 0s - loss: 1.3592e-05 - accuracy: 1.0000 - val_loss: 4.0120 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3632/4000\n",
      "2/2 - 0s - loss: 1.3573e-05 - accuracy: 1.0000 - val_loss: 4.0123 - val_accuracy: 0.7250 - 43ms/epoch - 22ms/step\n",
      "Epoch 3633/4000\n",
      "2/2 - 0s - loss: 1.3568e-05 - accuracy: 1.0000 - val_loss: 4.0127 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3634/4000\n",
      "2/2 - 0s - loss: 1.3551e-05 - accuracy: 1.0000 - val_loss: 4.0131 - val_accuracy: 0.7250 - 43ms/epoch - 21ms/step\n",
      "Epoch 3635/4000\n",
      "2/2 - 0s - loss: 1.3526e-05 - accuracy: 1.0000 - val_loss: 4.0135 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3636/4000\n",
      "2/2 - 0s - loss: 1.3513e-05 - accuracy: 1.0000 - val_loss: 4.0139 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3637/4000\n",
      "2/2 - 0s - loss: 1.3494e-05 - accuracy: 1.0000 - val_loss: 4.0141 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3638/4000\n",
      "2/2 - 0s - loss: 1.3481e-05 - accuracy: 1.0000 - val_loss: 4.0145 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3639/4000\n",
      "2/2 - 0s - loss: 1.3456e-05 - accuracy: 1.0000 - val_loss: 4.0148 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3640/4000\n",
      "2/2 - 0s - loss: 1.3443e-05 - accuracy: 1.0000 - val_loss: 4.0151 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3641/4000\n",
      "2/2 - 0s - loss: 1.3430e-05 - accuracy: 1.0000 - val_loss: 4.0155 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3642/4000\n",
      "2/2 - 0s - loss: 1.3409e-05 - accuracy: 1.0000 - val_loss: 4.0159 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3643/4000\n",
      "2/2 - 0s - loss: 1.3390e-05 - accuracy: 1.0000 - val_loss: 4.0163 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3644/4000\n",
      "2/2 - 0s - loss: 1.3370e-05 - accuracy: 1.0000 - val_loss: 4.0167 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3645/4000\n",
      "2/2 - 0s - loss: 1.3360e-05 - accuracy: 1.0000 - val_loss: 4.0170 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3646/4000\n",
      "2/2 - 0s - loss: 1.3343e-05 - accuracy: 1.0000 - val_loss: 4.0173 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3647/4000\n",
      "2/2 - 0s - loss: 1.3319e-05 - accuracy: 1.0000 - val_loss: 4.0176 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3648/4000\n",
      "2/2 - 0s - loss: 1.3300e-05 - accuracy: 1.0000 - val_loss: 4.0180 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3649/4000\n",
      "2/2 - 0s - loss: 1.3281e-05 - accuracy: 1.0000 - val_loss: 4.0184 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3650/4000\n",
      "2/2 - 0s - loss: 1.3262e-05 - accuracy: 1.0000 - val_loss: 4.0187 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3651/4000\n",
      "2/2 - 0s - loss: 1.3249e-05 - accuracy: 1.0000 - val_loss: 4.0191 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3652/4000\n",
      "2/2 - 0s - loss: 1.3232e-05 - accuracy: 1.0000 - val_loss: 4.0194 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3653/4000\n",
      "2/2 - 0s - loss: 1.3219e-05 - accuracy: 1.0000 - val_loss: 4.0197 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3654/4000\n",
      "2/2 - 0s - loss: 1.3202e-05 - accuracy: 1.0000 - val_loss: 4.0201 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3655/4000\n",
      "2/2 - 0s - loss: 1.3183e-05 - accuracy: 1.0000 - val_loss: 4.0205 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3656/4000\n",
      "2/2 - 0s - loss: 1.3164e-05 - accuracy: 1.0000 - val_loss: 4.0208 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3657/4000\n",
      "2/2 - 0s - loss: 1.3153e-05 - accuracy: 1.0000 - val_loss: 4.0212 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3658/4000\n",
      "2/2 - 0s - loss: 1.3136e-05 - accuracy: 1.0000 - val_loss: 4.0215 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3659/4000\n",
      "2/2 - 0s - loss: 1.3117e-05 - accuracy: 1.0000 - val_loss: 4.0218 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3660/4000\n",
      "2/2 - 0s - loss: 1.3100e-05 - accuracy: 1.0000 - val_loss: 4.0221 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3661/4000\n",
      "2/2 - 0s - loss: 1.3087e-05 - accuracy: 1.0000 - val_loss: 4.0226 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3662/4000\n",
      "2/2 - 0s - loss: 1.3072e-05 - accuracy: 1.0000 - val_loss: 4.0229 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3663/4000\n",
      "2/2 - 0s - loss: 1.3055e-05 - accuracy: 1.0000 - val_loss: 4.0233 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3664/4000\n",
      "2/2 - 0s - loss: 1.3034e-05 - accuracy: 1.0000 - val_loss: 4.0236 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3665/4000\n",
      "2/2 - 0s - loss: 1.3017e-05 - accuracy: 1.0000 - val_loss: 4.0239 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3666/4000\n",
      "2/2 - 0s - loss: 1.3009e-05 - accuracy: 1.0000 - val_loss: 4.0242 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3667/4000\n",
      "2/2 - 0s - loss: 1.2994e-05 - accuracy: 1.0000 - val_loss: 4.0247 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3668/4000\n",
      "2/2 - 0s - loss: 1.2983e-05 - accuracy: 1.0000 - val_loss: 4.0251 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3669/4000\n",
      "2/2 - 0s - loss: 1.2968e-05 - accuracy: 1.0000 - val_loss: 4.0255 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3670/4000\n",
      "2/2 - 0s - loss: 1.2955e-05 - accuracy: 1.0000 - val_loss: 4.0258 - val_accuracy: 0.7250 - 74ms/epoch - 37ms/step\n",
      "Epoch 3671/4000\n",
      "2/2 - 0s - loss: 1.2930e-05 - accuracy: 1.0000 - val_loss: 4.0263 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3672/4000\n",
      "2/2 - 0s - loss: 1.2913e-05 - accuracy: 1.0000 - val_loss: 4.0267 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3673/4000\n",
      "2/2 - 0s - loss: 1.2887e-05 - accuracy: 1.0000 - val_loss: 4.0271 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3674/4000\n",
      "2/2 - 0s - loss: 1.2874e-05 - accuracy: 1.0000 - val_loss: 4.0276 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3675/4000\n",
      "2/2 - 0s - loss: 1.2864e-05 - accuracy: 1.0000 - val_loss: 4.0280 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3676/4000\n",
      "2/2 - 0s - loss: 1.2849e-05 - accuracy: 1.0000 - val_loss: 4.0284 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3677/4000\n",
      "2/2 - 0s - loss: 1.2823e-05 - accuracy: 1.0000 - val_loss: 4.0288 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3678/4000\n",
      "2/2 - 0s - loss: 1.2819e-05 - accuracy: 1.0000 - val_loss: 4.0291 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3679/4000\n",
      "2/2 - 0s - loss: 1.2811e-05 - accuracy: 1.0000 - val_loss: 4.0295 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3680/4000\n",
      "2/2 - 0s - loss: 1.2787e-05 - accuracy: 1.0000 - val_loss: 4.0299 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3681/4000\n",
      "2/2 - 0s - loss: 1.2772e-05 - accuracy: 1.0000 - val_loss: 4.0305 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3682/4000\n",
      "2/2 - 0s - loss: 1.2749e-05 - accuracy: 1.0000 - val_loss: 4.0309 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3683/4000\n",
      "2/2 - 0s - loss: 1.2745e-05 - accuracy: 1.0000 - val_loss: 4.0314 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3684/4000\n",
      "2/2 - 0s - loss: 1.2717e-05 - accuracy: 1.0000 - val_loss: 4.0317 - val_accuracy: 0.7250 - 44ms/epoch - 22ms/step\n",
      "Epoch 3685/4000\n",
      "2/2 - 0s - loss: 1.2704e-05 - accuracy: 1.0000 - val_loss: 4.0320 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3686/4000\n",
      "2/2 - 0s - loss: 1.2685e-05 - accuracy: 1.0000 - val_loss: 4.0324 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3687/4000\n",
      "2/2 - 0s - loss: 1.2666e-05 - accuracy: 1.0000 - val_loss: 4.0327 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3688/4000\n",
      "2/2 - 0s - loss: 1.2655e-05 - accuracy: 1.0000 - val_loss: 4.0331 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3689/4000\n",
      "2/2 - 0s - loss: 1.2647e-05 - accuracy: 1.0000 - val_loss: 4.0335 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3690/4000\n",
      "2/2 - 0s - loss: 1.2628e-05 - accuracy: 1.0000 - val_loss: 4.0339 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3691/4000\n",
      "2/2 - 0s - loss: 1.2615e-05 - accuracy: 1.0000 - val_loss: 4.0343 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3692/4000\n",
      "2/2 - 0s - loss: 1.2596e-05 - accuracy: 1.0000 - val_loss: 4.0348 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3693/4000\n",
      "2/2 - 0s - loss: 1.2579e-05 - accuracy: 1.0000 - val_loss: 4.0351 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3694/4000\n",
      "2/2 - 0s - loss: 1.2555e-05 - accuracy: 1.0000 - val_loss: 4.0356 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3695/4000\n",
      "2/2 - 0s - loss: 1.2538e-05 - accuracy: 1.0000 - val_loss: 4.0361 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3696/4000\n",
      "2/2 - 0s - loss: 1.2530e-05 - accuracy: 1.0000 - val_loss: 4.0366 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3697/4000\n",
      "2/2 - 0s - loss: 1.2515e-05 - accuracy: 1.0000 - val_loss: 4.0370 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3698/4000\n",
      "2/2 - 0s - loss: 1.2491e-05 - accuracy: 1.0000 - val_loss: 4.0373 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3699/4000\n",
      "2/2 - 0s - loss: 1.2481e-05 - accuracy: 1.0000 - val_loss: 4.0376 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3700/4000\n",
      "2/2 - 0s - loss: 1.2472e-05 - accuracy: 1.0000 - val_loss: 4.0380 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3701/4000\n",
      "2/2 - 0s - loss: 1.2442e-05 - accuracy: 1.0000 - val_loss: 4.0384 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3702/4000\n",
      "2/2 - 0s - loss: 1.2423e-05 - accuracy: 1.0000 - val_loss: 4.0389 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3703/4000\n",
      "2/2 - 0s - loss: 1.2419e-05 - accuracy: 1.0000 - val_loss: 4.0393 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 3704/4000\n",
      "2/2 - 0s - loss: 1.2396e-05 - accuracy: 1.0000 - val_loss: 4.0398 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3705/4000\n",
      "2/2 - 0s - loss: 1.2385e-05 - accuracy: 1.0000 - val_loss: 4.0402 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3706/4000\n",
      "2/2 - 0s - loss: 1.2370e-05 - accuracy: 1.0000 - val_loss: 4.0407 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3707/4000\n",
      "2/2 - 0s - loss: 1.2353e-05 - accuracy: 1.0000 - val_loss: 4.0410 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3708/4000\n",
      "2/2 - 0s - loss: 1.2336e-05 - accuracy: 1.0000 - val_loss: 4.0414 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3709/4000\n",
      "2/2 - 0s - loss: 1.2323e-05 - accuracy: 1.0000 - val_loss: 4.0419 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3710/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.2310e-05 - accuracy: 1.0000 - val_loss: 4.0423 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3711/4000\n",
      "2/2 - 0s - loss: 1.2298e-05 - accuracy: 1.0000 - val_loss: 4.0427 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3712/4000\n",
      "2/2 - 0s - loss: 1.2276e-05 - accuracy: 1.0000 - val_loss: 4.0431 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3713/4000\n",
      "2/2 - 0s - loss: 1.2266e-05 - accuracy: 1.0000 - val_loss: 4.0435 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3714/4000\n",
      "2/2 - 0s - loss: 1.2251e-05 - accuracy: 1.0000 - val_loss: 4.0438 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3715/4000\n",
      "2/2 - 0s - loss: 1.2232e-05 - accuracy: 1.0000 - val_loss: 4.0442 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3716/4000\n",
      "2/2 - 0s - loss: 1.2215e-05 - accuracy: 1.0000 - val_loss: 4.0446 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3717/4000\n",
      "2/2 - 0s - loss: 1.2198e-05 - accuracy: 1.0000 - val_loss: 4.0449 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3718/4000\n",
      "2/2 - 0s - loss: 1.2191e-05 - accuracy: 1.0000 - val_loss: 4.0453 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3719/4000\n",
      "2/2 - 0s - loss: 1.2176e-05 - accuracy: 1.0000 - val_loss: 4.0456 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3720/4000\n",
      "2/2 - 0s - loss: 1.2159e-05 - accuracy: 1.0000 - val_loss: 4.0461 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3721/4000\n",
      "2/2 - 0s - loss: 1.2146e-05 - accuracy: 1.0000 - val_loss: 4.0464 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3722/4000\n",
      "2/2 - 0s - loss: 1.2138e-05 - accuracy: 1.0000 - val_loss: 4.0468 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3723/4000\n",
      "2/2 - 0s - loss: 1.2119e-05 - accuracy: 1.0000 - val_loss: 4.0472 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3724/4000\n",
      "2/2 - 0s - loss: 1.2106e-05 - accuracy: 1.0000 - val_loss: 4.0476 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3725/4000\n",
      "2/2 - 0s - loss: 1.2091e-05 - accuracy: 1.0000 - val_loss: 4.0479 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3726/4000\n",
      "2/2 - 0s - loss: 1.2074e-05 - accuracy: 1.0000 - val_loss: 4.0483 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3727/4000\n",
      "2/2 - 0s - loss: 1.2057e-05 - accuracy: 1.0000 - val_loss: 4.0487 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3728/4000\n",
      "2/2 - 0s - loss: 1.2044e-05 - accuracy: 1.0000 - val_loss: 4.0491 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3729/4000\n",
      "2/2 - 0s - loss: 1.2032e-05 - accuracy: 1.0000 - val_loss: 4.0494 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3730/4000\n",
      "2/2 - 0s - loss: 1.2012e-05 - accuracy: 1.0000 - val_loss: 4.0498 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3731/4000\n",
      "2/2 - 0s - loss: 1.2002e-05 - accuracy: 1.0000 - val_loss: 4.0502 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3732/4000\n",
      "2/2 - 0s - loss: 1.1985e-05 - accuracy: 1.0000 - val_loss: 4.0505 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3733/4000\n",
      "2/2 - 0s - loss: 1.1968e-05 - accuracy: 1.0000 - val_loss: 4.0509 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3734/4000\n",
      "2/2 - 0s - loss: 1.1963e-05 - accuracy: 1.0000 - val_loss: 4.0514 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3735/4000\n",
      "2/2 - 0s - loss: 1.1946e-05 - accuracy: 1.0000 - val_loss: 4.0518 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3736/4000\n",
      "2/2 - 0s - loss: 1.1934e-05 - accuracy: 1.0000 - val_loss: 4.0521 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3737/4000\n",
      "2/2 - 0s - loss: 1.1919e-05 - accuracy: 1.0000 - val_loss: 4.0524 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3738/4000\n",
      "2/2 - 0s - loss: 1.1897e-05 - accuracy: 1.0000 - val_loss: 4.0528 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3739/4000\n",
      "2/2 - 0s - loss: 1.1885e-05 - accuracy: 1.0000 - val_loss: 4.0532 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3740/4000\n",
      "2/2 - 0s - loss: 1.1861e-05 - accuracy: 1.0000 - val_loss: 4.0536 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3741/4000\n",
      "2/2 - 0s - loss: 1.1855e-05 - accuracy: 1.0000 - val_loss: 4.0540 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3742/4000\n",
      "2/2 - 0s - loss: 1.1840e-05 - accuracy: 1.0000 - val_loss: 4.0544 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3743/4000\n",
      "2/2 - 0s - loss: 1.1827e-05 - accuracy: 1.0000 - val_loss: 4.0548 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3744/4000\n",
      "2/2 - 0s - loss: 1.1806e-05 - accuracy: 1.0000 - val_loss: 4.0551 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3745/4000\n",
      "2/2 - 0s - loss: 1.1791e-05 - accuracy: 1.0000 - val_loss: 4.0555 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3746/4000\n",
      "2/2 - 0s - loss: 1.1776e-05 - accuracy: 1.0000 - val_loss: 4.0559 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3747/4000\n",
      "2/2 - 0s - loss: 1.1763e-05 - accuracy: 1.0000 - val_loss: 4.0563 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3748/4000\n",
      "2/2 - 0s - loss: 1.1755e-05 - accuracy: 1.0000 - val_loss: 4.0567 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3749/4000\n",
      "2/2 - 0s - loss: 1.1748e-05 - accuracy: 1.0000 - val_loss: 4.0572 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3750/4000\n",
      "2/2 - 0s - loss: 1.1723e-05 - accuracy: 1.0000 - val_loss: 4.0576 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3751/4000\n",
      "2/2 - 0s - loss: 1.1710e-05 - accuracy: 1.0000 - val_loss: 4.0579 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3752/4000\n",
      "2/2 - 0s - loss: 1.1689e-05 - accuracy: 1.0000 - val_loss: 4.0582 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3753/4000\n",
      "2/2 - 0s - loss: 1.1674e-05 - accuracy: 1.0000 - val_loss: 4.0586 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3754/4000\n",
      "2/2 - 0s - loss: 1.1661e-05 - accuracy: 1.0000 - val_loss: 4.0590 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3755/4000\n",
      "2/2 - 0s - loss: 1.1640e-05 - accuracy: 1.0000 - val_loss: 4.0593 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3756/4000\n",
      "2/2 - 0s - loss: 1.1625e-05 - accuracy: 1.0000 - val_loss: 4.0596 - val_accuracy: 0.7250 - 43ms/epoch - 21ms/step\n",
      "Epoch 3757/4000\n",
      "2/2 - 0s - loss: 1.1612e-05 - accuracy: 1.0000 - val_loss: 4.0600 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3758/4000\n",
      "2/2 - 0s - loss: 1.1593e-05 - accuracy: 1.0000 - val_loss: 4.0604 - val_accuracy: 0.7250 - 45ms/epoch - 22ms/step\n",
      "Epoch 3759/4000\n",
      "2/2 - 0s - loss: 1.1584e-05 - accuracy: 1.0000 - val_loss: 4.0608 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3760/4000\n",
      "2/2 - 0s - loss: 1.1574e-05 - accuracy: 1.0000 - val_loss: 4.0612 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3761/4000\n",
      "2/2 - 0s - loss: 1.1557e-05 - accuracy: 1.0000 - val_loss: 4.0615 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3762/4000\n",
      "2/2 - 0s - loss: 1.1536e-05 - accuracy: 1.0000 - val_loss: 4.0619 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3763/4000\n",
      "2/2 - 0s - loss: 1.1523e-05 - accuracy: 1.0000 - val_loss: 4.0622 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3764/4000\n",
      "2/2 - 0s - loss: 1.1506e-05 - accuracy: 1.0000 - val_loss: 4.0625 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3765/4000\n",
      "2/2 - 0s - loss: 1.1495e-05 - accuracy: 1.0000 - val_loss: 4.0630 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3766/4000\n",
      "2/2 - 0s - loss: 1.1487e-05 - accuracy: 1.0000 - val_loss: 4.0633 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3767/4000\n",
      "2/2 - 0s - loss: 1.1474e-05 - accuracy: 1.0000 - val_loss: 4.0636 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3768/4000\n",
      "2/2 - 0s - loss: 1.1457e-05 - accuracy: 1.0000 - val_loss: 4.0640 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3769/4000\n",
      "2/2 - 0s - loss: 1.1446e-05 - accuracy: 1.0000 - val_loss: 4.0644 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3770/4000\n",
      "2/2 - 0s - loss: 1.1438e-05 - accuracy: 1.0000 - val_loss: 4.0648 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3771/4000\n",
      "2/2 - 0s - loss: 1.1421e-05 - accuracy: 1.0000 - val_loss: 4.0651 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3772/4000\n",
      "2/2 - 0s - loss: 1.1406e-05 - accuracy: 1.0000 - val_loss: 4.0655 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3773/4000\n",
      "2/2 - 0s - loss: 1.1380e-05 - accuracy: 1.0000 - val_loss: 4.0659 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3774/4000\n",
      "2/2 - 0s - loss: 1.1369e-05 - accuracy: 1.0000 - val_loss: 4.0662 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3775/4000\n",
      "2/2 - 0s - loss: 1.1359e-05 - accuracy: 1.0000 - val_loss: 4.0666 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3776/4000\n",
      "2/2 - 0s - loss: 1.1344e-05 - accuracy: 1.0000 - val_loss: 4.0669 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3777/4000\n",
      "2/2 - 0s - loss: 1.1335e-05 - accuracy: 1.0000 - val_loss: 4.0673 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3778/4000\n",
      "2/2 - 0s - loss: 1.1321e-05 - accuracy: 1.0000 - val_loss: 4.0676 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3779/4000\n",
      "2/2 - 0s - loss: 1.1299e-05 - accuracy: 1.0000 - val_loss: 4.0680 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3780/4000\n",
      "2/2 - 0s - loss: 1.1286e-05 - accuracy: 1.0000 - val_loss: 4.0683 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3781/4000\n",
      "2/2 - 0s - loss: 1.1284e-05 - accuracy: 1.0000 - val_loss: 4.0687 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3782/4000\n",
      "2/2 - 0s - loss: 1.1272e-05 - accuracy: 1.0000 - val_loss: 4.0691 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3783/4000\n",
      "2/2 - 0s - loss: 1.1248e-05 - accuracy: 1.0000 - val_loss: 4.0695 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3784/4000\n",
      "2/2 - 0s - loss: 1.1231e-05 - accuracy: 1.0000 - val_loss: 4.0699 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3785/4000\n",
      "2/2 - 0s - loss: 1.1216e-05 - accuracy: 1.0000 - val_loss: 4.0703 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3786/4000\n",
      "2/2 - 0s - loss: 1.1203e-05 - accuracy: 1.0000 - val_loss: 4.0706 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3787/4000\n",
      "2/2 - 0s - loss: 1.1193e-05 - accuracy: 1.0000 - val_loss: 4.0709 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3788/4000\n",
      "2/2 - 0s - loss: 1.1176e-05 - accuracy: 1.0000 - val_loss: 4.0713 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3789/4000\n",
      "2/2 - 0s - loss: 1.1157e-05 - accuracy: 1.0000 - val_loss: 4.0717 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3790/4000\n",
      "2/2 - 0s - loss: 1.1150e-05 - accuracy: 1.0000 - val_loss: 4.0720 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3791/4000\n",
      "2/2 - 0s - loss: 1.1137e-05 - accuracy: 1.0000 - val_loss: 4.0723 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3792/4000\n",
      "2/2 - 0s - loss: 1.1129e-05 - accuracy: 1.0000 - val_loss: 4.0727 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3793/4000\n",
      "2/2 - 0s - loss: 1.1118e-05 - accuracy: 1.0000 - val_loss: 4.0731 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3794/4000\n",
      "2/2 - 0s - loss: 1.1103e-05 - accuracy: 1.0000 - val_loss: 4.0735 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3795/4000\n",
      "2/2 - 0s - loss: 1.1093e-05 - accuracy: 1.0000 - val_loss: 4.0739 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3796/4000\n",
      "2/2 - 0s - loss: 1.1078e-05 - accuracy: 1.0000 - val_loss: 4.0743 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3797/4000\n",
      "2/2 - 0s - loss: 1.1063e-05 - accuracy: 1.0000 - val_loss: 4.0747 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3798/4000\n",
      "2/2 - 0s - loss: 1.1044e-05 - accuracy: 1.0000 - val_loss: 4.0751 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3799/4000\n",
      "2/2 - 0s - loss: 1.1033e-05 - accuracy: 1.0000 - val_loss: 4.0755 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3800/4000\n",
      "2/2 - 0s - loss: 1.1018e-05 - accuracy: 1.0000 - val_loss: 4.0759 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3801/4000\n",
      "2/2 - 0s - loss: 1.1003e-05 - accuracy: 1.0000 - val_loss: 4.0763 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3802/4000\n",
      "2/2 - 0s - loss: 1.0997e-05 - accuracy: 1.0000 - val_loss: 4.0767 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3803/4000\n",
      "2/2 - 0s - loss: 1.0988e-05 - accuracy: 1.0000 - val_loss: 4.0771 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3804/4000\n",
      "2/2 - 0s - loss: 1.0967e-05 - accuracy: 1.0000 - val_loss: 4.0775 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3805/4000\n",
      "2/2 - 0s - loss: 1.0954e-05 - accuracy: 1.0000 - val_loss: 4.0779 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3806/4000\n",
      "2/2 - 0s - loss: 1.0933e-05 - accuracy: 1.0000 - val_loss: 4.0784 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3807/4000\n",
      "2/2 - 0s - loss: 1.0922e-05 - accuracy: 1.0000 - val_loss: 4.0787 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3808/4000\n",
      "2/2 - 0s - loss: 1.0910e-05 - accuracy: 1.0000 - val_loss: 4.0791 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3809/4000\n",
      "2/2 - 0s - loss: 1.0899e-05 - accuracy: 1.0000 - val_loss: 4.0794 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3810/4000\n",
      "2/2 - 0s - loss: 1.0880e-05 - accuracy: 1.0000 - val_loss: 4.0798 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3811/4000\n",
      "2/2 - 0s - loss: 1.0861e-05 - accuracy: 1.0000 - val_loss: 4.0802 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3812/4000\n",
      "2/2 - 0s - loss: 1.0844e-05 - accuracy: 1.0000 - val_loss: 4.0806 - val_accuracy: 0.7250 - 69ms/epoch - 35ms/step\n",
      "Epoch 3813/4000\n",
      "2/2 - 0s - loss: 1.0833e-05 - accuracy: 1.0000 - val_loss: 4.0810 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3814/4000\n",
      "2/2 - 0s - loss: 1.0825e-05 - accuracy: 1.0000 - val_loss: 4.0814 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3815/4000\n",
      "2/2 - 0s - loss: 1.0812e-05 - accuracy: 1.0000 - val_loss: 4.0819 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3816/4000\n",
      "2/2 - 0s - loss: 1.0799e-05 - accuracy: 1.0000 - val_loss: 4.0822 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3817/4000\n",
      "2/2 - 0s - loss: 1.0784e-05 - accuracy: 1.0000 - val_loss: 4.0825 - val_accuracy: 0.7250 - 71ms/epoch - 36ms/step\n",
      "Epoch 3818/4000\n",
      "2/2 - 0s - loss: 1.0767e-05 - accuracy: 1.0000 - val_loss: 4.0829 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3819/4000\n",
      "2/2 - 0s - loss: 1.0750e-05 - accuracy: 1.0000 - val_loss: 4.0833 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3820/4000\n",
      "2/2 - 0s - loss: 1.0733e-05 - accuracy: 1.0000 - val_loss: 4.0838 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3821/4000\n",
      "2/2 - 0s - loss: 1.0718e-05 - accuracy: 1.0000 - val_loss: 4.0842 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3822/4000\n",
      "2/2 - 0s - loss: 1.0718e-05 - accuracy: 1.0000 - val_loss: 4.0847 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3823/4000\n",
      "2/2 - 0s - loss: 1.0710e-05 - accuracy: 1.0000 - val_loss: 4.0851 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3824/4000\n",
      "2/2 - 0s - loss: 1.0699e-05 - accuracy: 1.0000 - val_loss: 4.0855 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3825/4000\n",
      "2/2 - 0s - loss: 1.0680e-05 - accuracy: 1.0000 - val_loss: 4.0858 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3826/4000\n",
      "2/2 - 0s - loss: 1.0667e-05 - accuracy: 1.0000 - val_loss: 4.0862 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3827/4000\n",
      "2/2 - 0s - loss: 1.0650e-05 - accuracy: 1.0000 - val_loss: 4.0866 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3828/4000\n",
      "2/2 - 0s - loss: 1.0637e-05 - accuracy: 1.0000 - val_loss: 4.0870 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3829/4000\n",
      "2/2 - 0s - loss: 1.0622e-05 - accuracy: 1.0000 - val_loss: 4.0873 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3830/4000\n",
      "2/2 - 0s - loss: 1.0605e-05 - accuracy: 1.0000 - val_loss: 4.0878 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3831/4000\n",
      "2/2 - 0s - loss: 1.0595e-05 - accuracy: 1.0000 - val_loss: 4.0882 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3832/4000\n",
      "2/2 - 0s - loss: 1.0588e-05 - accuracy: 1.0000 - val_loss: 4.0885 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3833/4000\n",
      "2/2 - 0s - loss: 1.0571e-05 - accuracy: 1.0000 - val_loss: 4.0888 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3834/4000\n",
      "2/2 - 0s - loss: 1.0550e-05 - accuracy: 1.0000 - val_loss: 4.0891 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3835/4000\n",
      "2/2 - 0s - loss: 1.0537e-05 - accuracy: 1.0000 - val_loss: 4.0895 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3836/4000\n",
      "2/2 - 0s - loss: 1.0529e-05 - accuracy: 1.0000 - val_loss: 4.0899 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3837/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.0518e-05 - accuracy: 1.0000 - val_loss: 4.0903 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3838/4000\n",
      "2/2 - 0s - loss: 1.0503e-05 - accuracy: 1.0000 - val_loss: 4.0906 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3839/4000\n",
      "2/2 - 0s - loss: 1.0501e-05 - accuracy: 1.0000 - val_loss: 4.0909 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3840/4000\n",
      "2/2 - 0s - loss: 1.0488e-05 - accuracy: 1.0000 - val_loss: 4.0913 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3841/4000\n",
      "2/2 - 0s - loss: 1.0467e-05 - accuracy: 1.0000 - val_loss: 4.0917 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3842/4000\n",
      "2/2 - 0s - loss: 1.0454e-05 - accuracy: 1.0000 - val_loss: 4.0921 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3843/4000\n",
      "2/2 - 0s - loss: 1.0450e-05 - accuracy: 1.0000 - val_loss: 4.0925 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3844/4000\n",
      "2/2 - 0s - loss: 1.0435e-05 - accuracy: 1.0000 - val_loss: 4.0928 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3845/4000\n",
      "2/2 - 0s - loss: 1.0424e-05 - accuracy: 1.0000 - val_loss: 4.0932 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3846/4000\n",
      "2/2 - 0s - loss: 1.0405e-05 - accuracy: 1.0000 - val_loss: 4.0936 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3847/4000\n",
      "2/2 - 0s - loss: 1.0395e-05 - accuracy: 1.0000 - val_loss: 4.0940 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3848/4000\n",
      "2/2 - 0s - loss: 1.0382e-05 - accuracy: 1.0000 - val_loss: 4.0943 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3849/4000\n",
      "2/2 - 0s - loss: 1.0358e-05 - accuracy: 1.0000 - val_loss: 4.0947 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3850/4000\n",
      "2/2 - 0s - loss: 1.0350e-05 - accuracy: 1.0000 - val_loss: 4.0951 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3851/4000\n",
      "2/2 - 0s - loss: 1.0335e-05 - accuracy: 1.0000 - val_loss: 4.0955 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3852/4000\n",
      "2/2 - 0s - loss: 1.0324e-05 - accuracy: 1.0000 - val_loss: 4.0959 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3853/4000\n",
      "2/2 - 0s - loss: 1.0312e-05 - accuracy: 1.0000 - val_loss: 4.0962 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3854/4000\n",
      "2/2 - 0s - loss: 1.0305e-05 - accuracy: 1.0000 - val_loss: 4.0965 - val_accuracy: 0.7250 - 44ms/epoch - 22ms/step\n",
      "Epoch 3855/4000\n",
      "2/2 - 0s - loss: 1.0290e-05 - accuracy: 1.0000 - val_loss: 4.0968 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3856/4000\n",
      "2/2 - 0s - loss: 1.0275e-05 - accuracy: 1.0000 - val_loss: 4.0972 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3857/4000\n",
      "2/2 - 0s - loss: 1.0256e-05 - accuracy: 1.0000 - val_loss: 4.0976 - val_accuracy: 0.7250 - 70ms/epoch - 35ms/step\n",
      "Epoch 3858/4000\n",
      "2/2 - 0s - loss: 1.0248e-05 - accuracy: 1.0000 - val_loss: 4.0980 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3859/4000\n",
      "2/2 - 0s - loss: 1.0237e-05 - accuracy: 1.0000 - val_loss: 4.0984 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3860/4000\n",
      "2/2 - 0s - loss: 1.0228e-05 - accuracy: 1.0000 - val_loss: 4.0988 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3861/4000\n",
      "2/2 - 0s - loss: 1.0220e-05 - accuracy: 1.0000 - val_loss: 4.0992 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3862/4000\n",
      "2/2 - 0s - loss: 1.0214e-05 - accuracy: 1.0000 - val_loss: 4.0996 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3863/4000\n",
      "2/2 - 0s - loss: 1.0192e-05 - accuracy: 1.0000 - val_loss: 4.1000 - val_accuracy: 0.7250 - 44ms/epoch - 22ms/step\n",
      "Epoch 3864/4000\n",
      "2/2 - 0s - loss: 1.0173e-05 - accuracy: 1.0000 - val_loss: 4.1004 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3865/4000\n",
      "2/2 - 0s - loss: 1.0165e-05 - accuracy: 1.0000 - val_loss: 4.1008 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3866/4000\n",
      "2/2 - 0s - loss: 1.0143e-05 - accuracy: 1.0000 - val_loss: 4.1012 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3867/4000\n",
      "2/2 - 0s - loss: 1.0135e-05 - accuracy: 1.0000 - val_loss: 4.1015 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3868/4000\n",
      "2/2 - 0s - loss: 1.0133e-05 - accuracy: 1.0000 - val_loss: 4.1019 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3869/4000\n",
      "2/2 - 0s - loss: 1.0118e-05 - accuracy: 1.0000 - val_loss: 4.1022 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3870/4000\n",
      "2/2 - 0s - loss: 1.0101e-05 - accuracy: 1.0000 - val_loss: 4.1026 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3871/4000\n",
      "2/2 - 0s - loss: 1.0092e-05 - accuracy: 1.0000 - val_loss: 4.1029 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3872/4000\n",
      "2/2 - 0s - loss: 1.0090e-05 - accuracy: 1.0000 - val_loss: 4.1033 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3873/4000\n",
      "2/2 - 0s - loss: 1.0075e-05 - accuracy: 1.0000 - val_loss: 4.1037 - val_accuracy: 0.7250 - 45ms/epoch - 22ms/step\n",
      "Epoch 3874/4000\n",
      "2/2 - 0s - loss: 1.0060e-05 - accuracy: 1.0000 - val_loss: 4.1040 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3875/4000\n",
      "2/2 - 0s - loss: 1.0054e-05 - accuracy: 1.0000 - val_loss: 4.1043 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3876/4000\n",
      "2/2 - 0s - loss: 1.0039e-05 - accuracy: 1.0000 - val_loss: 4.1046 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3877/4000\n",
      "2/2 - 0s - loss: 1.0022e-05 - accuracy: 1.0000 - val_loss: 4.1050 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3878/4000\n",
      "2/2 - 0s - loss: 1.0011e-05 - accuracy: 1.0000 - val_loss: 4.1055 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3879/4000\n",
      "2/2 - 0s - loss: 1.0001e-05 - accuracy: 1.0000 - val_loss: 4.1059 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3880/4000\n",
      "2/2 - 0s - loss: 9.9901e-06 - accuracy: 1.0000 - val_loss: 4.1063 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3881/4000\n",
      "2/2 - 0s - loss: 9.9752e-06 - accuracy: 1.0000 - val_loss: 4.1066 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3882/4000\n",
      "2/2 - 0s - loss: 9.9688e-06 - accuracy: 1.0000 - val_loss: 4.1069 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3883/4000\n",
      "2/2 - 0s - loss: 9.9560e-06 - accuracy: 1.0000 - val_loss: 4.1073 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3884/4000\n",
      "2/2 - 0s - loss: 9.9454e-06 - accuracy: 1.0000 - val_loss: 4.1077 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3885/4000\n",
      "2/2 - 0s - loss: 9.9284e-06 - accuracy: 1.0000 - val_loss: 4.1081 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3886/4000\n",
      "2/2 - 0s - loss: 9.9113e-06 - accuracy: 1.0000 - val_loss: 4.1085 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3887/4000\n",
      "2/2 - 0s - loss: 9.9049e-06 - accuracy: 1.0000 - val_loss: 4.1089 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3888/4000\n",
      "2/2 - 0s - loss: 9.8858e-06 - accuracy: 1.0000 - val_loss: 4.1092 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3889/4000\n",
      "2/2 - 0s - loss: 9.8773e-06 - accuracy: 1.0000 - val_loss: 4.1096 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3890/4000\n",
      "2/2 - 0s - loss: 9.8602e-06 - accuracy: 1.0000 - val_loss: 4.1100 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3891/4000\n",
      "2/2 - 0s - loss: 9.8538e-06 - accuracy: 1.0000 - val_loss: 4.1104 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3892/4000\n",
      "2/2 - 0s - loss: 9.8432e-06 - accuracy: 1.0000 - val_loss: 4.1107 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3893/4000\n",
      "2/2 - 0s - loss: 9.8262e-06 - accuracy: 1.0000 - val_loss: 4.1111 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3894/4000\n",
      "2/2 - 0s - loss: 9.8113e-06 - accuracy: 1.0000 - val_loss: 4.1115 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3895/4000\n",
      "2/2 - 0s - loss: 9.8070e-06 - accuracy: 1.0000 - val_loss: 4.1119 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3896/4000\n",
      "2/2 - 0s - loss: 9.7900e-06 - accuracy: 1.0000 - val_loss: 4.1122 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3897/4000\n",
      "2/2 - 0s - loss: 9.7857e-06 - accuracy: 1.0000 - val_loss: 4.1126 - val_accuracy: 0.7250 - 53ms/epoch - 26ms/step\n",
      "Epoch 3898/4000\n",
      "2/2 - 0s - loss: 9.7687e-06 - accuracy: 1.0000 - val_loss: 4.1129 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3899/4000\n",
      "2/2 - 0s - loss: 9.7559e-06 - accuracy: 1.0000 - val_loss: 4.1132 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3900/4000\n",
      "2/2 - 0s - loss: 9.7432e-06 - accuracy: 1.0000 - val_loss: 4.1135 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3901/4000\n",
      "2/2 - 0s - loss: 9.7304e-06 - accuracy: 1.0000 - val_loss: 4.1140 - val_accuracy: 0.7250 - 45ms/epoch - 22ms/step\n",
      "Epoch 3902/4000\n",
      "2/2 - 0s - loss: 9.7134e-06 - accuracy: 1.0000 - val_loss: 4.1143 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3903/4000\n",
      "2/2 - 0s - loss: 9.7027e-06 - accuracy: 1.0000 - val_loss: 4.1148 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3904/4000\n",
      "2/2 - 0s - loss: 9.6899e-06 - accuracy: 1.0000 - val_loss: 4.1151 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3905/4000\n",
      "2/2 - 0s - loss: 9.6729e-06 - accuracy: 1.0000 - val_loss: 4.1156 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3906/4000\n",
      "2/2 - 0s - loss: 9.6665e-06 - accuracy: 1.0000 - val_loss: 4.1160 - val_accuracy: 0.7250 - 63ms/epoch - 31ms/step\n",
      "Epoch 3907/4000\n",
      "2/2 - 0s - loss: 9.6537e-06 - accuracy: 1.0000 - val_loss: 4.1164 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3908/4000\n",
      "2/2 - 0s - loss: 9.6474e-06 - accuracy: 1.0000 - val_loss: 4.1167 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3909/4000\n",
      "2/2 - 0s - loss: 9.6388e-06 - accuracy: 1.0000 - val_loss: 4.1171 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3910/4000\n",
      "2/2 - 0s - loss: 9.6218e-06 - accuracy: 1.0000 - val_loss: 4.1175 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3911/4000\n",
      "2/2 - 0s - loss: 9.6133e-06 - accuracy: 1.0000 - val_loss: 4.1179 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3912/4000\n",
      "2/2 - 0s - loss: 9.6069e-06 - accuracy: 1.0000 - val_loss: 4.1183 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3913/4000\n",
      "2/2 - 0s - loss: 9.6005e-06 - accuracy: 1.0000 - val_loss: 4.1188 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3914/4000\n",
      "2/2 - 0s - loss: 9.5920e-06 - accuracy: 1.0000 - val_loss: 4.1192 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3915/4000\n",
      "2/2 - 0s - loss: 9.5750e-06 - accuracy: 1.0000 - val_loss: 4.1196 - val_accuracy: 0.7250 - 45ms/epoch - 22ms/step\n",
      "Epoch 3916/4000\n",
      "2/2 - 0s - loss: 9.5665e-06 - accuracy: 1.0000 - val_loss: 4.1200 - val_accuracy: 0.7250 - 57ms/epoch - 28ms/step\n",
      "Epoch 3917/4000\n",
      "2/2 - 0s - loss: 9.5580e-06 - accuracy: 1.0000 - val_loss: 4.1204 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3918/4000\n",
      "2/2 - 0s - loss: 9.5409e-06 - accuracy: 1.0000 - val_loss: 4.1207 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3919/4000\n",
      "2/2 - 0s - loss: 9.5345e-06 - accuracy: 1.0000 - val_loss: 4.1211 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3920/4000\n",
      "2/2 - 0s - loss: 9.5133e-06 - accuracy: 1.0000 - val_loss: 4.1215 - val_accuracy: 0.7250 - 45ms/epoch - 23ms/step\n",
      "Epoch 3921/4000\n",
      "2/2 - 0s - loss: 9.5005e-06 - accuracy: 1.0000 - val_loss: 4.1219 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3922/4000\n",
      "2/2 - 0s - loss: 9.4941e-06 - accuracy: 1.0000 - val_loss: 4.1223 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3923/4000\n",
      "2/2 - 0s - loss: 9.4835e-06 - accuracy: 1.0000 - val_loss: 4.1228 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3924/4000\n",
      "2/2 - 0s - loss: 9.4749e-06 - accuracy: 1.0000 - val_loss: 4.1232 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3925/4000\n",
      "2/2 - 0s - loss: 9.4558e-06 - accuracy: 1.0000 - val_loss: 4.1236 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3926/4000\n",
      "2/2 - 0s - loss: 9.4409e-06 - accuracy: 1.0000 - val_loss: 4.1240 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3927/4000\n",
      "2/2 - 0s - loss: 9.4281e-06 - accuracy: 1.0000 - val_loss: 4.1244 - val_accuracy: 0.7250 - 55ms/epoch - 28ms/step\n",
      "Epoch 3928/4000\n",
      "2/2 - 0s - loss: 9.4089e-06 - accuracy: 1.0000 - val_loss: 4.1247 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3929/4000\n",
      "2/2 - 0s - loss: 9.3962e-06 - accuracy: 1.0000 - val_loss: 4.1251 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3930/4000\n",
      "2/2 - 0s - loss: 9.3919e-06 - accuracy: 1.0000 - val_loss: 4.1255 - val_accuracy: 0.7250 - 68ms/epoch - 34ms/step\n",
      "Epoch 3931/4000\n",
      "2/2 - 0s - loss: 9.3791e-06 - accuracy: 1.0000 - val_loss: 4.1259 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3932/4000\n",
      "2/2 - 0s - loss: 9.3685e-06 - accuracy: 1.0000 - val_loss: 4.1262 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3933/4000\n",
      "2/2 - 0s - loss: 9.3600e-06 - accuracy: 1.0000 - val_loss: 4.1267 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3934/4000\n",
      "2/2 - 0s - loss: 9.3557e-06 - accuracy: 1.0000 - val_loss: 4.1271 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "Epoch 3935/4000\n",
      "2/2 - 0s - loss: 9.3451e-06 - accuracy: 1.0000 - val_loss: 4.1274 - val_accuracy: 0.7250 - 44ms/epoch - 22ms/step\n",
      "Epoch 3936/4000\n",
      "2/2 - 0s - loss: 9.3217e-06 - accuracy: 1.0000 - val_loss: 4.1278 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3937/4000\n",
      "2/2 - 0s - loss: 9.3068e-06 - accuracy: 1.0000 - val_loss: 4.1280 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3938/4000\n",
      "2/2 - 0s - loss: 9.2961e-06 - accuracy: 1.0000 - val_loss: 4.1283 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3939/4000\n",
      "2/2 - 0s - loss: 9.2855e-06 - accuracy: 1.0000 - val_loss: 4.1288 - val_accuracy: 0.7250 - 51ms/epoch - 25ms/step\n",
      "Epoch 3940/4000\n",
      "2/2 - 0s - loss: 9.2791e-06 - accuracy: 1.0000 - val_loss: 4.1291 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3941/4000\n",
      "2/2 - 0s - loss: 9.2706e-06 - accuracy: 1.0000 - val_loss: 4.1294 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3942/4000\n",
      "2/2 - 0s - loss: 9.2599e-06 - accuracy: 1.0000 - val_loss: 4.1297 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3943/4000\n",
      "2/2 - 0s - loss: 9.2450e-06 - accuracy: 1.0000 - val_loss: 4.1300 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3944/4000\n",
      "2/2 - 0s - loss: 9.2365e-06 - accuracy: 1.0000 - val_loss: 4.1302 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3945/4000\n",
      "2/2 - 0s - loss: 9.2280e-06 - accuracy: 1.0000 - val_loss: 4.1306 - val_accuracy: 0.7250 - 60ms/epoch - 30ms/step\n",
      "Epoch 3946/4000\n",
      "2/2 - 0s - loss: 9.2238e-06 - accuracy: 1.0000 - val_loss: 4.1310 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3947/4000\n",
      "2/2 - 0s - loss: 9.2089e-06 - accuracy: 1.0000 - val_loss: 4.1313 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3948/4000\n",
      "2/2 - 0s - loss: 9.1940e-06 - accuracy: 1.0000 - val_loss: 4.1316 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3949/4000\n",
      "2/2 - 0s - loss: 9.1790e-06 - accuracy: 1.0000 - val_loss: 4.1320 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3950/4000\n",
      "2/2 - 0s - loss: 9.1727e-06 - accuracy: 1.0000 - val_loss: 4.1323 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3951/4000\n",
      "2/2 - 0s - loss: 9.1535e-06 - accuracy: 1.0000 - val_loss: 4.1327 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3952/4000\n",
      "2/2 - 0s - loss: 9.1471e-06 - accuracy: 1.0000 - val_loss: 4.1331 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3953/4000\n",
      "2/2 - 0s - loss: 9.1365e-06 - accuracy: 1.0000 - val_loss: 4.1335 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3954/4000\n",
      "2/2 - 0s - loss: 9.1194e-06 - accuracy: 1.0000 - val_loss: 4.1339 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3955/4000\n",
      "2/2 - 0s - loss: 9.1109e-06 - accuracy: 1.0000 - val_loss: 4.1343 - val_accuracy: 0.7250 - 71ms/epoch - 35ms/step\n",
      "Epoch 3956/4000\n",
      "2/2 - 0s - loss: 9.1088e-06 - accuracy: 1.0000 - val_loss: 4.1346 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3957/4000\n",
      "2/2 - 0s - loss: 9.0960e-06 - accuracy: 1.0000 - val_loss: 4.1349 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3958/4000\n",
      "2/2 - 0s - loss: 9.0811e-06 - accuracy: 1.0000 - val_loss: 4.1353 - val_accuracy: 0.7250 - 49ms/epoch - 25ms/step\n",
      "Epoch 3959/4000\n",
      "2/2 - 0s - loss: 9.0641e-06 - accuracy: 1.0000 - val_loss: 4.1357 - val_accuracy: 0.7250 - 51ms/epoch - 26ms/step\n",
      "Epoch 3960/4000\n",
      "2/2 - 0s - loss: 9.0577e-06 - accuracy: 1.0000 - val_loss: 4.1361 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3961/4000\n",
      "2/2 - 0s - loss: 9.0428e-06 - accuracy: 1.0000 - val_loss: 4.1364 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3962/4000\n",
      "2/2 - 0s - loss: 9.0300e-06 - accuracy: 1.0000 - val_loss: 4.1368 - val_accuracy: 0.7250 - 47ms/epoch - 24ms/step\n",
      "Epoch 3963/4000\n",
      "2/2 - 0s - loss: 9.0258e-06 - accuracy: 1.0000 - val_loss: 4.1372 - val_accuracy: 0.7250 - 65ms/epoch - 33ms/step\n",
      "Epoch 3964/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 9.0088e-06 - accuracy: 1.0000 - val_loss: 4.1376 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3965/4000\n",
      "2/2 - 0s - loss: 9.0066e-06 - accuracy: 1.0000 - val_loss: 4.1380 - val_accuracy: 0.7250 - 47ms/epoch - 23ms/step\n",
      "Epoch 3966/4000\n",
      "2/2 - 0s - loss: 8.9960e-06 - accuracy: 1.0000 - val_loss: 4.1384 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3967/4000\n",
      "2/2 - 0s - loss: 8.9832e-06 - accuracy: 1.0000 - val_loss: 4.1387 - val_accuracy: 0.7250 - 53ms/epoch - 27ms/step\n",
      "Epoch 3968/4000\n",
      "2/2 - 0s - loss: 8.9704e-06 - accuracy: 1.0000 - val_loss: 4.1390 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3969/4000\n",
      "2/2 - 0s - loss: 8.9513e-06 - accuracy: 1.0000 - val_loss: 4.1393 - val_accuracy: 0.7250 - 48ms/epoch - 24ms/step\n",
      "Epoch 3970/4000\n",
      "2/2 - 0s - loss: 8.9385e-06 - accuracy: 1.0000 - val_loss: 4.1397 - val_accuracy: 0.7250 - 69ms/epoch - 34ms/step\n",
      "Epoch 3971/4000\n",
      "2/2 - 0s - loss: 8.9300e-06 - accuracy: 1.0000 - val_loss: 4.1400 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3972/4000\n",
      "2/2 - 0s - loss: 8.9215e-06 - accuracy: 1.0000 - val_loss: 4.1404 - val_accuracy: 0.7250 - 49ms/epoch - 24ms/step\n",
      "Epoch 3973/4000\n",
      "2/2 - 0s - loss: 8.9130e-06 - accuracy: 1.0000 - val_loss: 4.1407 - val_accuracy: 0.7250 - 54ms/epoch - 27ms/step\n",
      "Epoch 3974/4000\n",
      "2/2 - 0s - loss: 8.9023e-06 - accuracy: 1.0000 - val_loss: 4.1411 - val_accuracy: 0.7250 - 64ms/epoch - 32ms/step\n",
      "Epoch 3975/4000\n",
      "2/2 - 0s - loss: 8.8917e-06 - accuracy: 1.0000 - val_loss: 4.1415 - val_accuracy: 0.7250 - 61ms/epoch - 31ms/step\n",
      "Epoch 3976/4000\n",
      "2/2 - 0s - loss: 8.8810e-06 - accuracy: 1.0000 - val_loss: 4.1419 - val_accuracy: 0.7250 - 72ms/epoch - 36ms/step\n",
      "Epoch 3977/4000\n",
      "2/2 - 0s - loss: 8.8661e-06 - accuracy: 1.0000 - val_loss: 4.1422 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3978/4000\n",
      "2/2 - 0s - loss: 8.8555e-06 - accuracy: 1.0000 - val_loss: 4.1426 - val_accuracy: 0.7250 - 65ms/epoch - 32ms/step\n",
      "Epoch 3979/4000\n",
      "2/2 - 0s - loss: 8.8534e-06 - accuracy: 1.0000 - val_loss: 4.1430 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3980/4000\n",
      "2/2 - 0s - loss: 8.8406e-06 - accuracy: 1.0000 - val_loss: 4.1433 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3981/4000\n",
      "2/2 - 0s - loss: 8.8278e-06 - accuracy: 1.0000 - val_loss: 4.1438 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3982/4000\n",
      "2/2 - 0s - loss: 8.8214e-06 - accuracy: 1.0000 - val_loss: 4.1442 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3983/4000\n",
      "2/2 - 0s - loss: 8.8044e-06 - accuracy: 1.0000 - val_loss: 4.1445 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 3984/4000\n",
      "2/2 - 0s - loss: 8.7938e-06 - accuracy: 1.0000 - val_loss: 4.1449 - val_accuracy: 0.7250 - 61ms/epoch - 30ms/step\n",
      "Epoch 3985/4000\n",
      "2/2 - 0s - loss: 8.7789e-06 - accuracy: 1.0000 - val_loss: 4.1453 - val_accuracy: 0.7250 - 67ms/epoch - 33ms/step\n",
      "Epoch 3986/4000\n",
      "2/2 - 0s - loss: 8.7682e-06 - accuracy: 1.0000 - val_loss: 4.1457 - val_accuracy: 0.7250 - 59ms/epoch - 30ms/step\n",
      "Epoch 3987/4000\n",
      "2/2 - 0s - loss: 8.7640e-06 - accuracy: 1.0000 - val_loss: 4.1462 - val_accuracy: 0.7250 - 66ms/epoch - 33ms/step\n",
      "Epoch 3988/4000\n",
      "2/2 - 0s - loss: 8.7554e-06 - accuracy: 1.0000 - val_loss: 4.1467 - val_accuracy: 0.7250 - 56ms/epoch - 28ms/step\n",
      "Epoch 3989/4000\n",
      "2/2 - 0s - loss: 8.7384e-06 - accuracy: 1.0000 - val_loss: 4.1470 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3990/4000\n",
      "2/2 - 0s - loss: 8.7299e-06 - accuracy: 1.0000 - val_loss: 4.1474 - val_accuracy: 0.7250 - 57ms/epoch - 29ms/step\n",
      "Epoch 3991/4000\n",
      "2/2 - 0s - loss: 8.7256e-06 - accuracy: 1.0000 - val_loss: 4.1478 - val_accuracy: 0.7250 - 67ms/epoch - 34ms/step\n",
      "Epoch 3992/4000\n",
      "2/2 - 0s - loss: 8.7150e-06 - accuracy: 1.0000 - val_loss: 4.1481 - val_accuracy: 0.7250 - 59ms/epoch - 29ms/step\n",
      "Epoch 3993/4000\n",
      "2/2 - 0s - loss: 8.7022e-06 - accuracy: 1.0000 - val_loss: 4.1485 - val_accuracy: 0.7250 - 55ms/epoch - 27ms/step\n",
      "Epoch 3994/4000\n",
      "2/2 - 0s - loss: 8.6894e-06 - accuracy: 1.0000 - val_loss: 4.1489 - val_accuracy: 0.7250 - 63ms/epoch - 32ms/step\n",
      "Epoch 3995/4000\n",
      "2/2 - 0s - loss: 8.6852e-06 - accuracy: 1.0000 - val_loss: 4.1493 - val_accuracy: 0.7250 - 62ms/epoch - 31ms/step\n",
      "Epoch 3996/4000\n",
      "2/2 - 0s - loss: 8.6745e-06 - accuracy: 1.0000 - val_loss: 4.1498 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3997/4000\n",
      "2/2 - 0s - loss: 8.6575e-06 - accuracy: 1.0000 - val_loss: 4.1502 - val_accuracy: 0.7250 - 46ms/epoch - 23ms/step\n",
      "Epoch 3998/4000\n",
      "2/2 - 0s - loss: 8.6469e-06 - accuracy: 1.0000 - val_loss: 4.1506 - val_accuracy: 0.7250 - 58ms/epoch - 29ms/step\n",
      "Epoch 3999/4000\n",
      "2/2 - 0s - loss: 8.6384e-06 - accuracy: 1.0000 - val_loss: 4.1510 - val_accuracy: 0.7250 - 52ms/epoch - 26ms/step\n",
      "Epoch 4000/4000\n",
      "2/2 - 0s - loss: 8.6256e-06 - accuracy: 1.0000 - val_loss: 4.1513 - val_accuracy: 0.7250 - 50ms/epoch - 25ms/step\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8466 - accuracy: 0.7750\n",
      "Final test set loss: 1.846593\n",
      "Final test set accuracy: 0.775000\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.30)\n",
    "val_x, test_x, val_y, test_y = train_test_split(x, y, test_size=0.50)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, input_shape=(27,), activation='relu', name='fc1'))\n",
    "model.add(Dense(50, activation='relu', name='fc2'))\n",
    "model.add(Dense(10, activation='relu', name='fc4'))\n",
    "model.add(Dense(7, activation='softmax', name='output'))\n",
    "\n",
    "# Adam optimizer with learning rate of 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Neural Network Model Summary: ')\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_x, train_y, verbose=2, epochs=1000, validation_data=(val_x, val_y))\n",
    "\n",
    "# Test on unseen data\n",
    "\n",
    "results = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "83d06be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9890866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaee26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954bcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eae738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "569251f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.265356</td>\n",
       "      <td>-0.115455</td>\n",
       "      <td>-0.332518</td>\n",
       "      <td>0.170951</td>\n",
       "      <td>-0.071650</td>\n",
       "      <td>-0.166471</td>\n",
       "      <td>0.282378</td>\n",
       "      <td>-0.248279</td>\n",
       "      <td>0.002671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>-0.265356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860640</td>\n",
       "      <td>0.276163</td>\n",
       "      <td>-0.815666</td>\n",
       "      <td>-0.031072</td>\n",
       "      <td>0.192567</td>\n",
       "      <td>0.351733</td>\n",
       "      <td>0.147555</td>\n",
       "      <td>-0.121854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>-0.115455</td>\n",
       "      <td>0.860640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179392</td>\n",
       "      <td>-0.774632</td>\n",
       "      <td>-0.062182</td>\n",
       "      <td>0.248614</td>\n",
       "      <td>0.433073</td>\n",
       "      <td>0.154587</td>\n",
       "      <td>-0.163190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>-0.332518</td>\n",
       "      <td>0.276163</td>\n",
       "      <td>0.179392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.169729</td>\n",
       "      <td>-0.084955</td>\n",
       "      <td>-0.081976</td>\n",
       "      <td>-0.203824</td>\n",
       "      <td>0.072112</td>\n",
       "      <td>-0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>0.170951</td>\n",
       "      <td>-0.815666</td>\n",
       "      <td>-0.774632</td>\n",
       "      <td>-0.169729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083679</td>\n",
       "      <td>-0.246899</td>\n",
       "      <td>-0.410913</td>\n",
       "      <td>-0.132874</td>\n",
       "      <td>0.145817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>-0.071650</td>\n",
       "      <td>-0.031072</td>\n",
       "      <td>-0.062182</td>\n",
       "      <td>-0.084955</td>\n",
       "      <td>-0.083679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087968</td>\n",
       "      <td>-0.050943</td>\n",
       "      <td>0.072688</td>\n",
       "      <td>0.119384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>-0.166471</td>\n",
       "      <td>0.192567</td>\n",
       "      <td>0.248614</td>\n",
       "      <td>-0.081976</td>\n",
       "      <td>-0.246899</td>\n",
       "      <td>-0.087968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152638</td>\n",
       "      <td>-0.032287</td>\n",
       "      <td>-0.134088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.282378</td>\n",
       "      <td>0.351733</td>\n",
       "      <td>0.433073</td>\n",
       "      <td>-0.203824</td>\n",
       "      <td>-0.410913</td>\n",
       "      <td>-0.050943</td>\n",
       "      <td>0.152638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160590</td>\n",
       "      <td>-0.297470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>-0.248279</td>\n",
       "      <td>0.147555</td>\n",
       "      <td>0.154587</td>\n",
       "      <td>0.072112</td>\n",
       "      <td>-0.132874</td>\n",
       "      <td>0.072688</td>\n",
       "      <td>-0.032287</td>\n",
       "      <td>0.160590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms</th>\n",
       "      <td>0.002671</td>\n",
       "      <td>-0.121854</td>\n",
       "      <td>-0.163190</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.145817</td>\n",
       "      <td>0.119384</td>\n",
       "      <td>-0.134088</td>\n",
       "      <td>-0.297470</td>\n",
       "      <td>-0.041982</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  danceability    energy  loudness  speechiness  acousticness  \\\n",
       "danceability          1.000000 -0.265356 -0.115455    -0.332518      0.170951   \n",
       "energy               -0.265356  1.000000  0.860640     0.276163     -0.815666   \n",
       "loudness             -0.115455  0.860640  1.000000     0.179392     -0.774632   \n",
       "speechiness          -0.332518  0.276163  0.179392     1.000000     -0.169729   \n",
       "acousticness          0.170951 -0.815666 -0.774632    -0.169729      1.000000   \n",
       "instrumentalness     -0.071650 -0.031072 -0.062182    -0.084955     -0.083679   \n",
       "liveness             -0.166471  0.192567  0.248614    -0.081976     -0.246899   \n",
       "valence               0.282378  0.351733  0.433073    -0.203824     -0.410913   \n",
       "tempo                -0.248279  0.147555  0.154587     0.072112     -0.132874   \n",
       "duration_ms           0.002671 -0.121854 -0.163190    -0.000082      0.145817   \n",
       "\n",
       "                  instrumentalness  liveness   valence     tempo  duration_ms  \n",
       "danceability             -0.071650 -0.166471  0.282378 -0.248279     0.002671  \n",
       "energy                   -0.031072  0.192567  0.351733  0.147555    -0.121854  \n",
       "loudness                 -0.062182  0.248614  0.433073  0.154587    -0.163190  \n",
       "speechiness              -0.084955 -0.081976 -0.203824  0.072112    -0.000082  \n",
       "acousticness             -0.083679 -0.246899 -0.410913 -0.132874     0.145817  \n",
       "instrumentalness          1.000000 -0.087968 -0.050943  0.072688     0.119384  \n",
       "liveness                 -0.087968  1.000000  0.152638 -0.032287    -0.134088  \n",
       "valence                  -0.050943  0.152638  1.000000  0.160590    -0.297470  \n",
       "tempo                     0.072688 -0.032287  0.160590  1.000000    -0.041982  \n",
       "duration_ms               0.119384 -0.134088 -0.297470 -0.041982     1.000000  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_continuous = X_scaled.iloc[:,0:10]\n",
    "df_continuous.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5d6f4cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_834/2501747724.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.triu(np.ones_like(df_continuous.corr(), dtype=np.bool))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "mask = np.triu(np.ones_like(df_continuous.corr(), dtype=np.bool))\n",
    "with sns.axes_style('white'):\n",
    "    sns.heatmap(df_continuous.corr(), cmap='BrBG', mask=mask, vmin=-1, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a09829ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "54539030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8, 1, 5, 2, 3, 8, 7, 1, 1, 7, 1, 4, 6, 8, 6, 8, 2, 2, 4, 2, 4,\n",
       "       0])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd53d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873ff5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3816f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e658e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd521a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "00395790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 663, in fit\n",
      "    X, y = self._check_X_y(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 1153, in _check_X_y\n",
      "    X, y = super()._check_X_y(X, y, reset=reset)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 523, in _check_X_y\n",
      "    return self._validate_data(X, y, accept_sparse=\"csr\", reset=reset)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 663, in fit\n",
      "    X, y = self._check_X_y(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 1153, in _check_X_y\n",
      "    X, y = super()._check_X_y(X, y, reset=reset)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 523, in _check_X_y\n",
      "    return self._validate_data(X, y, accept_sparse=\"csr\", reset=reset)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "BernoulliNB()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.001503133773803711\n",
      "fit_time  std  0.0007180782038000101\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "LogisticRegression()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0014708995819091796\n",
      "fit_time  std  0.0013683222298297062\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "DecisionTreeClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.002342700958251953\n",
      "fit_time  std  0.0010666236830134406\n",
      "score_time  mean  0.0012378215789794922\n",
      "score_time  std  0.00021398305360327143\n",
      "test_score  mean  0.3409090909090909\n",
      "test_score  std  0.10946904162538448\n",
      "---------------------------------\n",
      "ExtraTreeClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.001264476776123047\n",
      "fit_time  std  6.078235605716418e-05\n",
      "score_time  mean  0.0011583805084228516\n",
      "score_time  std  0.00016184141159866736\n",
      "test_score  mean  0.25303030303030305\n",
      "test_score  std  0.15801221605434776\n",
      "---------------------------------\n",
      "ExtraTreesClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.13529553413391113\n",
      "fit_time  std  0.01445124677395676\n",
      "score_time  mean  0.024471187591552736\n",
      "score_time  std  0.004781876490902956\n",
      "test_score  mean  0.14242424242424245\n",
      "test_score  std  0.04242424242424243\n",
      "---------------------------------\n",
      "KNeighborsClassifier(n_neighbors=3)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.004497623443603516\n",
      "fit_time  std  0.004090354493486342\n",
      "score_time  mean  0.008092784881591797\n",
      "score_time  std  0.0010572920169016264\n",
      "test_score  mean  0.1606060606060606\n",
      "test_score  std  0.06748805288278813\n",
      "---------------------------------\n",
      "DecisionTreeClassifier(max_depth=5)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.004054212570190429\n",
      "fit_time  std  0.0016911569709339748\n",
      "score_time  mean  0.003357410430908203\n",
      "score_time  std  0.0016019189298458402\n",
      "test_score  mean  0.35757575757575755\n",
      "test_score  std  0.11562899411114491\n",
      "---------------------------------\n",
      "RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.02986907958984375\n",
      "fit_time  std  0.008328471553089377\n",
      "score_time  mean  0.005375099182128906\n",
      "score_time  std  0.001988094333213777\n",
      "test_score  mean  0.053030303030303025\n",
      "test_score  std  0.043387336555382884\n",
      "---------------------------------\n",
      "GradientBoostingClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0022351741790771484\n",
      "fit_time  std  0.0009916760379546565\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "GaussianNB()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.001893758773803711\n",
      "fit_time  std  0.0006912047793462291\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "LabelPropagation()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0014000415802001953\n",
      "fit_time  std  0.0009093821239189836\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "LabelSpreading()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0030349254608154296\n",
      "fit_time  std  0.0019921279865485263\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "LinearDiscriminantAnalysis()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0015649795532226562\n",
      "fit_time  std  0.000743035011292396\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "LinearSVC(multi_class='crammer_singer')\n",
      "-----------------------------------\n",
      "fit_time  mean  0.001108264923095703\n",
      "fit_time  std  0.00014565424780756098\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "LogisticRegression(multi_class='multinomial')\n",
      "-----------------------------------\n",
      "fit_time  mean  0.000815725326538086\n",
      "fit_time  std  5.5222107578057195e-05\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "LogisticRegressionCV(multi_class='multinomial')\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0010272979736328125\n",
      "fit_time  std  0.00023139568508652708\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 494, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 494, in fit\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 244, in fit\n",
      "    y = self._validate_data(y=y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 569, in _validate_data\n",
      "    y = _check_y(y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\", line 244, in fit\n",
      "    y = self._validate_data(y=y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 569, in _validate_data\n",
      "    y = _check_y(y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/semi_supervised/_label_propagation.py\", line 475, in fit\n",
      "    return super().fit(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/semi_supervised/_label_propagation.py\", line 249, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/semi_supervised/_label_propagation.py\", line 475, in fit\n",
      "    return super().fit(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/semi_supervised/_label_propagation.py\", line 249, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/semi_supervised/_label_propagation.py\", line 249, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/semi_supervised/_label_propagation.py\", line 249, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 544, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 544, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\", line 246, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\", line 246, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 2077, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 2077, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_nearest_centroid.py\", line 127, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=[\"csr\", \"csc\"])\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_nearest_centroid.py\", line 127, in fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=[\"csr\", \"csc\"])\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 842, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (44, 7) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 842, in fit\n",
      "    X, y = self._validate_data(X, y)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 979, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 993, in _check_y\n",
      "    y = column_or_1d(y, warn=True)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1038, in column_or_1d\n",
      "    raise ValueError(\n",
      "ValueError: y should be a 1d array, got an array of shape (45, 7) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 711, in score\n",
      "    return self.steps[-1][1].score(Xt, y, **score_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 651, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 569, in predict\n",
      "    probs = self.predict_proba(X)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 628, in predict_proba\n",
      "    raise ValueError(\n",
      "ValueError: No neighbors found for test samples array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 711, in score\n",
      "    return self.steps[-1][1].score(Xt, y, **score_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 651, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 569, in predict\n",
      "    probs = self.predict_proba(X)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 628, in predict_proba\n",
      "    raise ValueError(\n",
      "ValueError: No neighbors found for test samples array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 711, in score\n",
      "    return self.steps[-1][1].score(Xt, y, **score_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 651, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 569, in predict\n",
      "    probs = self.predict_proba(X)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 628, in predict_proba\n",
      "    raise ValueError(\n",
      "ValueError: No neighbors found for test samples array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 711, in score\n",
      "    return self.steps[-1][1].score(Xt, y, **score_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 651, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 569, in predict\n",
      "    probs = self.predict_proba(X)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 628, in predict_proba\n",
      "    raise ValueError(\n",
      "ValueError: No neighbors found for test samples array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 711, in score\n",
      "    return self.steps[-1][1].score(Xt, y, **score_params)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 651, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 569, in predict\n",
      "    probs = self.predict_proba(X)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 628, in predict_proba\n",
      "    raise ValueError(\n",
      "ValueError: No neighbors found for test samples array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "MLPClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.3290721416473389\n",
      "fit_time  std  0.0309477091748715\n",
      "score_time  mean  0.0042208671569824215\n",
      "score_time  std  0.0006291632866585517\n",
      "test_score  mean  0.16060606060606059\n",
      "test_score  std  0.06748805288278813\n",
      "---------------------------------\n",
      "NearestCentroid()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0024223804473876955\n",
      "fit_time  std  0.0014214515558068123\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "QuadraticDiscriminantAnalysis()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0018260478973388672\n",
      "fit_time  std  0.00032947739668659433\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "RadiusNeighborsClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.006570768356323242\n",
      "fit_time  std  0.004008481634243389\n",
      "score_time  mean  0.0025310516357421875\n",
      "score_time  std  0.0016693221925803367\n",
      "test_score  mean  nan\n",
      "test_score  std  nan\n",
      "---------------------------------\n",
      "RandomForestClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.18943386077880858\n",
      "fit_time  std  0.03852376838414715\n",
      "score_time  mean  0.023583269119262694\n",
      "score_time  std  0.005380012624380262\n",
      "test_score  mean  0.14393939393939395\n",
      "test_score  std  0.07391703586454829\n",
      "---------------------------------\n",
      "RidgeClassifier()\n",
      "-----------------------------------\n",
      "fit_time  mean  0.011269378662109374\n",
      "fit_time  std  0.011682277186071094\n",
      "score_time  mean  0.0019493579864501953\n",
      "score_time  std  0.00012191723747657404\n",
      "test_score  mean  0.08787878787878789\n",
      "test_score  std  0.05283513870958392\n",
      "---------------------------------\n",
      "RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ]))\n",
      "-----------------------------------\n",
      "fit_time  mean  0.00944204330444336\n",
      "fit_time  std  0.00982879338850676\n",
      "score_time  mean  0.0013790130615234375\n",
      "score_time  std  0.00037994955074863515\n",
      "test_score  mean  0.10606060606060608\n",
      "test_score  std  0.0649927593622037\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('normalizer', StandardScaler()), #Step1 - normalize data\n",
    "    ('clf', LogisticRegression()) #step2 - classifier\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(pipeline, train_x, train_y)\n",
    "scores\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "classifiers = [\n",
    "    BernoulliNB(),\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreeClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    KNeighborsClassifier(n_neighbors=3),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LabelPropagation(),\n",
    "    LabelSpreading(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    LinearSVC(multi_class='crammer_singer'),\n",
    "    LogisticRegression(multi_class='multinomial'),\n",
    "    LogisticRegressionCV(multi_class='multinomial'),\n",
    "    MLPClassifier(),\n",
    "    NearestCentroid(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    RadiusNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    RidgeClassifier(),\n",
    "    RidgeClassifierCV()\n",
    "]\n",
    "\n",
    "clfs = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clfs.append(classifier)\n",
    "\n",
    "for classifier in clfs:\n",
    "    pipeline.set_params(clf = classifier)\n",
    "    scores = cross_validate(pipeline, train_x, train_y)\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    \n",
    "    for key, values in scores.items():\n",
    "            print(key,' mean ', values.mean())\n",
    "            print(key,' std ', values.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "958b2dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(pd.DataFrame(result1).iloc[:-1, :-4].T, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c415ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
      "              predictor=None, ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       0.80      0.50      0.62         8\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.70      1.00      0.82         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       1.00      0.67      0.80         9\n",
      "\n",
      "   micro avg       0.88      0.75      0.81        40\n",
      "   macro avg       0.93      0.76      0.81        40\n",
      "weighted avg       0.91      0.75      0.80        40\n",
      " samples avg       0.75      0.75      0.75        40\n",
      "\n",
      "Accuracy: 0.75\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.75      0.43      0.55         7\n",
      "           4       0.83      1.00      0.91         5\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.50      0.11      0.18         9\n",
      "\n",
      "   micro avg       0.67      0.25      0.36        40\n",
      "   macro avg       0.44      0.24      0.27        40\n",
      "weighted avg       0.50      0.25      0.29        40\n",
      " samples avg       0.25      0.25      0.25        40\n",
      "\n",
      "Accuracy: 0.25\n",
      "DecisionTreeClassifier(max_depth=70)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.67      0.50      0.57         8\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.70      1.00      0.82         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.67      0.67      0.67         3\n",
      "           6       0.88      0.78      0.82         9\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        40\n",
      "   macro avg       0.82      0.83      0.82        40\n",
      "weighted avg       0.80      0.80      0.79        40\n",
      " samples avg       0.80      0.80      0.80        40\n",
      "\n",
      "Accuracy: 0.8\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       1.00      0.38      0.55         8\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.88      1.00      0.93         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       1.00      0.78      0.88         9\n",
      "\n",
      "   micro avg       0.94      0.75      0.83        40\n",
      "   macro avg       0.96      0.76      0.81        40\n",
      "weighted avg       0.95      0.75      0.81        40\n",
      " samples avg       0.75      0.75      0.75        40\n",
      "\n",
      "Accuracy: 0.75\n",
      "ExtraTreesClassifier(n_estimators=10, random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       1.00      0.50      0.67         8\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       0.88      1.00      0.93         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       1.00      0.78      0.88         9\n",
      "\n",
      "   micro avg       0.94      0.78      0.85        40\n",
      "   macro avg       0.93      0.78      0.81        40\n",
      "weighted avg       0.96      0.78      0.83        40\n",
      " samples avg       0.78      0.78      0.78        40\n",
      "\n",
      "Accuracy: 0.775\n",
      "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=0.1, n_estimators=300)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.67      0.50      0.57         8\n",
      "           2       0.33      1.00      0.50         2\n",
      "           3       0.50      0.43      0.46         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       0.89      0.89      0.89         9\n",
      "\n",
      "   micro avg       0.72      0.72      0.73        40\n",
      "   macro avg       0.75      0.76      0.72        40\n",
      "weighted avg       0.76      0.72      0.73        40\n",
      " samples avg       0.72      0.72      0.72        40\n",
      "\n",
      "Accuracy: 0.725\n",
      "GradientBoostingClassifier(random_state=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.80      0.50      0.62         8\n",
      "           2       0.50      1.00      0.67         2\n",
      "           3       0.70      1.00      0.82         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       0.89      0.89      0.89         9\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        40\n",
      "   macro avg       0.82      0.79      0.76        40\n",
      "weighted avg       0.83      0.80      0.79        40\n",
      " samples avg       0.80      0.80      0.80        40\n",
      "\n",
      "Accuracy: 0.8\n",
      "HistGradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       1.00      0.62      0.77         8\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       0.70      1.00      0.82         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       0.80      0.89      0.84         9\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        40\n",
      "   macro avg       0.88      0.86      0.85        40\n",
      "weighted avg       0.89      0.85      0.85        40\n",
      " samples avg       0.85      0.85      0.85        40\n",
      "\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import cv\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import DMatrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "classifiers_1 = [\n",
    "    XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(max_depth=70),\n",
    "    RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42),\n",
    "    ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0),   \n",
    "]\n",
    "\n",
    "classifiers_2 = [\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=300, learning_rate=.1),\n",
    "    GradientBoostingClassifier(learning_rate=0.1, random_state=10),\n",
    "    HistGradientBoostingClassifier(max_iter=100)\n",
    "]\n",
    "\n",
    "for classifier in classifiers_1:\n",
    "    print(str(classifier))\n",
    "    classifier.fit(train_x,train_y)\n",
    "    ypred=classifier.predict(test_x)\n",
    "    result1 = classification_report(test_y, ypred)\n",
    "    print (result1)\n",
    "    #sns.heatmap(pd.DataFrame(result1).iloc[:-1, :].T, annot=True)\n",
    "    result2 = accuracy_score(test_y,ypred)\n",
    "    print('Accuracy:',result2)\n",
    "    \n",
    "tmp_df = pd.DataFrame(train_y)\n",
    "train_y_decoded = tmp_df.apply(lambda x: x.argmax(), axis=1).values\n",
    "tmp_df = pd.DataFrame(test_y)\n",
    "test_y_decoded = tmp_df.apply(lambda x: x.argmax(), axis=1).values\n",
    "    \n",
    "for classifier in classifiers_2:\n",
    "    \n",
    "    print(str(classifier))\n",
    "\n",
    "    classifier.fit(train_x,train_y_decoded)\n",
    "    ypred=classifier.predict(test_x)\n",
    "    tmp_df = pd.DataFrame(ypred,columns=['album'])\n",
    "   \n",
    "    ypred_encoded = pd.get_dummies(tmp_df['album']).to_numpy()\n",
    "\n",
    "\n",
    "    result1 = classification_report(test_y, ypred_encoded)\n",
    "    \n",
    "    print (result1)\n",
    "    #sns.heatmap(pd.DataFrame(result1).iloc[:-1, :].T, annot=True)\n",
    "    result2 = accuracy_score(test_y,ypred_encoded)\n",
    "    print('Accuracy:',result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "bc977fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on dict object:\n",
      "\n",
      "class dict(object)\n",
      " |  dict() -> new empty dictionary\n",
      " |  dict(mapping) -> new dictionary initialized from a mapping object's\n",
      " |      (key, value) pairs\n",
      " |  dict(iterable) -> new dictionary initialized as if via:\n",
      " |      d = {}\n",
      " |      for k, v in iterable:\n",
      " |          d[k] = v\n",
      " |  dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      " |      in the keyword argument list.  For example:  dict(one=1, two=2)\n",
      " |  \n",
      " |  Built-in subclasses:\n",
      " |      StgDict\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      True if the dictionary has the specified key, else False.\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __ior__(self, value, /)\n",
      " |      Return self|=value.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __or__(self, value, /)\n",
      " |      Return self|value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __reversed__(self, /)\n",
      " |      Return a reverse iterator over the dict keys.\n",
      " |  \n",
      " |  __ror__(self, value, /)\n",
      " |      Return value|self.\n",
      " |  \n",
      " |  __setitem__(self, key, value, /)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -> size of D in memory, in bytes\n",
      " |  \n",
      " |  clear(...)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      D.copy() -> a shallow copy of D\n",
      " |  \n",
      " |  get(self, key, default=None, /)\n",
      " |      Return the value for key if key is in the dictionary, else default.\n",
      " |  \n",
      " |  items(...)\n",
      " |      D.items() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  keys(...)\n",
      " |      D.keys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  pop(...)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      \n",
      " |      If key is not found, default is returned if given, otherwise KeyError is raised\n",
      " |  \n",
      " |  popitem(self, /)\n",
      " |      Remove and return a (key, value) pair as a 2-tuple.\n",
      " |      \n",
      " |      Pairs are returned in LIFO (last-in, first-out) order.\n",
      " |      Raises KeyError if the dict is empty.\n",
      " |  \n",
      " |  setdefault(self, key, default=None, /)\n",
      " |      Insert key with a value of default if key is not in the dictionary.\n",
      " |      \n",
      " |      Return the value for key if key is in the dictionary, else default.\n",
      " |  \n",
      " |  update(...)\n",
      " |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      " |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
      " |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      " |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      " |  \n",
      " |  values(...)\n",
      " |      D.values() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  __class_getitem__(...) from builtins.type\n",
      " |      See PEP 585\n",
      " |  \n",
      " |  fromkeys(iterable, value=None, /) from builtins.type\n",
      " |      Create a new dictionary with keys from iterable and values set to value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hgbc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "507270e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1757, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score of the grid-searched pipeline is: 0.90\n",
      "CPU times: user 39.8 s, sys: 1.54 s, total: 41.3 s\n",
      "Wall time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "hgbc = HistGradientBoostingClassifier(max_iter=100)\n",
    "\n",
    "param_grid = {\n",
    " 'max_iter': [1000,1200,1500],\n",
    " 'learning_rate': [0.1],\n",
    " 'max_depth' : [25, 50, 75],\n",
    " 'l2_regularization': [1.5],\n",
    " 'scoring': ['f1_micro'],\n",
    " 'random_state' : [13],\n",
    " }\n",
    "\n",
    "scorers = {\n",
    "        'precision_score': make_scorer(precision_score),\n",
    "        'recall_score': make_scorer(recall_score),\n",
    "        'accuracy_score': make_scorer(accuracy_score)\n",
    "        }\n",
    "\n",
    "model_grid_search = GridSearchCV(hgbc, param_grid=param_grid,\n",
    "                                 n_jobs=2, cv=2, scoring=scorers, refit='accuracy_score')\n",
    "model_grid_search.fit(train_x, train_y_decoded)\n",
    "\n",
    "accuracy = model_grid_search.score(test_x,test_y_decoded)\n",
    "print(\n",
    "    f\"The test accuracy score of the grid-searched pipeline is: \"\n",
    "    f\"{accuracy:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "fcf922c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "The test accuracy score of the grid-searched pipeline is: 0.90\n",
      "CPU times: user 4min 8s, sys: 9.9 s, total: 4min 18s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "hgbc = HistGradientBoostingClassifier(max_iter=100)\n",
    "\n",
    "param_grid = {\n",
    " 'max_iter': [1000,1200,1500],\n",
    " 'learning_rate': [0.1],\n",
    " 'max_depth' : [25, 50, 75],\n",
    " 'l2_regularization': [1.5],\n",
    " 'scoring': ['f1_micro'],\n",
    " 'random_state' : [13],\n",
    " }\n",
    "\n",
    "# scorers = {\n",
    "#         'precision_score': make_scorer(precision_score),\n",
    "#         'recall_score': make_scorer(recall_score),\n",
    "#         'accuracy_score': make_scorer(accuracy_score)\n",
    "#         }\n",
    "\n",
    "model_grid_search = GridSearchCV(hgbc, param_grid=param_grid,\n",
    "                                 n_jobs=2, cv=5, scoring='f1_micro', verbose=2, refit=True)\n",
    "model_grid_search.fit(train_x, train_y_decoded)\n",
    "\n",
    "accuracy = model_grid_search.score(test_x,test_y_decoded)\n",
    "print(\n",
    "    f\"The test accuracy score of the grid-searched pipeline is: \"\n",
    "    f\"{accuracy:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "1aa25d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l2_regularization': 1.5, 'learning_rate': 0.1, 'max_depth': 25, 'max_iter': 1000, 'random_state': 13, 'scoring': 'f1_micro'}\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(model_grid_search.best_params_)\n",
    "# Print the best scores found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "bd317e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', 'micro avg', 'macro avg', 'weighted avg', 'samples avg'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ypred=model_grid_search.predict(test_x)\n",
    "tmp_df = pd.DataFrame(ypred,columns=['album'])\n",
    "\n",
    "ypred_encoded = pd.get_dummies(tmp_df['album']).to_numpy()\n",
    "\n",
    "\n",
    "result1 = classification_report(test_y, ypred_encoded,output_dict=True)\n",
    "print(result1.keys())\n",
    "with sns.axes_style('white'):\n",
    "    sns.heatmap(pd.DataFrame(result1).iloc[:-1, :-4].T, annot=True)\n",
    "\n",
    "#sns.heatmap(pd.DataFrame(result1).iloc[:-1, :].T, annot=True)\n",
    "result2 = accuracy_score(test_y,ypred_encoded)\n",
    "#print('Accuracy:',result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1740e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function classification_report in module sklearn.metrics._classification:\n",
      "\n",
      "classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
      "    Build a text report showing the main classification metrics.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <classification_report>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array-like of shape (n_labels,), default=None\n",
      "        Optional list of label indices to include in the report.\n",
      "    \n",
      "    target_names : list of str of shape (n_labels,), default=None\n",
      "        Optional display names matching the labels (same order).\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    digits : int, default=2\n",
      "        Number of digits for formatting output floating point values.\n",
      "        When ``output_dict`` is ``True``, this will be ignored and the\n",
      "        returned values will not be rounded.\n",
      "    \n",
      "    output_dict : bool, default=False\n",
      "        If True, return output as dict.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    zero_division : \"warn\", 0 or 1, default=\"warn\"\n",
      "        Sets the value to return when there is a zero division. If set to\n",
      "        \"warn\", this acts as 0, but warnings are also raised.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    report : str or dict\n",
      "        Text summary of the precision, recall, F1 score for each class.\n",
      "        Dictionary returned if output_dict is True. Dictionary has the\n",
      "        following structure::\n",
      "    \n",
      "            {'label 1': {'precision':0.5,\n",
      "                         'recall':1.0,\n",
      "                         'f1-score':0.67,\n",
      "                         'support':1},\n",
      "             'label 2': { ... },\n",
      "              ...\n",
      "            }\n",
      "    \n",
      "        The reported averages include macro average (averaging the unweighted\n",
      "        mean per label), weighted average (averaging the support-weighted mean\n",
      "        per label), and sample average (only for multilabel classification).\n",
      "        Micro average (averaging the total true positives, false negatives and\n",
      "        false positives) is only shown for multi-label or multi-class\n",
      "        with a subset of classes, because it corresponds to accuracy\n",
      "        otherwise and would be the same for all metrics.\n",
      "        See also :func:`precision_recall_fscore_support` for more details\n",
      "        on averages.\n",
      "    \n",
      "        Note that in binary classification, recall of the positive class\n",
      "        is also known as \"sensitivity\"; recall of the negative class is\n",
      "        \"specificity\".\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    precision_recall_fscore_support, confusion_matrix,\n",
      "    multilabel_confusion_matrix\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import classification_report\n",
      "    >>> y_true = [0, 1, 2, 2, 2]\n",
      "    >>> y_pred = [0, 0, 2, 2, 1]\n",
      "    >>> target_names = ['class 0', 'class 1', 'class 2']\n",
      "    >>> print(classification_report(y_true, y_pred, target_names=target_names))\n",
      "                  precision    recall  f1-score   support\n",
      "    <BLANKLINE>\n",
      "         class 0       0.50      1.00      0.67         1\n",
      "         class 1       0.00      0.00      0.00         1\n",
      "         class 2       1.00      0.67      0.80         3\n",
      "    <BLANKLINE>\n",
      "        accuracy                           0.60         5\n",
      "       macro avg       0.50      0.56      0.49         5\n",
      "    weighted avg       0.70      0.60      0.61         5\n",
      "    <BLANKLINE>\n",
      "    >>> y_pred = [1, 1, 0]\n",
      "    >>> y_true = [1, 1, 1]\n",
      "    >>> print(classification_report(y_true, y_pred, labels=[1, 2, 3]))\n",
      "                  precision    recall  f1-score   support\n",
      "    <BLANKLINE>\n",
      "               1       1.00      0.67      0.80         3\n",
      "               2       0.00      0.00      0.00         0\n",
      "               3       0.00      0.00      0.00         0\n",
      "    <BLANKLINE>\n",
      "       micro avg       1.00      0.67      0.80         3\n",
      "       macro avg       0.33      0.22      0.27         3\n",
      "    weighted avg       1.00      0.67      0.80         3\n",
      "    <BLANKLINE>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f2d1acf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'auto', 'learning_rate': 0.1, 'max_iter': 100, 'max_leaf_nodes': 31, 'max_depth': None, 'min_samples_leaf': 20, 'l2_regularization': 0.0, 'max_bins': 255, 'monotonic_cst': None, 'categorical_features': None, 'warm_start': False, 'early_stopping': 'auto', 'scoring': 'loss', 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'tol': 1e-07, 'verbose': 0, 'random_state': None}\n",
      "The test accuracy score of the grid-searched pipeline is: 0.85\n"
     ]
    }
   ],
   "source": [
    "hgbc = HistGradientBoostingClassifier(max_iter=100)\n",
    "print(vars(hgbc))\n",
    "\n",
    "hgbc.fit(train_x, train_y_decoded)\n",
    "accuracy = hgbc.score(test_x,test_y_decoded)\n",
    "print(\n",
    "    f\"The test accuracy score of the grid-searched pipeline is: \"\n",
    "    f\"{accuracy:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc0c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef6447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf20d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c584d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.DataFrame(train_y)\n",
    "train_y_decoded = label.apply(lambda x: x.argmax(), axis=1).values\n",
    "\n",
    "label = pd.DataFrame(test_y)\n",
    "test_y_decoded = label.apply(lambda x: x.argmax(), axis=1).values\n",
    "\n",
    "label = pd.DataFrame(val_y)\n",
    "val_y_decoded = label.apply(lambda x: x.argmax(), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4a15f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b6bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "73f645bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.455069\n",
      "49    0.386624\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "xg_reg = XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "params = {\"objective\":'binary:logistic','colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "data_dmatrix = DMatrix(data=X_scaled,label=y, enable_categorical=True)\n",
    "cv_results = cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))\n",
    "\n",
    "\n",
    "xg_clf = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "542e7d12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py:79\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[0;32m---> 79\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43m_run_input_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py:99\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_input_lines\u001b[39m(cmd, input_lines, \u001b[38;5;241m*\u001b[39m, kwargs):\n\u001b[0;32m---> 99\u001b[0m     popen \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     stdin_write \u001b[38;5;241m=\u001b[39m popen\u001b[38;5;241m.\u001b[39mstdin\u001b[38;5;241m.\u001b[39mwrite\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/core/formatters.py:973\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    970\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 973\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/jupyter_integration.py:112\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_image_svg_xml\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msvg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSVG_ENCODING\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m          \u001b[38;5;28mformat\u001b[39m: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m          renderer: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m          engine: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m          encoding: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m        '<?xml version='\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_legacy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@_tools\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecate_positional_args(supported_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe_legacy\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    114\u001b[0m                  \u001b[38;5;28mformat\u001b[39m: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                  engine: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                  encoding: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/piping.py:149\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mlookup(encoding) \u001b[38;5;129;01mis\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding):\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;66;03m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_lines_string\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m         raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_lines(\u001b[38;5;241m*\u001b[39margs, input_encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/backend/piping.py:212\u001b[0m, in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    206\u001b[0m cmd \u001b[38;5;241m=\u001b[39m dot_command\u001b[38;5;241m.\u001b[39mcommand(engine, \u001b[38;5;28mformat\u001b[39m,\n\u001b[1;32m    207\u001b[0m                           renderer\u001b[38;5;241m=\u001b[39mrenderer,\n\u001b[1;32m    208\u001b[0m                           formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[1;32m    209\u001b[0m                           neato_no_op\u001b[38;5;241m=\u001b[39mneato_no_op)\n\u001b[1;32m    210\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_lines\u001b[39m\u001b[38;5;124m'\u001b[39m: input_lines, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding}\n\u001b[0;32m--> 212\u001b[0m proc \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m---> 84\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.sources.Source at 0x7fb353d78340>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import graphviz\n",
    "from xgboost import plot_tree\n",
    "from graphviz import Digraph\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH']+';'+os.environ['CONDA_PREFIX']+r\"\\Library\\bin\\graphviz\"\n",
    "\n",
    "xgb.to_graphviz(xg_clf, num_trees=0, rankdir='LR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "da0d0042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xg_clf)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.rcParams[\"figure.facecolor\"] = \"b\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a147979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_clf=KNeighborsClassifier()\n",
    "# knn_clf.fit(train_x,train_y)\n",
    "# ypred=knn_clf.predict(test_x)\n",
    "\n",
    "# dtc_clf=DecisionTreeClassifier(max_depth=70)\n",
    "# dtc_clf.fit(train_x,train_y)\n",
    "# ypred=dtc_clf.predict(test_x)\n",
    "\n",
    "rfc_clf=RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "rfc_clf.fit(train_x,train_y)\n",
    "ypred=rfc_clf.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "18992174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       1.00      0.38      0.55         8\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.88      1.00      0.93         7\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       1.00      0.78      0.88         9\n",
      "\n",
      "   micro avg       0.94      0.75      0.83        40\n",
      "   macro avg       0.96      0.76      0.81        40\n",
      "weighted avg       0.95      0.75      0.81        40\n",
      " samples avg       0.75      0.75      0.75        40\n",
      "\n",
      "Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcsg/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "result1 = classification_report(test_y, ypred)\n",
    "print('Classification Report:',)\n",
    "print (result1)\n",
    "result2 = accuracy_score(test_y,ypred)\n",
    "print('Accuracy:',result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a912dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50305b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12feca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74e602da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('df22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6544232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('df22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4eca424b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.922</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-5.192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>0.00487</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.417</td>\n",
       "      <td>146.478</td>\n",
       "      <td>222947.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.948</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-4.190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.778</td>\n",
       "      <td>103.183</td>\n",
       "      <td>173680.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.778</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-4.225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.00998</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.704</td>\n",
       "      <td>127.158</td>\n",
       "      <td>177947.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.00328</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.852</td>\n",
       "      <td>144.499</td>\n",
       "      <td>141133.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-01-29</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.972</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-4.274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.00384</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.926</td>\n",
       "      <td>105.492</td>\n",
       "      <td>130813.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-11.889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.78000</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.236</td>\n",
       "      <td>94.033</td>\n",
       "      <td>198554.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.328</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-9.973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.66300</td>\n",
       "      <td>0.00365</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.343</td>\n",
       "      <td>67.023</td>\n",
       "      <td>237984.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.452</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.27600</td>\n",
       "      <td>0.00998</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.653</td>\n",
       "      <td>169.298</td>\n",
       "      <td>244932.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.335</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-13.637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.80200</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.388</td>\n",
       "      <td>127.587</td>\n",
       "      <td>210012.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.478</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.61000</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.545</td>\n",
       "      <td>82.932</td>\n",
       "      <td>167380.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 release_date  danceability  energy   key  loudness  mode  \\\n",
       "0            0   2006-01-29         0.387   0.922   9.0    -5.192   0.0   \n",
       "1            1   2006-01-29         0.535   0.948   6.0    -4.190   0.0   \n",
       "2            2   2006-01-29         0.454   0.778   9.0    -4.225   1.0   \n",
       "3            3   2006-01-29         0.522   0.889   1.0    -4.137   1.0   \n",
       "4            4   2006-01-29         0.580   0.972  11.0    -4.274   0.0   \n",
       "..         ...          ...           ...     ...   ...       ...   ...   \n",
       "75          75   2022-10-21         0.428   0.365   4.0   -11.889   0.0   \n",
       "76          76   2022-10-21         0.548   0.328   9.0    -9.973   0.0   \n",
       "77          77   2022-10-21         0.394   0.452   4.0    -9.923   0.0   \n",
       "78          78   2022-10-21         0.569   0.335  11.0   -13.637   0.0   \n",
       "79          79   2022-10-21         0.520   0.478   4.0   -10.862   1.0   \n",
       "\n",
       "    speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0        0.0674       0.00487           0.00000    0.1870    0.417  146.478   \n",
       "1        0.0356       0.00225           0.00000    0.3760    0.778  103.183   \n",
       "2        0.0449       0.00998           0.00000    0.0427    0.704  127.158   \n",
       "3        0.0461       0.00328           0.00000    0.3450    0.852  144.499   \n",
       "4        0.0589       0.00384           0.00000    0.2960    0.926  105.492   \n",
       "..          ...           ...               ...       ...      ...      ...   \n",
       "75       0.0276       0.78000           0.00330    0.1130    0.236   94.033   \n",
       "76       0.0296       0.66300           0.00365    0.0972    0.343   67.023   \n",
       "77       0.0321       0.27600           0.00998    0.1930    0.653  169.298   \n",
       "78       0.0322       0.80200           0.01800    0.0834    0.388  127.587   \n",
       "79       0.0276       0.61000           0.00122    0.1050    0.545   82.932   \n",
       "\n",
       "    duration_ms  time_signature  \n",
       "0      222947.0             4.0  \n",
       "1      173680.0             4.0  \n",
       "2      177947.0             4.0  \n",
       "3      141133.0             4.0  \n",
       "4      130813.0             4.0  \n",
       "..          ...             ...  \n",
       "75     198554.0             3.0  \n",
       "76     237984.0             3.0  \n",
       "77     244932.0             4.0  \n",
       "78     210012.0             4.0  \n",
       "79     167380.0             4.0  \n",
       "\n",
       "[80 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.drop(['track_number','name','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4e19dda",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'album'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'album'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df2\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malbum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malbum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m df2\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:5270\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   5229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   5230\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5231\u001b[0m \u001b[38;5;124;03m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[1;32m   5232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;124;03m    3  monkey        NaN\u001b[39;00m\n\u001b[1;32m   5269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:865\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m Any:\n\u001b[0;32m--> 865\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m[item]\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'album'"
     ]
    }
   ],
   "source": [
    "df2.insert(0, 'album', df2.pop('album'))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8cd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
